{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder\n",
    "\n",
    "We will evaluate denoising autoencoders applied to the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model \n",
    "\n",
    "Autoencoders can be used to denoise images quite successfully just by training the network on noisy images. We can create the noisy images ourselves by adding Gaussian noise to the training images, then clipping the values to be between 0 and 1. We'll use noisy images as input and the original, clean images as targets. Here's an example of the noisy images I generated and the denoised images.\n",
    "\n",
    "![Denoising autoencoder](assets/denoising.png)\n",
    "\n",
    "\n",
    "Since this is a harder problem for the network, we'll want to use deeper convolutional layers here, more feature maps. We wil use 32-32-16 for the depths of the convolutional layers in the encoder, and the same depths going backward through the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs_, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n",
    "# Now 14x14x32\n",
    "conv2 = tf.layers.conv2d(maxpool1, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "# Now 7x7x32\n",
    "conv3 = tf.layers.conv2d(maxpool2, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "encoded = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')\n",
    "# Now 4x4x16\n",
    "\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "# Now 7x7x16\n",
    "conv4 = tf.layers.conv2d(upsample1, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "# Now 14x14x16\n",
    "conv5 = tf.layers.conv2d(upsample2, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))\n",
    "# Now 28x28x32\n",
    "conv6 = tf.layers.conv2d(upsample3, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "\n",
    "logits = tf.layers.conv2d(conv6, 1, (3,3), padding='same', activation=None)\n",
    "#Now 28x28x1\n",
    "\n",
    "decoded = tf.nn.sigmoid(logits, name='decoded')\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Training loss: 0.6963\n",
      "Epoch: 1/100... Training loss: 0.6888\n",
      "Epoch: 1/100... Training loss: 0.6817\n",
      "Epoch: 1/100... Training loss: 0.6691\n",
      "Epoch: 1/100... Training loss: 0.6500\n",
      "Epoch: 1/100... Training loss: 0.6193\n",
      "Epoch: 1/100... Training loss: 0.5831\n",
      "Epoch: 1/100... Training loss: 0.5391\n",
      "Epoch: 1/100... Training loss: 0.5141\n",
      "Epoch: 1/100... Training loss: 0.4993\n",
      "Epoch: 1/100... Training loss: 0.5381\n",
      "Epoch: 1/100... Training loss: 0.5265\n",
      "Epoch: 1/100... Training loss: 0.5055\n",
      "Epoch: 1/100... Training loss: 0.4760\n",
      "Epoch: 1/100... Training loss: 0.4790\n",
      "Epoch: 1/100... Training loss: 0.4601\n",
      "Epoch: 1/100... Training loss: 0.4676\n",
      "Epoch: 1/100... Training loss: 0.4571\n",
      "Epoch: 1/100... Training loss: 0.4501\n",
      "Epoch: 1/100... Training loss: 0.4393\n",
      "Epoch: 1/100... Training loss: 0.4213\n",
      "Epoch: 1/100... Training loss: 0.4212\n",
      "Epoch: 1/100... Training loss: 0.4179\n",
      "Epoch: 1/100... Training loss: 0.4021\n",
      "Epoch: 1/100... Training loss: 0.3889\n",
      "Epoch: 1/100... Training loss: 0.3717\n",
      "Epoch: 1/100... Training loss: 0.3588\n",
      "Epoch: 1/100... Training loss: 0.3518\n",
      "Epoch: 1/100... Training loss: 0.3455\n",
      "Epoch: 1/100... Training loss: 0.3308\n",
      "Epoch: 1/100... Training loss: 0.3252\n",
      "Epoch: 1/100... Training loss: 0.3022\n",
      "Epoch: 1/100... Training loss: 0.3134\n",
      "Epoch: 1/100... Training loss: 0.3046\n",
      "Epoch: 1/100... Training loss: 0.2965\n",
      "Epoch: 1/100... Training loss: 0.2808\n",
      "Epoch: 1/100... Training loss: 0.2837\n",
      "Epoch: 1/100... Training loss: 0.2832\n",
      "Epoch: 1/100... Training loss: 0.2742\n",
      "Epoch: 1/100... Training loss: 0.2784\n",
      "Epoch: 1/100... Training loss: 0.2721\n",
      "Epoch: 1/100... Training loss: 0.2721\n",
      "Epoch: 1/100... Training loss: 0.2686\n",
      "Epoch: 1/100... Training loss: 0.2652\n",
      "Epoch: 1/100... Training loss: 0.2735\n",
      "Epoch: 1/100... Training loss: 0.2662\n",
      "Epoch: 1/100... Training loss: 0.2726\n",
      "Epoch: 1/100... Training loss: 0.2587\n",
      "Epoch: 1/100... Training loss: 0.2708\n",
      "Epoch: 1/100... Training loss: 0.2617\n",
      "Epoch: 1/100... Training loss: 0.2672\n",
      "Epoch: 1/100... Training loss: 0.2642\n",
      "Epoch: 1/100... Training loss: 0.2657\n",
      "Epoch: 1/100... Training loss: 0.2644\n",
      "Epoch: 1/100... Training loss: 0.2683\n",
      "Epoch: 1/100... Training loss: 0.2589\n",
      "Epoch: 1/100... Training loss: 0.2667\n",
      "Epoch: 1/100... Training loss: 0.2643\n",
      "Epoch: 1/100... Training loss: 0.2555\n",
      "Epoch: 1/100... Training loss: 0.2556\n",
      "Epoch: 1/100... Training loss: 0.2489\n",
      "Epoch: 1/100... Training loss: 0.2577\n",
      "Epoch: 1/100... Training loss: 0.2492\n",
      "Epoch: 1/100... Training loss: 0.2540\n",
      "Epoch: 1/100... Training loss: 0.2490\n",
      "Epoch: 1/100... Training loss: 0.2522\n",
      "Epoch: 1/100... Training loss: 0.2420\n",
      "Epoch: 1/100... Training loss: 0.2427\n",
      "Epoch: 1/100... Training loss: 0.2468\n",
      "Epoch: 1/100... Training loss: 0.2401\n",
      "Epoch: 1/100... Training loss: 0.2527\n",
      "Epoch: 1/100... Training loss: 0.2450\n",
      "Epoch: 1/100... Training loss: 0.2392\n",
      "Epoch: 1/100... Training loss: 0.2401\n",
      "Epoch: 1/100... Training loss: 0.2400\n",
      "Epoch: 1/100... Training loss: 0.2381\n",
      "Epoch: 1/100... Training loss: 0.2344\n",
      "Epoch: 1/100... Training loss: 0.2401\n",
      "Epoch: 1/100... Training loss: 0.2374\n",
      "Epoch: 1/100... Training loss: 0.2370\n",
      "Epoch: 1/100... Training loss: 0.2352\n",
      "Epoch: 1/100... Training loss: 0.2292\n",
      "Epoch: 1/100... Training loss: 0.2331\n",
      "Epoch: 1/100... Training loss: 0.2316\n",
      "Epoch: 1/100... Training loss: 0.2312\n",
      "Epoch: 1/100... Training loss: 0.2323\n",
      "Epoch: 1/100... Training loss: 0.2243\n",
      "Epoch: 1/100... Training loss: 0.2254\n",
      "Epoch: 1/100... Training loss: 0.2221\n",
      "Epoch: 1/100... Training loss: 0.2279\n",
      "Epoch: 1/100... Training loss: 0.2206\n",
      "Epoch: 1/100... Training loss: 0.2289\n",
      "Epoch: 1/100... Training loss: 0.2217\n",
      "Epoch: 1/100... Training loss: 0.2218\n",
      "Epoch: 1/100... Training loss: 0.2232\n",
      "Epoch: 1/100... Training loss: 0.2240\n",
      "Epoch: 1/100... Training loss: 0.2216\n",
      "Epoch: 1/100... Training loss: 0.2193\n",
      "Epoch: 1/100... Training loss: 0.2245\n",
      "Epoch: 1/100... Training loss: 0.2133\n",
      "Epoch: 1/100... Training loss: 0.2223\n",
      "Epoch: 1/100... Training loss: 0.2231\n",
      "Epoch: 1/100... Training loss: 0.2151\n",
      "Epoch: 1/100... Training loss: 0.2260\n",
      "Epoch: 1/100... Training loss: 0.2179\n",
      "Epoch: 1/100... Training loss: 0.2153\n",
      "Epoch: 1/100... Training loss: 0.2163\n",
      "Epoch: 1/100... Training loss: 0.2265\n",
      "Epoch: 1/100... Training loss: 0.2141\n",
      "Epoch: 1/100... Training loss: 0.2171\n",
      "Epoch: 1/100... Training loss: 0.2087\n",
      "Epoch: 1/100... Training loss: 0.2215\n",
      "Epoch: 1/100... Training loss: 0.2202\n",
      "Epoch: 1/100... Training loss: 0.2121\n",
      "Epoch: 1/100... Training loss: 0.2147\n",
      "Epoch: 1/100... Training loss: 0.2068\n",
      "Epoch: 1/100... Training loss: 0.2113\n",
      "Epoch: 1/100... Training loss: 0.2038\n",
      "Epoch: 1/100... Training loss: 0.2036\n",
      "Epoch: 1/100... Training loss: 0.2070\n",
      "Epoch: 1/100... Training loss: 0.2031\n",
      "Epoch: 1/100... Training loss: 0.2058\n",
      "Epoch: 1/100... Training loss: 0.2118\n",
      "Epoch: 1/100... Training loss: 0.2085\n",
      "Epoch: 1/100... Training loss: 0.2036\n",
      "Epoch: 1/100... Training loss: 0.2021\n",
      "Epoch: 1/100... Training loss: 0.2011\n",
      "Epoch: 1/100... Training loss: 0.2045\n",
      "Epoch: 1/100... Training loss: 0.2041\n",
      "Epoch: 1/100... Training loss: 0.2037\n",
      "Epoch: 1/100... Training loss: 0.2066\n",
      "Epoch: 1/100... Training loss: 0.2021\n",
      "Epoch: 1/100... Training loss: 0.2063\n",
      "Epoch: 1/100... Training loss: 0.1994\n",
      "Epoch: 1/100... Training loss: 0.1994\n",
      "Epoch: 1/100... Training loss: 0.2041\n",
      "Epoch: 1/100... Training loss: 0.1971\n",
      "Epoch: 1/100... Training loss: 0.2034\n",
      "Epoch: 1/100... Training loss: 0.2036\n",
      "Epoch: 1/100... Training loss: 0.1988\n",
      "Epoch: 1/100... Training loss: 0.1952\n",
      "Epoch: 1/100... Training loss: 0.2079\n",
      "Epoch: 1/100... Training loss: 0.1965\n",
      "Epoch: 1/100... Training loss: 0.1966\n",
      "Epoch: 1/100... Training loss: 0.2008\n",
      "Epoch: 1/100... Training loss: 0.1954\n",
      "Epoch: 1/100... Training loss: 0.1962\n",
      "Epoch: 1/100... Training loss: 0.1952\n",
      "Epoch: 1/100... Training loss: 0.1946\n",
      "Epoch: 1/100... Training loss: 0.1991\n",
      "Epoch: 1/100... Training loss: 0.1958\n",
      "Epoch: 1/100... Training loss: 0.1980\n",
      "Epoch: 1/100... Training loss: 0.1939\n",
      "Epoch: 1/100... Training loss: 0.1939\n",
      "Epoch: 1/100... Training loss: 0.1983\n",
      "Epoch: 1/100... Training loss: 0.1952\n",
      "Epoch: 1/100... Training loss: 0.1935\n",
      "Epoch: 1/100... Training loss: 0.1945\n",
      "Epoch: 1/100... Training loss: 0.1864\n",
      "Epoch: 1/100... Training loss: 0.1960\n",
      "Epoch: 1/100... Training loss: 0.2003\n",
      "Epoch: 1/100... Training loss: 0.1909\n",
      "Epoch: 1/100... Training loss: 0.1946\n",
      "Epoch: 1/100... Training loss: 0.1966\n",
      "Epoch: 1/100... Training loss: 0.1898\n",
      "Epoch: 1/100... Training loss: 0.1925\n",
      "Epoch: 1/100... Training loss: 0.1906\n",
      "Epoch: 1/100... Training loss: 0.1873\n",
      "Epoch: 1/100... Training loss: 0.1897\n",
      "Epoch: 1/100... Training loss: 0.1828\n",
      "Epoch: 1/100... Training loss: 0.1903\n",
      "Epoch: 1/100... Training loss: 0.1890\n",
      "Epoch: 1/100... Training loss: 0.1933\n",
      "Epoch: 1/100... Training loss: 0.1944\n",
      "Epoch: 1/100... Training loss: 0.1868\n",
      "Epoch: 1/100... Training loss: 0.1968\n",
      "Epoch: 1/100... Training loss: 0.1840\n",
      "Epoch: 1/100... Training loss: 0.1824\n",
      "Epoch: 1/100... Training loss: 0.1887\n",
      "Epoch: 1/100... Training loss: 0.1856\n",
      "Epoch: 1/100... Training loss: 0.1873\n",
      "Epoch: 1/100... Training loss: 0.1855\n",
      "Epoch: 1/100... Training loss: 0.1848\n",
      "Epoch: 1/100... Training loss: 0.1865\n",
      "Epoch: 1/100... Training loss: 0.1884\n",
      "Epoch: 1/100... Training loss: 0.1939\n",
      "Epoch: 1/100... Training loss: 0.1884\n",
      "Epoch: 1/100... Training loss: 0.1880\n",
      "Epoch: 1/100... Training loss: 0.1923\n",
      "Epoch: 1/100... Training loss: 0.1891\n",
      "Epoch: 1/100... Training loss: 0.1876\n",
      "Epoch: 1/100... Training loss: 0.1816\n",
      "Epoch: 1/100... Training loss: 0.1876\n",
      "Epoch: 1/100... Training loss: 0.1859\n",
      "Epoch: 1/100... Training loss: 0.1886\n",
      "Epoch: 1/100... Training loss: 0.1823\n",
      "Epoch: 1/100... Training loss: 0.1843\n",
      "Epoch: 1/100... Training loss: 0.1846\n",
      "Epoch: 1/100... Training loss: 0.1803\n",
      "Epoch: 1/100... Training loss: 0.1839\n",
      "Epoch: 1/100... Training loss: 0.1838\n",
      "Epoch: 1/100... Training loss: 0.1843\n",
      "Epoch: 1/100... Training loss: 0.1881\n",
      "Epoch: 1/100... Training loss: 0.1898\n",
      "Epoch: 1/100... Training loss: 0.1789\n",
      "Epoch: 1/100... Training loss: 0.1855\n",
      "Epoch: 1/100... Training loss: 0.1845\n",
      "Epoch: 1/100... Training loss: 0.1895\n",
      "Epoch: 1/100... Training loss: 0.1816\n",
      "Epoch: 1/100... Training loss: 0.1830\n",
      "Epoch: 1/100... Training loss: 0.1791\n",
      "Epoch: 1/100... Training loss: 0.1866\n",
      "Epoch: 1/100... Training loss: 0.1856\n",
      "Epoch: 1/100... Training loss: 0.1809\n",
      "Epoch: 1/100... Training loss: 0.1856\n",
      "Epoch: 1/100... Training loss: 0.1790\n",
      "Epoch: 1/100... Training loss: 0.1809\n",
      "Epoch: 1/100... Training loss: 0.1803\n",
      "Epoch: 1/100... Training loss: 0.1768\n",
      "Epoch: 1/100... Training loss: 0.1765\n",
      "Epoch: 1/100... Training loss: 0.1848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Training loss: 0.1785\n",
      "Epoch: 1/100... Training loss: 0.1754\n",
      "Epoch: 1/100... Training loss: 0.1816\n",
      "Epoch: 1/100... Training loss: 0.1784\n",
      "Epoch: 1/100... Training loss: 0.1807\n",
      "Epoch: 1/100... Training loss: 0.1693\n",
      "Epoch: 1/100... Training loss: 0.1744\n",
      "Epoch: 1/100... Training loss: 0.1791\n",
      "Epoch: 1/100... Training loss: 0.1737\n",
      "Epoch: 1/100... Training loss: 0.1771\n",
      "Epoch: 1/100... Training loss: 0.1763\n",
      "Epoch: 1/100... Training loss: 0.1742\n",
      "Epoch: 1/100... Training loss: 0.1808\n",
      "Epoch: 1/100... Training loss: 0.1711\n",
      "Epoch: 1/100... Training loss: 0.1775\n",
      "Epoch: 1/100... Training loss: 0.1765\n",
      "Epoch: 1/100... Training loss: 0.1787\n",
      "Epoch: 1/100... Training loss: 0.1769\n",
      "Epoch: 1/100... Training loss: 0.1761\n",
      "Epoch: 1/100... Training loss: 0.1771\n",
      "Epoch: 1/100... Training loss: 0.1748\n",
      "Epoch: 1/100... Training loss: 0.1785\n",
      "Epoch: 1/100... Training loss: 0.1716\n",
      "Epoch: 1/100... Training loss: 0.1741\n",
      "Epoch: 1/100... Training loss: 0.1694\n",
      "Epoch: 1/100... Training loss: 0.1721\n",
      "Epoch: 1/100... Training loss: 0.1715\n",
      "Epoch: 1/100... Training loss: 0.1719\n",
      "Epoch: 1/100... Training loss: 0.1677\n",
      "Epoch: 1/100... Training loss: 0.1780\n",
      "Epoch: 1/100... Training loss: 0.1685\n",
      "Epoch: 1/100... Training loss: 0.1752\n",
      "Epoch: 1/100... Training loss: 0.1701\n",
      "Epoch: 1/100... Training loss: 0.1720\n",
      "Epoch: 1/100... Training loss: 0.1687\n",
      "Epoch: 1/100... Training loss: 0.1654\n",
      "Epoch: 1/100... Training loss: 0.1744\n",
      "Epoch: 1/100... Training loss: 0.1775\n",
      "Epoch: 1/100... Training loss: 0.1750\n",
      "Epoch: 1/100... Training loss: 0.1680\n",
      "Epoch: 1/100... Training loss: 0.1678\n",
      "Epoch: 1/100... Training loss: 0.1742\n",
      "Epoch: 1/100... Training loss: 0.1679\n",
      "Epoch: 1/100... Training loss: 0.1712\n",
      "Epoch: 1/100... Training loss: 0.1745\n",
      "Epoch: 1/100... Training loss: 0.1680\n",
      "Epoch: 1/100... Training loss: 0.1717\n",
      "Epoch: 1/100... Training loss: 0.1738\n",
      "Epoch: 1/100... Training loss: 0.1664\n",
      "Epoch: 1/100... Training loss: 0.1679\n",
      "Epoch: 1/100... Training loss: 0.1667\n",
      "Epoch: 1/100... Training loss: 0.1696\n",
      "Epoch: 1/100... Training loss: 0.1686\n",
      "Epoch: 1/100... Training loss: 0.1672\n",
      "Epoch: 1/100... Training loss: 0.1716\n",
      "Epoch: 1/100... Training loss: 0.1626\n",
      "Epoch: 1/100... Training loss: 0.1698\n",
      "Epoch: 1/100... Training loss: 0.1707\n",
      "Epoch: 1/100... Training loss: 0.1630\n",
      "Epoch: 1/100... Training loss: 0.1695\n",
      "Epoch: 1/100... Training loss: 0.1739\n",
      "Epoch: 1/100... Training loss: 0.1612\n",
      "Epoch: 1/100... Training loss: 0.1734\n",
      "Epoch: 1/100... Training loss: 0.1657\n",
      "Epoch: 1/100... Training loss: 0.1680\n",
      "Epoch: 1/100... Training loss: 0.1687\n",
      "Epoch: 1/100... Training loss: 0.1631\n",
      "Epoch: 1/100... Training loss: 0.1685\n",
      "Epoch: 1/100... Training loss: 0.1694\n",
      "Epoch: 1/100... Training loss: 0.1694\n",
      "Epoch: 1/100... Training loss: 0.1620\n",
      "Epoch: 1/100... Training loss: 0.1705\n",
      "Epoch: 1/100... Training loss: 0.1647\n",
      "Epoch: 1/100... Training loss: 0.1626\n",
      "Epoch: 1/100... Training loss: 0.1607\n",
      "Epoch: 1/100... Training loss: 0.1577\n",
      "Epoch: 1/100... Training loss: 0.1671\n",
      "Epoch: 1/100... Training loss: 0.1652\n",
      "Epoch: 1/100... Training loss: 0.1668\n",
      "Epoch: 2/100... Training loss: 0.1652\n",
      "Epoch: 2/100... Training loss: 0.1633\n",
      "Epoch: 2/100... Training loss: 0.1657\n",
      "Epoch: 2/100... Training loss: 0.1644\n",
      "Epoch: 2/100... Training loss: 0.1660\n",
      "Epoch: 2/100... Training loss: 0.1681\n",
      "Epoch: 2/100... Training loss: 0.1612\n",
      "Epoch: 2/100... Training loss: 0.1726\n",
      "Epoch: 2/100... Training loss: 0.1665\n",
      "Epoch: 2/100... Training loss: 0.1623\n",
      "Epoch: 2/100... Training loss: 0.1680\n",
      "Epoch: 2/100... Training loss: 0.1568\n",
      "Epoch: 2/100... Training loss: 0.1574\n",
      "Epoch: 2/100... Training loss: 0.1638\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1652\n",
      "Epoch: 2/100... Training loss: 0.1617\n",
      "Epoch: 2/100... Training loss: 0.1612\n",
      "Epoch: 2/100... Training loss: 0.1645\n",
      "Epoch: 2/100... Training loss: 0.1687\n",
      "Epoch: 2/100... Training loss: 0.1615\n",
      "Epoch: 2/100... Training loss: 0.1647\n",
      "Epoch: 2/100... Training loss: 0.1576\n",
      "Epoch: 2/100... Training loss: 0.1565\n",
      "Epoch: 2/100... Training loss: 0.1605\n",
      "Epoch: 2/100... Training loss: 0.1580\n",
      "Epoch: 2/100... Training loss: 0.1566\n",
      "Epoch: 2/100... Training loss: 0.1645\n",
      "Epoch: 2/100... Training loss: 0.1591\n",
      "Epoch: 2/100... Training loss: 0.1550\n",
      "Epoch: 2/100... Training loss: 0.1594\n",
      "Epoch: 2/100... Training loss: 0.1671\n",
      "Epoch: 2/100... Training loss: 0.1615\n",
      "Epoch: 2/100... Training loss: 0.1536\n",
      "Epoch: 2/100... Training loss: 0.1642\n",
      "Epoch: 2/100... Training loss: 0.1655\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1566\n",
      "Epoch: 2/100... Training loss: 0.1611\n",
      "Epoch: 2/100... Training loss: 0.1556\n",
      "Epoch: 2/100... Training loss: 0.1568\n",
      "Epoch: 2/100... Training loss: 0.1610\n",
      "Epoch: 2/100... Training loss: 0.1556\n",
      "Epoch: 2/100... Training loss: 0.1596\n",
      "Epoch: 2/100... Training loss: 0.1617\n",
      "Epoch: 2/100... Training loss: 0.1580\n",
      "Epoch: 2/100... Training loss: 0.1557\n",
      "Epoch: 2/100... Training loss: 0.1565\n",
      "Epoch: 2/100... Training loss: 0.1566\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1619\n",
      "Epoch: 2/100... Training loss: 0.1572\n",
      "Epoch: 2/100... Training loss: 0.1563\n",
      "Epoch: 2/100... Training loss: 0.1563\n",
      "Epoch: 2/100... Training loss: 0.1558\n",
      "Epoch: 2/100... Training loss: 0.1627\n",
      "Epoch: 2/100... Training loss: 0.1619\n",
      "Epoch: 2/100... Training loss: 0.1536\n",
      "Epoch: 2/100... Training loss: 0.1537\n",
      "Epoch: 2/100... Training loss: 0.1546\n",
      "Epoch: 2/100... Training loss: 0.1542\n",
      "Epoch: 2/100... Training loss: 0.1537\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1566\n",
      "Epoch: 2/100... Training loss: 0.1592\n",
      "Epoch: 2/100... Training loss: 0.1530\n",
      "Epoch: 2/100... Training loss: 0.1547\n",
      "Epoch: 2/100... Training loss: 0.1562\n",
      "Epoch: 2/100... Training loss: 0.1580\n",
      "Epoch: 2/100... Training loss: 0.1561\n",
      "Epoch: 2/100... Training loss: 0.1596\n",
      "Epoch: 2/100... Training loss: 0.1589\n",
      "Epoch: 2/100... Training loss: 0.1544\n",
      "Epoch: 2/100... Training loss: 0.1542\n",
      "Epoch: 2/100... Training loss: 0.1602\n",
      "Epoch: 2/100... Training loss: 0.1611\n",
      "Epoch: 2/100... Training loss: 0.1541\n",
      "Epoch: 2/100... Training loss: 0.1535\n",
      "Epoch: 2/100... Training loss: 0.1552\n",
      "Epoch: 2/100... Training loss: 0.1546\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1534\n",
      "Epoch: 2/100... Training loss: 0.1546\n",
      "Epoch: 2/100... Training loss: 0.1541\n",
      "Epoch: 2/100... Training loss: 0.1563\n",
      "Epoch: 2/100... Training loss: 0.1585\n",
      "Epoch: 2/100... Training loss: 0.1512\n",
      "Epoch: 2/100... Training loss: 0.1588\n",
      "Epoch: 2/100... Training loss: 0.1599\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1601\n",
      "Epoch: 2/100... Training loss: 0.1567\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1588\n",
      "Epoch: 2/100... Training loss: 0.1569\n",
      "Epoch: 2/100... Training loss: 0.1570\n",
      "Epoch: 2/100... Training loss: 0.1548\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1530\n",
      "Epoch: 2/100... Training loss: 0.1522\n",
      "Epoch: 2/100... Training loss: 0.1567\n",
      "Epoch: 2/100... Training loss: 0.1541\n",
      "Epoch: 2/100... Training loss: 0.1514\n",
      "Epoch: 2/100... Training loss: 0.1474\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1558\n",
      "Epoch: 2/100... Training loss: 0.1488\n",
      "Epoch: 2/100... Training loss: 0.1553\n",
      "Epoch: 2/100... Training loss: 0.1566\n",
      "Epoch: 2/100... Training loss: 0.1471\n",
      "Epoch: 2/100... Training loss: 0.1518\n",
      "Epoch: 2/100... Training loss: 0.1538\n",
      "Epoch: 2/100... Training loss: 0.1534\n",
      "Epoch: 2/100... Training loss: 0.1511\n",
      "Epoch: 2/100... Training loss: 0.1511\n",
      "Epoch: 2/100... Training loss: 0.1492\n",
      "Epoch: 2/100... Training loss: 0.1511\n",
      "Epoch: 2/100... Training loss: 0.1550\n",
      "Epoch: 2/100... Training loss: 0.1535\n",
      "Epoch: 2/100... Training loss: 0.1501\n",
      "Epoch: 2/100... Training loss: 0.1531\n",
      "Epoch: 2/100... Training loss: 0.1530\n",
      "Epoch: 2/100... Training loss: 0.1514\n",
      "Epoch: 2/100... Training loss: 0.1516\n",
      "Epoch: 2/100... Training loss: 0.1536\n",
      "Epoch: 2/100... Training loss: 0.1455\n",
      "Epoch: 2/100... Training loss: 0.1470\n",
      "Epoch: 2/100... Training loss: 0.1509\n",
      "Epoch: 2/100... Training loss: 0.1479\n",
      "Epoch: 2/100... Training loss: 0.1528\n",
      "Epoch: 2/100... Training loss: 0.1565\n",
      "Epoch: 2/100... Training loss: 0.1495\n",
      "Epoch: 2/100... Training loss: 0.1466\n",
      "Epoch: 2/100... Training loss: 0.1561\n",
      "Epoch: 2/100... Training loss: 0.1501\n",
      "Epoch: 2/100... Training loss: 0.1519\n",
      "Epoch: 2/100... Training loss: 0.1505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100... Training loss: 0.1511\n",
      "Epoch: 2/100... Training loss: 0.1496\n",
      "Epoch: 2/100... Training loss: 0.1515\n",
      "Epoch: 2/100... Training loss: 0.1534\n",
      "Epoch: 2/100... Training loss: 0.1483\n",
      "Epoch: 2/100... Training loss: 0.1485\n",
      "Epoch: 2/100... Training loss: 0.1499\n",
      "Epoch: 2/100... Training loss: 0.1557\n",
      "Epoch: 2/100... Training loss: 0.1498\n",
      "Epoch: 2/100... Training loss: 0.1554\n",
      "Epoch: 2/100... Training loss: 0.1545\n",
      "Epoch: 2/100... Training loss: 0.1457\n",
      "Epoch: 2/100... Training loss: 0.1477\n",
      "Epoch: 2/100... Training loss: 0.1478\n",
      "Epoch: 2/100... Training loss: 0.1486\n",
      "Epoch: 2/100... Training loss: 0.1478\n",
      "Epoch: 2/100... Training loss: 0.1468\n",
      "Epoch: 2/100... Training loss: 0.1493\n",
      "Epoch: 2/100... Training loss: 0.1498\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1507\n",
      "Epoch: 2/100... Training loss: 0.1467\n",
      "Epoch: 2/100... Training loss: 0.1510\n",
      "Epoch: 2/100... Training loss: 0.1475\n",
      "Epoch: 2/100... Training loss: 0.1484\n",
      "Epoch: 2/100... Training loss: 0.1479\n",
      "Epoch: 2/100... Training loss: 0.1488\n",
      "Epoch: 2/100... Training loss: 0.1500\n",
      "Epoch: 2/100... Training loss: 0.1505\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1518\n",
      "Epoch: 2/100... Training loss: 0.1496\n",
      "Epoch: 2/100... Training loss: 0.1448\n",
      "Epoch: 2/100... Training loss: 0.1466\n",
      "Epoch: 2/100... Training loss: 0.1453\n",
      "Epoch: 2/100... Training loss: 0.1474\n",
      "Epoch: 2/100... Training loss: 0.1474\n",
      "Epoch: 2/100... Training loss: 0.1500\n",
      "Epoch: 2/100... Training loss: 0.1497\n",
      "Epoch: 2/100... Training loss: 0.1463\n",
      "Epoch: 2/100... Training loss: 0.1476\n",
      "Epoch: 2/100... Training loss: 0.1526\n",
      "Epoch: 2/100... Training loss: 0.1441\n",
      "Epoch: 2/100... Training loss: 0.1473\n",
      "Epoch: 2/100... Training loss: 0.1476\n",
      "Epoch: 2/100... Training loss: 0.1464\n",
      "Epoch: 2/100... Training loss: 0.1459\n",
      "Epoch: 2/100... Training loss: 0.1504\n",
      "Epoch: 2/100... Training loss: 0.1520\n",
      "Epoch: 2/100... Training loss: 0.1452\n",
      "Epoch: 2/100... Training loss: 0.1473\n",
      "Epoch: 2/100... Training loss: 0.1472\n",
      "Epoch: 2/100... Training loss: 0.1456\n",
      "Epoch: 2/100... Training loss: 0.1460\n",
      "Epoch: 2/100... Training loss: 0.1472\n",
      "Epoch: 2/100... Training loss: 0.1463\n",
      "Epoch: 2/100... Training loss: 0.1448\n",
      "Epoch: 2/100... Training loss: 0.1454\n",
      "Epoch: 2/100... Training loss: 0.1461\n",
      "Epoch: 2/100... Training loss: 0.1434\n",
      "Epoch: 2/100... Training loss: 0.1460\n",
      "Epoch: 2/100... Training loss: 0.1464\n",
      "Epoch: 2/100... Training loss: 0.1452\n",
      "Epoch: 2/100... Training loss: 0.1419\n",
      "Epoch: 2/100... Training loss: 0.1434\n",
      "Epoch: 2/100... Training loss: 0.1417\n",
      "Epoch: 2/100... Training loss: 0.1459\n",
      "Epoch: 2/100... Training loss: 0.1475\n",
      "Epoch: 2/100... Training loss: 0.1450\n",
      "Epoch: 2/100... Training loss: 0.1404\n",
      "Epoch: 2/100... Training loss: 0.1417\n",
      "Epoch: 2/100... Training loss: 0.1452\n",
      "Epoch: 2/100... Training loss: 0.1485\n",
      "Epoch: 2/100... Training loss: 0.1473\n",
      "Epoch: 2/100... Training loss: 0.1452\n",
      "Epoch: 2/100... Training loss: 0.1397\n",
      "Epoch: 2/100... Training loss: 0.1452\n",
      "Epoch: 2/100... Training loss: 0.1486\n",
      "Epoch: 2/100... Training loss: 0.1470\n",
      "Epoch: 2/100... Training loss: 0.1477\n",
      "Epoch: 2/100... Training loss: 0.1522\n",
      "Epoch: 2/100... Training loss: 0.1487\n",
      "Epoch: 2/100... Training loss: 0.1431\n",
      "Epoch: 2/100... Training loss: 0.1463\n",
      "Epoch: 2/100... Training loss: 0.1428\n",
      "Epoch: 2/100... Training loss: 0.1417\n",
      "Epoch: 2/100... Training loss: 0.1388\n",
      "Epoch: 2/100... Training loss: 0.1423\n",
      "Epoch: 2/100... Training loss: 0.1416\n",
      "Epoch: 2/100... Training loss: 0.1474\n",
      "Epoch: 2/100... Training loss: 0.1470\n",
      "Epoch: 2/100... Training loss: 0.1417\n",
      "Epoch: 2/100... Training loss: 0.1430\n",
      "Epoch: 2/100... Training loss: 0.1451\n",
      "Epoch: 2/100... Training loss: 0.1460\n",
      "Epoch: 2/100... Training loss: 0.1466\n",
      "Epoch: 2/100... Training loss: 0.1453\n",
      "Epoch: 2/100... Training loss: 0.1390\n",
      "Epoch: 2/100... Training loss: 0.1422\n",
      "Epoch: 2/100... Training loss: 0.1469\n",
      "Epoch: 2/100... Training loss: 0.1457\n",
      "Epoch: 2/100... Training loss: 0.1441\n",
      "Epoch: 2/100... Training loss: 0.1462\n",
      "Epoch: 2/100... Training loss: 0.1427\n",
      "Epoch: 2/100... Training loss: 0.1433\n",
      "Epoch: 2/100... Training loss: 0.1418\n",
      "Epoch: 2/100... Training loss: 0.1421\n",
      "Epoch: 2/100... Training loss: 0.1470\n",
      "Epoch: 2/100... Training loss: 0.1477\n",
      "Epoch: 2/100... Training loss: 0.1418\n",
      "Epoch: 2/100... Training loss: 0.1427\n",
      "Epoch: 2/100... Training loss: 0.1421\n",
      "Epoch: 2/100... Training loss: 0.1405\n",
      "Epoch: 2/100... Training loss: 0.1408\n",
      "Epoch: 2/100... Training loss: 0.1425\n",
      "Epoch: 2/100... Training loss: 0.1385\n",
      "Epoch: 2/100... Training loss: 0.1408\n",
      "Epoch: 2/100... Training loss: 0.1385\n",
      "Epoch: 2/100... Training loss: 0.1441\n",
      "Epoch: 2/100... Training loss: 0.1429\n",
      "Epoch: 2/100... Training loss: 0.1424\n",
      "Epoch: 2/100... Training loss: 0.1425\n",
      "Epoch: 2/100... Training loss: 0.1460\n",
      "Epoch: 2/100... Training loss: 0.1472\n",
      "Epoch: 2/100... Training loss: 0.1403\n",
      "Epoch: 2/100... Training loss: 0.1416\n",
      "Epoch: 2/100... Training loss: 0.1398\n",
      "Epoch: 2/100... Training loss: 0.1434\n",
      "Epoch: 2/100... Training loss: 0.1390\n",
      "Epoch: 2/100... Training loss: 0.1364\n",
      "Epoch: 2/100... Training loss: 0.1443\n",
      "Epoch: 2/100... Training loss: 0.1429\n",
      "Epoch: 2/100... Training loss: 0.1403\n",
      "Epoch: 2/100... Training loss: 0.1419\n",
      "Epoch: 2/100... Training loss: 0.1399\n",
      "Epoch: 2/100... Training loss: 0.1388\n",
      "Epoch: 2/100... Training loss: 0.1415\n",
      "Epoch: 2/100... Training loss: 0.1487\n",
      "Epoch: 2/100... Training loss: 0.1432\n",
      "Epoch: 2/100... Training loss: 0.1461\n",
      "Epoch: 2/100... Training loss: 0.1359\n",
      "Epoch: 2/100... Training loss: 0.1378\n",
      "Epoch: 2/100... Training loss: 0.1386\n",
      "Epoch: 2/100... Training loss: 0.1437\n",
      "Epoch: 2/100... Training loss: 0.1399\n",
      "Epoch: 2/100... Training loss: 0.1439\n",
      "Epoch: 2/100... Training loss: 0.1421\n",
      "Epoch: 2/100... Training loss: 0.1447\n",
      "Epoch: 2/100... Training loss: 0.1409\n",
      "Epoch: 2/100... Training loss: 0.1411\n",
      "Epoch: 2/100... Training loss: 0.1393\n",
      "Epoch: 2/100... Training loss: 0.1395\n",
      "Epoch: 2/100... Training loss: 0.1413\n",
      "Epoch: 2/100... Training loss: 0.1411\n",
      "Epoch: 2/100... Training loss: 0.1426\n",
      "Epoch: 2/100... Training loss: 0.1381\n",
      "Epoch: 2/100... Training loss: 0.1427\n",
      "Epoch: 2/100... Training loss: 0.1403\n",
      "Epoch: 2/100... Training loss: 0.1417\n",
      "Epoch: 2/100... Training loss: 0.1374\n",
      "Epoch: 2/100... Training loss: 0.1437\n",
      "Epoch: 2/100... Training loss: 0.1445\n",
      "Epoch: 3/100... Training loss: 0.1440\n",
      "Epoch: 3/100... Training loss: 0.1355\n",
      "Epoch: 3/100... Training loss: 0.1431\n",
      "Epoch: 3/100... Training loss: 0.1435\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1383\n",
      "Epoch: 3/100... Training loss: 0.1460\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1439\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1426\n",
      "Epoch: 3/100... Training loss: 0.1422\n",
      "Epoch: 3/100... Training loss: 0.1400\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1390\n",
      "Epoch: 3/100... Training loss: 0.1402\n",
      "Epoch: 3/100... Training loss: 0.1425\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1408\n",
      "Epoch: 3/100... Training loss: 0.1470\n",
      "Epoch: 3/100... Training loss: 0.1448\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1428\n",
      "Epoch: 3/100... Training loss: 0.1391\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1436\n",
      "Epoch: 3/100... Training loss: 0.1400\n",
      "Epoch: 3/100... Training loss: 0.1415\n",
      "Epoch: 3/100... Training loss: 0.1388\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1377\n",
      "Epoch: 3/100... Training loss: 0.1374\n",
      "Epoch: 3/100... Training loss: 0.1377\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1426\n",
      "Epoch: 3/100... Training loss: 0.1426\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1370\n",
      "Epoch: 3/100... Training loss: 0.1400\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1423\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1398\n",
      "Epoch: 3/100... Training loss: 0.1374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1399\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1354\n",
      "Epoch: 3/100... Training loss: 0.1400\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1352\n",
      "Epoch: 3/100... Training loss: 0.1408\n",
      "Epoch: 3/100... Training loss: 0.1423\n",
      "Epoch: 3/100... Training loss: 0.1382\n",
      "Epoch: 3/100... Training loss: 0.1379\n",
      "Epoch: 3/100... Training loss: 0.1431\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1402\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1406\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1352\n",
      "Epoch: 3/100... Training loss: 0.1334\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1391\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1375\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1375\n",
      "Epoch: 3/100... Training loss: 0.1388\n",
      "Epoch: 3/100... Training loss: 0.1382\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1362\n",
      "Epoch: 3/100... Training loss: 0.1383\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1374\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1391\n",
      "Epoch: 3/100... Training loss: 0.1406\n",
      "Epoch: 3/100... Training loss: 0.1332\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1370\n",
      "Epoch: 3/100... Training loss: 0.1361\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1409\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1354\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1347\n",
      "Epoch: 3/100... Training loss: 0.1411\n",
      "Epoch: 3/100... Training loss: 0.1393\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1327\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1371\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1418\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1368\n",
      "Epoch: 3/100... Training loss: 0.1305\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1354\n",
      "Epoch: 3/100... Training loss: 0.1342\n",
      "Epoch: 3/100... Training loss: 0.1327\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1327\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1343\n",
      "Epoch: 3/100... Training loss: 0.1285\n",
      "Epoch: 3/100... Training loss: 0.1315\n",
      "Epoch: 3/100... Training loss: 0.1343\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1316\n",
      "Epoch: 3/100... Training loss: 0.1379\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1313\n",
      "Epoch: 3/100... Training loss: 0.1339\n",
      "Epoch: 3/100... Training loss: 0.1356\n",
      "Epoch: 3/100... Training loss: 0.1362\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1325\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1365\n",
      "Epoch: 3/100... Training loss: 0.1313\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1352\n",
      "Epoch: 3/100... Training loss: 0.1319\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1303\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1318\n",
      "Epoch: 3/100... Training loss: 0.1336\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1322\n",
      "Epoch: 3/100... Training loss: 0.1314\n",
      "Epoch: 3/100... Training loss: 0.1322\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1368\n",
      "Epoch: 3/100... Training loss: 0.1340\n",
      "Epoch: 3/100... Training loss: 0.1295\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1338\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1299\n",
      "Epoch: 3/100... Training loss: 0.1345\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1301\n",
      "Epoch: 3/100... Training loss: 0.1344\n",
      "Epoch: 3/100... Training loss: 0.1326\n",
      "Epoch: 3/100... Training loss: 0.1319\n",
      "Epoch: 3/100... Training loss: 0.1347\n",
      "Epoch: 3/100... Training loss: 0.1345\n",
      "Epoch: 3/100... Training loss: 0.1320\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1365\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1343\n",
      "Epoch: 3/100... Training loss: 0.1322\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1352\n",
      "Epoch: 3/100... Training loss: 0.1314\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1340\n",
      "Epoch: 3/100... Training loss: 0.1325\n",
      "Epoch: 3/100... Training loss: 0.1288\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1301\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1361\n",
      "Epoch: 3/100... Training loss: 0.1296\n",
      "Epoch: 3/100... Training loss: 0.1274\n",
      "Epoch: 3/100... Training loss: 0.1376\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1344\n",
      "Epoch: 3/100... Training loss: 0.1338\n",
      "Epoch: 3/100... Training loss: 0.1346\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1355\n",
      "Epoch: 3/100... Training loss: 0.1373\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1334\n",
      "Epoch: 3/100... Training loss: 0.1384\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1320\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1278\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1399\n",
      "Epoch: 3/100... Training loss: 0.1356\n",
      "Epoch: 3/100... Training loss: 0.1305\n",
      "Epoch: 3/100... Training loss: 0.1305\n",
      "Epoch: 3/100... Training loss: 0.1315\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1339\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1322\n",
      "Epoch: 3/100... Training loss: 0.1300\n",
      "Epoch: 3/100... Training loss: 0.1306\n",
      "Epoch: 3/100... Training loss: 0.1347\n",
      "Epoch: 3/100... Training loss: 0.1340\n",
      "Epoch: 3/100... Training loss: 0.1307\n",
      "Epoch: 3/100... Training loss: 0.1325\n",
      "Epoch: 3/100... Training loss: 0.1326\n",
      "Epoch: 3/100... Training loss: 0.1320\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1277\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1282\n",
      "Epoch: 3/100... Training loss: 0.1334\n",
      "Epoch: 3/100... Training loss: 0.1315\n",
      "Epoch: 3/100... Training loss: 0.1321\n",
      "Epoch: 3/100... Training loss: 0.1340\n",
      "Epoch: 3/100... Training loss: 0.1324\n",
      "Epoch: 3/100... Training loss: 0.1327\n",
      "Epoch: 3/100... Training loss: 0.1286\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1344\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1322\n",
      "Epoch: 3/100... Training loss: 0.1265\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1310\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100... Training loss: 0.1316\n",
      "Epoch: 3/100... Training loss: 0.1321\n",
      "Epoch: 3/100... Training loss: 0.1311\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1332\n",
      "Epoch: 3/100... Training loss: 0.1344\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1305\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1334\n",
      "Epoch: 3/100... Training loss: 0.1306\n",
      "Epoch: 3/100... Training loss: 0.1307\n",
      "Epoch: 3/100... Training loss: 0.1345\n",
      "Epoch: 3/100... Training loss: 0.1304\n",
      "Epoch: 3/100... Training loss: 0.1325\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1318\n",
      "Epoch: 3/100... Training loss: 0.1328\n",
      "Epoch: 3/100... Training loss: 0.1332\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1318\n",
      "Epoch: 3/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1347\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1331\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1340\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1374\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1373\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1363\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1364\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1328\n",
      "Epoch: 4/100... Training loss: 0.1307\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1348\n",
      "Epoch: 4/100... Training loss: 0.1305\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1276\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1336\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1371\n",
      "Epoch: 4/100... Training loss: 0.1337\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1283\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1331\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1317\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1326\n",
      "Epoch: 4/100... Training loss: 0.1364\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1338\n",
      "Epoch: 4/100... Training loss: 0.1312\n",
      "Epoch: 4/100... Training loss: 0.1261\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1337\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1270\n",
      "Epoch: 4/100... Training loss: 0.1319\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1345\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1327\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1363\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1305\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1256\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1266\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1270\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1255\n",
      "Epoch: 4/100... Training loss: 0.1251\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1276\n",
      "Epoch: 4/100... Training loss: 0.1242\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1276\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1285\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1305\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1246\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1277\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1305\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1328\n",
      "Epoch: 4/100... Training loss: 0.1289\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1289\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1259\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1244\n",
      "Epoch: 4/100... Training loss: 0.1268\n",
      "Epoch: 4/100... Training loss: 0.1267\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1323\n",
      "Epoch: 4/100... Training loss: 0.1250\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1259\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1319\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1268\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1310\n",
      "Epoch: 4/100... Training loss: 0.1251\n",
      "Epoch: 4/100... Training loss: 0.1326\n",
      "Epoch: 4/100... Training loss: 0.1267\n",
      "Epoch: 4/100... Training loss: 0.1310\n",
      "Epoch: 4/100... Training loss: 0.1323\n",
      "Epoch: 4/100... Training loss: 0.1260\n",
      "Epoch: 4/100... Training loss: 0.1277\n",
      "Epoch: 4/100... Training loss: 0.1286\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1265\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1263\n",
      "Epoch: 4/100... Training loss: 0.1307\n",
      "Epoch: 4/100... Training loss: 0.1284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100... Training loss: 0.1257\n",
      "Epoch: 4/100... Training loss: 0.1256\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1245\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1232\n",
      "Epoch: 4/100... Training loss: 0.1342\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1227\n",
      "Epoch: 4/100... Training loss: 0.1242\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1251\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1255\n",
      "Epoch: 4/100... Training loss: 0.1256\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1218\n",
      "Epoch: 4/100... Training loss: 0.1285\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1261\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1284\n",
      "Epoch: 4/100... Training loss: 0.1249\n",
      "Epoch: 4/100... Training loss: 0.1269\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1289\n",
      "Epoch: 4/100... Training loss: 0.1249\n",
      "Epoch: 4/100... Training loss: 0.1220\n",
      "Epoch: 4/100... Training loss: 0.1265\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1265\n",
      "Epoch: 4/100... Training loss: 0.1267\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1275\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1248\n",
      "Epoch: 4/100... Training loss: 0.1257\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1272\n",
      "Epoch: 4/100... Training loss: 0.1268\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1246\n",
      "Epoch: 4/100... Training loss: 0.1266\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1250\n",
      "Epoch: 4/100... Training loss: 0.1261\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1268\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1249\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1263\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1212\n",
      "Epoch: 4/100... Training loss: 0.1253\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1270\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1275\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1257\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1269\n",
      "Epoch: 4/100... Training loss: 0.1249\n",
      "Epoch: 4/100... Training loss: 0.1248\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1259\n",
      "Epoch: 4/100... Training loss: 0.1221\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1270\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1284\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1244\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1308\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1300\n",
      "Epoch: 5/100... Training loss: 0.1232\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1304\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1286\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1302\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1299\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1319\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1284\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1230\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1223\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1287\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1214\n",
      "Epoch: 5/100... Training loss: 0.1316\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1225\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1209\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1337\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1229\n",
      "Epoch: 5/100... Training loss: 0.1302\n",
      "Epoch: 5/100... Training loss: 0.1205\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1229\n",
      "Epoch: 5/100... Training loss: 0.1274\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1227\n",
      "Epoch: 5/100... Training loss: 0.1213\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1216\n",
      "Epoch: 5/100... Training loss: 0.1225\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1189\n",
      "Epoch: 5/100... Training loss: 0.1227\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1317\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1301\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1223\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1295\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1223\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1209\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1194\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1214\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1218\n",
      "Epoch: 5/100... Training loss: 0.1249\n",
      "Epoch: 5/100... Training loss: 0.1222\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1213\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1298\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1205\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1230\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1286\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1202\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1224\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1224\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1210\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1216\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1201\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1202\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1205\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1220\n",
      "Epoch: 5/100... Training loss: 0.1228\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1304\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1213\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1216\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1197\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1289\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1220\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1197\n",
      "Epoch: 5/100... Training loss: 0.1228\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1211\n",
      "Epoch: 5/100... Training loss: 0.1225\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1212\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1209\n",
      "Epoch: 5/100... Training loss: 0.1232\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1210\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1308\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1189\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1194\n",
      "Epoch: 5/100... Training loss: 0.1232\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1184\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1166\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1153\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1186\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1282\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1294\n",
      "Epoch: 6/100... Training loss: 0.1196\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1285\n",
      "Epoch: 6/100... Training loss: 0.1181\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1261\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1185\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1279\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1182\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1247\n",
      "Epoch: 6/100... Training loss: 0.1241\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1254\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1275\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1205\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1203\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1186\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1267\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1232\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1169\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1213\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1225\n",
      "Epoch: 6/100... Training loss: 0.1175\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1232\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1187\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1183\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1183\n",
      "Epoch: 6/100... Training loss: 0.1162\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1245\n",
      "Epoch: 6/100... Training loss: 0.1194\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1159\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1251\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1185\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1213\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1232\n",
      "Epoch: 6/100... Training loss: 0.1170\n",
      "Epoch: 6/100... Training loss: 0.1205\n",
      "Epoch: 6/100... Training loss: 0.1213\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1202\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1175\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1183\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1164\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1193\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1258\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1251\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1178\n",
      "Epoch: 6/100... Training loss: 0.1167\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1166\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1184\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1202\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1179\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1288\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1247\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1203\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1139\n",
      "Epoch: 6/100... Training loss: 0.1181\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1245\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1187\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1177\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1186\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1170\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1169\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1196\n",
      "Epoch: 6/100... Training loss: 0.1190\n",
      "Epoch: 6/100... Training loss: 0.1189\n",
      "Epoch: 6/100... Training loss: 0.1185\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1182\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1159\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1181\n",
      "Epoch: 6/100... Training loss: 0.1198\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1247\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1219\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1226\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1183\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1218\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1127\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1223\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1257\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1170\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1163\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1154\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1242\n",
      "Epoch: 7/100... Training loss: 0.1168\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1176\n",
      "Epoch: 7/100... Training loss: 0.1229\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1245\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1149\n",
      "Epoch: 7/100... Training loss: 0.1176\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1159\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1168\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1136\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1162\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1166\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1160\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1167\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1164\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1184\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1168\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1152\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1229\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1253\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1148\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1155\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1145\n",
      "Epoch: 7/100... Training loss: 0.1144\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1124\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1157\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1141\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1166\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1164\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1136\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1155\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1176\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1147\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1135\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1143\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1242\n",
      "Epoch: 7/100... Training loss: 0.1184\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1159\n",
      "Epoch: 7/100... Training loss: 0.1148\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1234\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1129\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1218\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1144\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1124\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1242\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1225\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1157\n",
      "Epoch: 8/100... Training loss: 0.1119\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1103\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1206\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1225\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1210\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1141\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1227\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1210\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1216\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1182\n",
      "Epoch: 8/100... Training loss: 0.1212\n",
      "Epoch: 8/100... Training loss: 0.1139\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1228\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1215\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1139\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1170\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1140\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1206\n",
      "Epoch: 8/100... Training loss: 0.1217\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1102\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1121\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1124\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1138\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1121\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1135\n",
      "Epoch: 8/100... Training loss: 0.1157\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1131\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1222\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1151\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1136\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1138\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1120\n",
      "Epoch: 8/100... Training loss: 0.1106\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1182\n",
      "Epoch: 8/100... Training loss: 0.1134\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1151\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1142\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1216\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1216\n",
      "Epoch: 8/100... Training loss: 0.1133\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1128\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1157\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1159\n",
      "Epoch: 8/100... Training loss: 0.1215\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1159\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1140\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1208\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1226\n",
      "Epoch: 9/100... Training loss: 0.1118\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1204\n",
      "Epoch: 9/100... Training loss: 0.1193\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100... Training loss: 0.1202\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1188\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1137\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1124\n",
      "Epoch: 9/100... Training loss: 0.1117\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1199\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1199\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1133\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1122\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1142\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1216\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1149\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1100\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1127\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1147\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1147\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1137\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1209\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1137\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1123\n",
      "Epoch: 9/100... Training loss: 0.1204\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1147\n",
      "Epoch: 9/100... Training loss: 0.1123\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1119\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1130\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1130\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1082\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1109\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1184\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1124\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1128\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1128\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1116\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1104\n",
      "Epoch: 9/100... Training loss: 0.1184\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1125\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1130\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1107\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1208\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1200\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1095\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1086\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1206\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1117\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1149\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1184\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1202\n",
      "Epoch: 9/100... Training loss: 0.1113\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1188\n",
      "Epoch: 9/100... Training loss: 0.1121\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1149\n",
      "Epoch: 9/100... Training loss: 0.1122\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1120\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1190\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1098\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1123\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1174\n",
      "Epoch: 10/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1178\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1181\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1110\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1117\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1105\n",
      "Epoch: 10/100... Training loss: 0.1199\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1106\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1196\n",
      "Epoch: 10/100... Training loss: 0.1079\n",
      "Epoch: 10/100... Training loss: 0.1098\n",
      "Epoch: 10/100... Training loss: 0.1093\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1106\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1107\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1066\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1111\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1180\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1101\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1118\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1123\n",
      "Epoch: 10/100... Training loss: 0.1177\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1130\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1102\n",
      "Epoch: 10/100... Training loss: 0.1102\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1110\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1117\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1130\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1103\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1118\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1117\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1102\n",
      "Epoch: 10/100... Training loss: 0.1103\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1175\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1095\n",
      "Epoch: 10/100... Training loss: 0.1112\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1106\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1111\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1123\n",
      "Epoch: 10/100... Training loss: 0.1191\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1087\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1171\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1096\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1160\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1163\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1143\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1099\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1107\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1099\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1143\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1175\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1168\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1107\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1171\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1100\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1102\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1083\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1094\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1106\n",
      "Epoch: 11/100... Training loss: 0.1160\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1106\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1173\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1181\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1102\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1089\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1105\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1091\n",
      "Epoch: 11/100... Training loss: 0.1106\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1096\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1155\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1151\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1094\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1076\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1155\n",
      "Epoch: 11/100... Training loss: 0.1098\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1101\n",
      "Epoch: 11/100... Training loss: 0.1082\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1098\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1105\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1107\n",
      "Epoch: 11/100... Training loss: 0.1098\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1092\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1095\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1094\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1151\n",
      "Epoch: 11/100... Training loss: 0.1119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1073\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1163\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1103\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1056\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 12/100... Training loss: 0.1152\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1147\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1181\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1089\n",
      "Epoch: 12/100... Training loss: 0.1153\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1163\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1089\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1154\n",
      "Epoch: 12/100... Training loss: 0.1141\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1149\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1162\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1091\n",
      "Epoch: 12/100... Training loss: 0.1153\n",
      "Epoch: 12/100... Training loss: 0.1152\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1164\n",
      "Epoch: 12/100... Training loss: 0.1171\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1083\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1084\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1138\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1082\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1066\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1137\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1138\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1105\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1159\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1087\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1171\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1149\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1091\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1159\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1105\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1107\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1092\n",
      "Epoch: 12/100... Training loss: 0.1179\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1076\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1084\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1075\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1141\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1092\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1072\n",
      "Epoch: 12/100... Training loss: 0.1137\n",
      "Epoch: 12/100... Training loss: 0.1137\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1159\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1096\n",
      "Epoch: 12/100... Training loss: 0.1150\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1155\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1073\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1062\n",
      "Epoch: 12/100... Training loss: 0.1071\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1140\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1105\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1169\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1140\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1082\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1160\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1165\n",
      "Epoch: 13/100... Training loss: 0.1154\n",
      "Epoch: 13/100... Training loss: 0.1164\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1157\n",
      "Epoch: 13/100... Training loss: 0.1119\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1141\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1143\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1128\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1158\n",
      "Epoch: 13/100... Training loss: 0.1150\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1074\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1139\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1119\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1147\n",
      "Epoch: 13/100... Training loss: 0.1073\n",
      "Epoch: 13/100... Training loss: 0.1081\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1053\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1087\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1177\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1106\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1051\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1058\n",
      "Epoch: 13/100... Training loss: 0.1150\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1087\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1134\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1165\n",
      "Epoch: 13/100... Training loss: 0.1104\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1078\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1081\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1081\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1157\n",
      "Epoch: 13/100... Training loss: 0.1130\n",
      "Epoch: 13/100... Training loss: 0.1075\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1063\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1085\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1156\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1119\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1076\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1077\n",
      "Epoch: 13/100... Training loss: 0.1076\n",
      "Epoch: 13/100... Training loss: 0.1140\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1138\n",
      "Epoch: 13/100... Training loss: 0.1089\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1072\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1119\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1087\n",
      "Epoch: 13/100... Training loss: 0.1166\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1066\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1060\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1139\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1139\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1085\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1071\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1161\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1136\n",
      "Epoch: 13/100... Training loss: 0.1085\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1164\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1069\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1153\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1140\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1143\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1159\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1140\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1144\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1074\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1080\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1137\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1137\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1069\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1160\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1135\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1149\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1141\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1066\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1067\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1070\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1051\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1074\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1140\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1073\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1147\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1074\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1125\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1129\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1071\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1063\n",
      "Epoch: 14/100... Training loss: 0.1058\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1083\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1062\n",
      "Epoch: 14/100... Training loss: 0.1145\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1164\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1083\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1139\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1061\n",
      "Epoch: 14/100... Training loss: 0.1126\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1068\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1137\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1148\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1111\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1134\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1061\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1127\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1062\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1085\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1083\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1075\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1083\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1064\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1121\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1154\n",
      "Epoch: 14/100... Training loss: 0.1116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1069\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1054\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1060\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1071\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1147\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1126\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1168\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1145\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1123\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1124\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1135\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1067\n",
      "Epoch: 15/100... Training loss: 0.1156\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1071\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1117\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1124\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1150\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1117\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1067\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1127\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1066\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1075\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1131\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1143\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1135\n",
      "Epoch: 15/100... Training loss: 0.1127\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1145\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1114\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1114\n",
      "Epoch: 15/100... Training loss: 0.1053\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1114\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1150\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1140\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1137\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1065\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1114\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1047\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1117\n",
      "Epoch: 15/100... Training loss: 0.1067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1049\n",
      "Epoch: 15/100... Training loss: 0.1054\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1056\n",
      "Epoch: 15/100... Training loss: 0.1127\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1075\n",
      "Epoch: 15/100... Training loss: 0.1066\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1065\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1072\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1126\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1132\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1077\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1133\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1124\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1145\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1046\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1062\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1108\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1115\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1062\n",
      "Epoch: 16/100... Training loss: 0.1120\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1064\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1137\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1043\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1139\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1120\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1104\n",
      "Epoch: 16/100... Training loss: 0.1123\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1031\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1072\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1116\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1133\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1115\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1135\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1065\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1132\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1104\n",
      "Epoch: 16/100... Training loss: 0.1077\n",
      "Epoch: 16/100... Training loss: 0.1044\n",
      "Epoch: 16/100... Training loss: 0.1134\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100... Training loss: 0.1098\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1053\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1165\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1115\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1143\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1133\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1128\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1131\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1065\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1044\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1033\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1122\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1098\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1142\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1058\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1046\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1059\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1116\n",
      "Epoch: 16/100... Training loss: 0.1126\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1072\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1123\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1108\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1128\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1050\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1064\n",
      "Epoch: 16/100... Training loss: 0.1140\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1059\n",
      "Epoch: 16/100... Training loss: 0.1055\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1037\n",
      "Epoch: 16/100... Training loss: 0.1042\n",
      "Epoch: 16/100... Training loss: 0.1108\n",
      "Epoch: 16/100... Training loss: 0.1071\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1057\n",
      "Epoch: 16/100... Training loss: 0.1098\n",
      "Epoch: 16/100... Training loss: 0.1065\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1056\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1042\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1131\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1120\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1153\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1061\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1125\n",
      "Epoch: 17/100... Training loss: 0.1058\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1035\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1057\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1117\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1054\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1065\n",
      "Epoch: 17/100... Training loss: 0.1109\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1047\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1138\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1134\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1037\n",
      "Epoch: 17/100... Training loss: 0.1054\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1052\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1055\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1118\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1056\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1125\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1023\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1049\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1131\n",
      "Epoch: 17/100... Training loss: 0.1130\n",
      "Epoch: 17/100... Training loss: 0.1116\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1048\n",
      "Epoch: 17/100... Training loss: 0.1118\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1137\n",
      "Epoch: 17/100... Training loss: 0.1052\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1061\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1053\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1126\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1055\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1148\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1058\n",
      "Epoch: 17/100... Training loss: 0.1137\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1031\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1058\n",
      "Epoch: 17/100... Training loss: 0.1120\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1031\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1112\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1116\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1032\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1119\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1114\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1113\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1121\n",
      "Epoch: 17/100... Training loss: 0.1056\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1017\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1124\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1126\n",
      "Epoch: 17/100... Training loss: 0.1142\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1055\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1053\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1108\n",
      "Epoch: 18/100... Training loss: 0.1050\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1115\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1120\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1035\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1118\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1117\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1046\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1027\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1117\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1103\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1128\n",
      "Epoch: 18/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1044\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1119\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1051\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1048\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1115\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1049\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1038\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1118\n",
      "Epoch: 18/100... Training loss: 0.1103\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1053\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1108\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1051\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1060\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1044\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1117\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1092\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1011\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1043\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1103\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1054\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1037\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1046\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1121\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1049\n",
      "Epoch: 18/100... Training loss: 0.1046\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1035\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1121\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1045\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1047\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1008\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1092\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1034\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1039\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1060\n",
      "Epoch: 18/100... Training loss: 0.1137\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1110\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1103\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1143\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1100\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1105\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1103\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1110\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1105\n",
      "Epoch: 19/100... Training loss: 0.1050\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1100\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1043\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1100\n",
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1050\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1052\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1048\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1055\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1046\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1112\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1141\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1113\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1017\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1024\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1041\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1123\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1040\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1103\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1133\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1103\n",
      "Epoch: 19/100... Training loss: 0.1108\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1037\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1048\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1021\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1040\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1115\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1041\n",
      "Epoch: 19/100... Training loss: 0.1045\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1053\n",
      "Epoch: 19/100... Training loss: 0.1041\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1042\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1108\n",
      "Epoch: 19/100... Training loss: 0.1043\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1110\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1085\n",
      "Epoch: 19/100... Training loss: 0.1048\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1043\n",
      "Epoch: 19/100... Training loss: 0.1039\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1018\n",
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1053\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1085\n",
      "Epoch: 19/100... Training loss: 0.1039\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1112\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1038\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1038\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1120\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1106\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1114\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1027\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1107\n",
      "Epoch: 20/100... Training loss: 0.1097\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1097\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1112\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1109\n",
      "Epoch: 20/100... Training loss: 0.1052\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1036\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1037\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1115\n",
      "Epoch: 20/100... Training loss: 0.1042\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1101\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1084\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1127\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1040\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1099\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1033\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1055\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1136\n",
      "Epoch: 20/100... Training loss: 0.1115\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1034\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1137\n",
      "Epoch: 20/100... Training loss: 0.1049\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1037\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1107\n",
      "Epoch: 20/100... Training loss: 0.1047\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1029\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1035\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1116\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1119\n",
      "Epoch: 20/100... Training loss: 0.1047\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1040\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1034\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1057\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1039\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1041\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1110\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1040\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1117\n",
      "Epoch: 20/100... Training loss: 0.1036\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1017\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1042\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1034\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1109\n",
      "Epoch: 20/100... Training loss: 0.1030\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1045\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1045\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1052\n",
      "Epoch: 20/100... Training loss: 0.1108\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1049\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1030\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1090\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1044\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1039\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1028\n",
      "Epoch: 21/100... Training loss: 0.1096\n",
      "Epoch: 21/100... Training loss: 0.1031\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1032\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1031\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1118\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1108\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1037\n",
      "Epoch: 21/100... Training loss: 0.1098\n",
      "Epoch: 21/100... Training loss: 0.1118\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1084\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1116\n",
      "Epoch: 21/100... Training loss: 0.1115\n",
      "Epoch: 21/100... Training loss: 0.1036\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1107\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1036\n",
      "Epoch: 21/100... Training loss: 0.1126\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1112\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1038\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1026\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1023\n",
      "Epoch: 21/100... Training loss: 0.1084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1015\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1085\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1093\n",
      "Epoch: 21/100... Training loss: 0.1119\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1097\n",
      "Epoch: 21/100... Training loss: 0.1101\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1075\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1031\n",
      "Epoch: 21/100... Training loss: 0.1072\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1086\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1016\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1107\n",
      "Epoch: 21/100... Training loss: 0.1123\n",
      "Epoch: 21/100... Training loss: 0.1101\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1038\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1031\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1115\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1072\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1044\n",
      "Epoch: 21/100... Training loss: 0.1024\n",
      "Epoch: 21/100... Training loss: 0.1086\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1096\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1075\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1117\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1029\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1106\n",
      "Epoch: 21/100... Training loss: 0.1035\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1116\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1014\n",
      "Epoch: 21/100... Training loss: 0.1085\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1105\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1019\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1040\n",
      "Epoch: 21/100... Training loss: 0.1015\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1090\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1093\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1044\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1024\n",
      "Epoch: 21/100... Training loss: 0.1033\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1085\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1035\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1105\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1109\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1041\n",
      "Epoch: 22/100... Training loss: 0.1104\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1036\n",
      "Epoch: 22/100... Training loss: 0.1035\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1123\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1086\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1026\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1040\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1103\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1097\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1101\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1117\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1035\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1086\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1049\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1091\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1107\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1110\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1125\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1049\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1031\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1108\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1021\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1098\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1117\n",
      "Epoch: 22/100... Training loss: 0.1098\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1041\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1041\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1054\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1029\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1099\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 22/100... Training loss: 0.1096\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1012\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1091\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1030\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1043\n",
      "Epoch: 22/100... Training loss: 0.1091\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1098\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1032\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1032\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1034\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1026\n",
      "Epoch: 22/100... Training loss: 0.1106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1038\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1049\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1034\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1025\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1017\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1111\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1038\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1025\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1110\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1091\n",
      "Epoch: 22/100... Training loss: 0.1026\n",
      "Epoch: 22/100... Training loss: 0.1025\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1092\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1103\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1091\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1094\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1093\n",
      "Epoch: 23/100... Training loss: 0.1081\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1099\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1102\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1037\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1049\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1021\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1088\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1049\n",
      "Epoch: 23/100... Training loss: 0.1091\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1092\n",
      "Epoch: 23/100... Training loss: 0.1088\n",
      "Epoch: 23/100... Training loss: 0.1098\n",
      "Epoch: 23/100... Training loss: 0.1008\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1097\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1015\n",
      "Epoch: 23/100... Training loss: 0.1040\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1099\n",
      "Epoch: 23/100... Training loss: 0.1051\n",
      "Epoch: 23/100... Training loss: 0.1101\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1107\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100... Training loss: 0.1024\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1016\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1092\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1026\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1093\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1026\n",
      "Epoch: 23/100... Training loss: 0.1088\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1047\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1096\n",
      "Epoch: 23/100... Training loss: 0.1016\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1027\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1025\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1102\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1028\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1032\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1119\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1051\n",
      "Epoch: 23/100... Training loss: 0.1027\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1091\n",
      "Epoch: 23/100... Training loss: 0.1112\n",
      "Epoch: 23/100... Training loss: 0.1028\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1020\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1037\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1095\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1089\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1110\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1099\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1091\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1007\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1085\n",
      "Epoch: 24/100... Training loss: 0.1075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1021\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1012\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1034\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1033\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1083\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1027\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1066\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1035\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1038\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1123\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1033\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1021\n",
      "Epoch: 24/100... Training loss: 0.1014\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1038\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1101\n",
      "Epoch: 24/100... Training loss: 0.1095\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1092\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1023\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1105\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1098\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1033\n",
      "Epoch: 24/100... Training loss: 0.1090\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1021\n",
      "Epoch: 24/100... Training loss: 0.1020\n",
      "Epoch: 24/100... Training loss: 0.1106\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1083\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1089\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1094\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1027\n",
      "Epoch: 24/100... Training loss: 0.1015\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.0996\n",
      "Epoch: 24/100... Training loss: 0.1035\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1086\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1035\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1090\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1101\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1017\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1040\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1090\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1107\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1093\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1091\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1111\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1001\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1086\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1013\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1025\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1111\n",
      "Epoch: 25/100... Training loss: 0.1085\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1018\n",
      "Epoch: 25/100... Training loss: 0.1022\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1107\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1110\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1107\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1096\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1098\n",
      "Epoch: 25/100... Training loss: 0.1008\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1090\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1015\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1022\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1017\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1014\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1093\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1010\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1110\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1013\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1091\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1033\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1028\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1105\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1090\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1099\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1089\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1031\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.0993\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1031\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1028\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1098\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1111\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1116\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1023\n",
      "Epoch: 26/100... Training loss: 0.1092\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1075\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1002\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1006\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1105\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1008\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1022\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1104\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1006\n",
      "Epoch: 26/100... Training loss: 0.1080\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1022\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1029\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1010\n",
      "Epoch: 26/100... Training loss: 0.1043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100... Training loss: 0.1112\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1104\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1012\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1037\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1089\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1081\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1081\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1024\n",
      "Epoch: 26/100... Training loss: 0.1097\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1008\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1085\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1109\n",
      "Epoch: 26/100... Training loss: 0.1086\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1088\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1019\n",
      "Epoch: 26/100... Training loss: 0.1031\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1095\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1018\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1022\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1018\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1020\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1006\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1022\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1016\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1093\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1085\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1095\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1014\n",
      "Epoch: 26/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1012\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1082\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1090\n",
      "Epoch: 27/100... Training loss: 0.1021\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1091\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1087\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.0997\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1076\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1096\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1093\n",
      "Epoch: 27/100... Training loss: 0.1073\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1003\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1025\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1005\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1084\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1012\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1020\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1093\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1070\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1081\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1044\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.0998\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1075\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1076\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1084\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1122\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1086\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1082\n",
      "Epoch: 27/100... Training loss: 0.1091\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1100\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1044\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1000\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1089\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1005\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1010\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1087\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.0988\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1085\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1005\n",
      "Epoch: 27/100... Training loss: 0.1093\n",
      "Epoch: 27/100... Training loss: 0.0991\n",
      "Epoch: 27/100... Training loss: 0.1091\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1095\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1104\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1091\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.0996\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1012\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1099\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1002\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1097\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1027\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1017\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1094\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1010\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1080\n",
      "Epoch: 28/100... Training loss: 0.1090\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1074\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1025\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.1079\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1009\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1027\n",
      "Epoch: 28/100... Training loss: 0.1017\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1003\n",
      "Epoch: 28/100... Training loss: 0.1079\n",
      "Epoch: 28/100... Training loss: 0.1086\n",
      "Epoch: 28/100... Training loss: 0.1081\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1081\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1101\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1097\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1074\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1084\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1007\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1080\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.0996\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1084\n",
      "Epoch: 28/100... Training loss: 0.1080\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1029\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1014\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1084\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1029\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1086\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1027\n",
      "Epoch: 28/100... Training loss: 0.1010\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1088\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1016\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1092\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1083\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1096\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1074\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1080\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1071\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1018\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1074\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.0984\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1069\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1052\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1078\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1082\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1014\n",
      "Epoch: 29/100... Training loss: 0.1008\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1069\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1030\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1093\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1095\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1027\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100... Training loss: 0.1006\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1016\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1071\n",
      "Epoch: 29/100... Training loss: 0.1052\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1082\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1096\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1090\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1067\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1097\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1010\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1061\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1011\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.0998\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1083\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1076\n",
      "Epoch: 29/100... Training loss: 0.1076\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.1101\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1017\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1068\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1091\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1082\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1069\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1075\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1091\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1052\n",
      "Epoch: 29/100... Training loss: 0.1122\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1061\n",
      "Epoch: 29/100... Training loss: 0.1014\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1088\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1082\n",
      "Epoch: 29/100... Training loss: 0.1011\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1016\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.0995\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1014\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.0990\n",
      "Epoch: 29/100... Training loss: 0.1071\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1083\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1071\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1089\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1074\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.0991\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1015\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1006\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1099\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1001\n",
      "Epoch: 29/100... Training loss: 0.1084\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1078\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1083\n",
      "Epoch: 30/100... Training loss: 0.1015\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1009\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1028\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1075\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1066\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1028\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1028\n",
      "Epoch: 30/100... Training loss: 0.1063\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1034\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1085\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1016\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1017\n",
      "Epoch: 30/100... Training loss: 0.1034\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1001\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1016\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.1015\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1089\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.0996\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1094\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1004\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1067\n",
      "Epoch: 30/100... Training loss: 0.1016\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1083\n",
      "Epoch: 30/100... Training loss: 0.1009\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1084\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.1082\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1015\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1015\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1008\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1072\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1085\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1072\n",
      "Epoch: 30/100... Training loss: 0.1082\n",
      "Epoch: 30/100... Training loss: 0.1067\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1074\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1015\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1097\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1063\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1073\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1074\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1078\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1080\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1067\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1067\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1013\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1012\n",
      "Epoch: 31/100... Training loss: 0.1070\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1071\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1079\n",
      "Epoch: 31/100... Training loss: 0.1016\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1070\n",
      "Epoch: 31/100... Training loss: 0.1003\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1087\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1008\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1084\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1019\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1097\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1079\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.0993\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.0979\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1000\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.0987\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1006\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1003\n",
      "Epoch: 31/100... Training loss: 0.1012\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1082\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1092\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1085\n",
      "Epoch: 31/100... Training loss: 0.1085\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1001\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1071\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1065\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1011\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1002\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 31/100... Training loss: 0.1012\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.0996\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1004\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1070\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1007\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1080\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1016\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1013\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1089\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1080\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1078\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1019\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1065\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1081\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1065\n",
      "Epoch: 31/100... Training loss: 0.1002\n",
      "Epoch: 31/100... Training loss: 0.1073\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.0983\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1081\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1078\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100... Training loss: 0.0971\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1090\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1006\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1011\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1078\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1075\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1008\n",
      "Epoch: 32/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1086\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.0999\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1091\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1058\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1075\n",
      "Epoch: 32/100... Training loss: 0.1019\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1075\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1083\n",
      "Epoch: 32/100... Training loss: 0.0985\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1019\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1013\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1088\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1083\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1010\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1013\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.0997\n",
      "Epoch: 32/100... Training loss: 0.1096\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1082\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1059\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1020\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1080\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1003\n",
      "Epoch: 32/100... Training loss: 0.1011\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.0995\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1076\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1085\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1076\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1006\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.0997\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1069\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.0989\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1077\n",
      "Epoch: 33/100... Training loss: 0.1011\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1011\n",
      "Epoch: 33/100... Training loss: 0.1073\n",
      "Epoch: 33/100... Training loss: 0.1011\n",
      "Epoch: 33/100... Training loss: 0.1091\n",
      "Epoch: 33/100... Training loss: 0.1006\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1081\n",
      "Epoch: 33/100... Training loss: 0.1090\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1012\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1078\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1095\n",
      "Epoch: 33/100... Training loss: 0.1060\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1012\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1080\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1072\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1005\n",
      "Epoch: 33/100... Training loss: 0.1082\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1056\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1008\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1019\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1079\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1056\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1073\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1012\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.0982\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1090\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1080\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1004\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1077\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1082\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1001\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1085\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1060\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1057\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1019\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.0997\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1068\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1006\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1073\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1010\n",
      "Epoch: 33/100... Training loss: 0.1057\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1006\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1008\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.0999\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1011\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1083\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.0979\n",
      "Epoch: 34/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1016\n",
      "Epoch: 34/100... Training loss: 0.1008\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1003\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.0979\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1077\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1074\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1003\n",
      "Epoch: 34/100... Training loss: 0.1064\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1053\n",
      "Epoch: 34/100... Training loss: 0.1087\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1073\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1016\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1070\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1066\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1013\n",
      "Epoch: 34/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1053\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1079\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1000\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1083\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.0987\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1072\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1016\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1078\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1075\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1016\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1062\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.0985\n",
      "Epoch: 34/100... Training loss: 0.1067\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1066\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1065\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.1013\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1065\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.0996\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1091\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1053\n",
      "Epoch: 34/100... Training loss: 0.1071\n",
      "Epoch: 34/100... Training loss: 0.0998\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1054\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1081\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1004\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1054\n",
      "Epoch: 34/100... Training loss: 0.1083\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1054\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1073\n",
      "Epoch: 34/100... Training loss: 0.0985\n",
      "Epoch: 34/100... Training loss: 0.0996\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1065\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.0999\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1008\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1000\n",
      "Epoch: 34/100... Training loss: 0.1006\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.0991\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.0997\n",
      "Epoch: 34/100... Training loss: 0.1080\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1066\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1089\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1064\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1079\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1047\n",
      "Epoch: 35/100... Training loss: 0.1002\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1010\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.1011\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1002\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1065\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1008\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.0998\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1001\n",
      "Epoch: 35/100... Training loss: 0.1004\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1072\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1073\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1073\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1073\n",
      "Epoch: 35/100... Training loss: 0.1009\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1069\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1057\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1078\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1069\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1065\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1004\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.0985\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.0994\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1076\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1010\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1011\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1078\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1047\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1078\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1011\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.0998\n",
      "Epoch: 35/100... Training loss: 0.1002\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1081\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1079\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1008\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.0972\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1061\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1064\n",
      "Epoch: 35/100... Training loss: 0.1063\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1090\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1065\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1001\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.0992\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1069\n",
      "Epoch: 35/100... Training loss: 0.1009\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1047\n",
      "Epoch: 35/100... Training loss: 0.1008\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1001\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1012\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1057\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.1081\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1084\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1087\n",
      "Epoch: 36/100... Training loss: 0.0995\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.0997\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.0997\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1070\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1070\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1075\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1072\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1068\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1087\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1005\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.1073\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1012\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1068\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1060\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1054\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.0996\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1062\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1002\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1081\n",
      "Epoch: 36/100... Training loss: 0.1063\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1067\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1072\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1057\n",
      "Epoch: 36/100... Training loss: 0.1012\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1012\n",
      "Epoch: 36/100... Training loss: 0.0982\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.0999\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1079\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.0994\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1073\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.0986\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1070\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.0993\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1063\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1062\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.0983\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.0995\n",
      "Epoch: 37/100... Training loss: 0.1059\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100... Training loss: 0.1091\n",
      "Epoch: 37/100... Training loss: 0.1071\n",
      "Epoch: 37/100... Training loss: 0.1079\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1076\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1084\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.0986\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.1011\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1066\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1061\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1071\n",
      "Epoch: 37/100... Training loss: 0.1073\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1064\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1012\n",
      "Epoch: 37/100... Training loss: 0.1079\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.0997\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.0985\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1073\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1064\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.0995\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.0997\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.0967\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1008\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.0990\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1011\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1056\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1097\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1066\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1063\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1059\n",
      "Epoch: 37/100... Training loss: 0.1011\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.0997\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1070\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.0985\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1056\n",
      "Epoch: 37/100... Training loss: 0.0994\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1066\n",
      "Epoch: 37/100... Training loss: 0.1068\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1070\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1079\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.0987\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1056\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1060\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1061\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1060\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1075\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.0999\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1061\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.0986\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.0990\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.1007\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.0998\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1068\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1006\n",
      "Epoch: 38/100... Training loss: 0.1083\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.0996\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1006\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1061\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1065\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.0985\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1079\n",
      "Epoch: 38/100... Training loss: 0.0984\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1071\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1065\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.0964\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/100... Training loss: 0.1056\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1063\n",
      "Epoch: 38/100... Training loss: 0.1074\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1080\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1082\n",
      "Epoch: 38/100... Training loss: 0.1079\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1068\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.0991\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.0990\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1064\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.0994\n",
      "Epoch: 38/100... Training loss: 0.1001\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1065\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1001\n",
      "Epoch: 38/100... Training loss: 0.1096\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.0996\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1056\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.0985\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1081\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1060\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1076\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1072\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1070\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1006\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1079\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1072\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.0986\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.0993\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1048\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.0997\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.0988\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.1050\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.1076\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1046\n",
      "Epoch: 39/100... Training loss: 0.1066\n",
      "Epoch: 39/100... Training loss: 0.1048\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1065\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.0999\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.0997\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.0988\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1048\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1001\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1053\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.0997\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.0990\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1012\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.0979\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1003\n",
      "Epoch: 39/100... Training loss: 0.0973\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1063\n",
      "Epoch: 39/100... Training loss: 0.0996\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.0999\n",
      "Epoch: 39/100... Training loss: 0.1071\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.0996\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.0996\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1081\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.0992\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.0985\n",
      "Epoch: 39/100... Training loss: 0.1061\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1066\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.1071\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1067\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1063\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1067\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.0995\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1050\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.0996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1013\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1068\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1001\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1075\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1004\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.0973\n",
      "Epoch: 40/100... Training loss: 0.0994\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1070\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.0998\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1078\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1067\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1066\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1067\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1065\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1073\n",
      "Epoch: 40/100... Training loss: 0.1084\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.0982\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1000\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1001\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1069\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1074\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1004\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1074\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.0998\n",
      "Epoch: 40/100... Training loss: 0.0983\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.0992\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.0995\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1056\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1083\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1074\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1059\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1080\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1086\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1062\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.0989\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.0999\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1092\n",
      "Epoch: 40/100... Training loss: 0.1000\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1064\n",
      "Epoch: 40/100... Training loss: 0.1076\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.0998\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1081\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.0996\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1028\n",
      "Epoch: 40/100... Training loss: 0.1065\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.0984\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.0988\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1001\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1056\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1028\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1000\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.0991\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1070\n",
      "Epoch: 41/100... Training loss: 0.1054\n",
      "Epoch: 41/100... Training loss: 0.1071\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1081\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.0987\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1057\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1056\n",
      "Epoch: 41/100... Training loss: 0.0997\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1056\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1060\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1077\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1069\n",
      "Epoch: 41/100... Training loss: 0.0984\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1072\n",
      "Epoch: 41/100... Training loss: 0.1067\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1067\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.0993\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1050\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1100\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1081\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1060\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1062\n",
      "Epoch: 41/100... Training loss: 0.0989\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.0996\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 41/100... Training loss: 0.1057\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 41/100... Training loss: 0.1060\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.0999\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.0994\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.0988\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1062\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1056\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.0991\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.0983\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.0991\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1055\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1073\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.0989\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.0995\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1073\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1069\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1068\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1062\n",
      "Epoch: 42/100... Training loss: 0.1002\n",
      "Epoch: 42/100... Training loss: 0.0987\n",
      "Epoch: 42/100... Training loss: 0.0989\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.0981\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1071\n",
      "Epoch: 42/100... Training loss: 0.1093\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1073\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1061\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1051\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1062\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1071\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.0983\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1068\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1072\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1063\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1067\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1048\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.0990\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.0993\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1064\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.0981\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1045\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1053\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1004\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.0991\n",
      "Epoch: 42/100... Training loss: 0.0994\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1060\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.1045\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1002\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1066\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.0985\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.0989\n",
      "Epoch: 42/100... Training loss: 0.1002\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.0993\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1069\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.0978\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.0981\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1004\n",
      "Epoch: 42/100... Training loss: 0.0969\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1066\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.0990\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1045\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.0995\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 43/100... Training loss: 0.1001\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.0975\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.0979\n",
      "Epoch: 43/100... Training loss: 0.0983\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1064\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1056\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1054\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.0998\n",
      "Epoch: 43/100... Training loss: 0.0998\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1065\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1053\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1072\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.0995\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1067\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.0984\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 43/100... Training loss: 0.0995\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1054\n",
      "Epoch: 43/100... Training loss: 0.1063\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1051\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.0976\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1080\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.1051\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1062\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1044\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1000\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.0984\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.0978\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.0983\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.0992\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1044\n",
      "Epoch: 43/100... Training loss: 0.0971\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.0969\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1081\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1061\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1066\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1051\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1060\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.1001\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.0985\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.0991\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.1058\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1049\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1056\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1064\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.0979\n",
      "Epoch: 44/100... Training loss: 0.1060\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1063\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1068\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.0990\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.1060\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1056\n",
      "Epoch: 44/100... Training loss: 0.1066\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1065\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1044\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1057\n",
      "Epoch: 44/100... Training loss: 0.0984\n",
      "Epoch: 44/100... Training loss: 0.1021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.0992\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1044\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.0997\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.0990\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1053\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.0988\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1063\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1057\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1054\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1050\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1060\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.0999\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1064\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.0997\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1002\n",
      "Epoch: 44/100... Training loss: 0.1067\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1050\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.0976\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.0966\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.0999\n",
      "Epoch: 44/100... Training loss: 0.1054\n",
      "Epoch: 44/100... Training loss: 0.1049\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1002\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.0969\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1055\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.0978\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.0997\n",
      "Epoch: 44/100... Training loss: 0.1064\n",
      "Epoch: 44/100... Training loss: 0.1054\n",
      "Epoch: 44/100... Training loss: 0.0981\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1051\n",
      "Epoch: 44/100... Training loss: 0.0993\n",
      "Epoch: 44/100... Training loss: 0.1059\n",
      "Epoch: 44/100... Training loss: 0.1051\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1081\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1051\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.0995\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1068\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1061\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1042\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1069\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1068\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.0985\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1055\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1008\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1056\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.0987\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.0981\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1054\n",
      "Epoch: 45/100... Training loss: 0.1063\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1056\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.0985\n",
      "Epoch: 45/100... Training loss: 0.1074\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1062\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1068\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1060\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1058\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1061\n",
      "Epoch: 45/100... Training loss: 0.1047\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.0993\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1071\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1044\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1044\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1062\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1008\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1047\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.0988\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1060\n",
      "Epoch: 45/100... Training loss: 0.0989\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1059\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1040\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.0987\n",
      "Epoch: 45/100... Training loss: 0.1044\n",
      "Epoch: 45/100... Training loss: 0.0991\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1056\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.0975\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1077\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.0987\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.0994\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1055\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1051\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1054\n",
      "Epoch: 46/100... Training loss: 0.0980\n",
      "Epoch: 46/100... Training loss: 0.1056\n",
      "Epoch: 46/100... Training loss: 0.1044\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1062\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1051\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.1044\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1083\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1066\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1061\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.0991\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.0977\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.0997\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.1057\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.0983\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.0992\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1058\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1054\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1087\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.0996\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1054\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1034\n",
      "Epoch: 46/100... Training loss: 0.1034\n",
      "Epoch: 46/100... Training loss: 0.1057\n",
      "Epoch: 46/100... Training loss: 0.1056\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.0990\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1058\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1057\n",
      "Epoch: 46/100... Training loss: 0.0996\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1001\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1061\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1057\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.0986\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.0978\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1001\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1067\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1054\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1062\n",
      "Epoch: 47/100... Training loss: 0.0988\n",
      "Epoch: 47/100... Training loss: 0.1058\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.0983\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1001\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1046\n",
      "Epoch: 47/100... Training loss: 0.1065\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.0995\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.0984\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1059\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.0995\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1070\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.0991\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1052\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1063\n",
      "Epoch: 47/100... Training loss: 0.0995\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1063\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.0994\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1055\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.0987\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1035\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1075\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.0970\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.0993\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.0973\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.0983\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1035\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1002\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1055\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.0979\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1054\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.1046\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1059\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1051\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1051\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1052\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1046\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1048\n",
      "Epoch: 48/100... Training loss: 0.1047\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1047\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1054\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.0982\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.0993\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.0993\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.0987\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.1055\n",
      "Epoch: 48/100... Training loss: 0.0970\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.0993\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.0989\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1062\n",
      "Epoch: 48/100... Training loss: 0.1048\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1065\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1044\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.0978\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.1062\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1048\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.0998\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.0987\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1046\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1057\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1084\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.0998\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1047\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1060\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1075\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1065\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1059\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.0971\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.1046\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.0989\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1046\n",
      "Epoch: 48/100... Training loss: 0.0986\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1067\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1058\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1053\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1032\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.0978\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.0991\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.0991\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.0984\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.0987\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1032\n",
      "Epoch: 49/100... Training loss: 0.1052\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.0985\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.0979\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1052\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.0995\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1054\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1028\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1047\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1054\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1057\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1028\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.0984\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.0987\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1069\n",
      "Epoch: 49/100... Training loss: 0.1066\n",
      "Epoch: 49/100... Training loss: 0.0987\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1078\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.0986\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1059\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1056\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1047\n",
      "Epoch: 49/100... Training loss: 0.1049\n",
      "Epoch: 49/100... Training loss: 0.1012\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1062\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1056\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1052\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1051\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.0995\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.0975\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.0977\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1070\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1056\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1067\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.0986\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1053\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1077\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1047\n",
      "Epoch: 50/100... Training loss: 0.1051\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1059\n",
      "Epoch: 50/100... Training loss: 0.0990\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.1007\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.1048\n",
      "Epoch: 50/100... Training loss: 0.1056\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.0969\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1065\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1047\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1072\n",
      "Epoch: 50/100... Training loss: 0.0983\n",
      "Epoch: 50/100... Training loss: 0.1057\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.0975\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1049\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.0981\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1065\n",
      "Epoch: 50/100... Training loss: 0.0983\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1053\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.0976\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.0963\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.0980\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.0985\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1049\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1061\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1048\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.0980\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1042\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.0962\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.0982\n",
      "Epoch: 50/100... Training loss: 0.1047\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1055\n",
      "Epoch: 50/100... Training loss: 0.1051\n",
      "Epoch: 50/100... Training loss: 0.1055\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.0985\n",
      "Epoch: 50/100... Training loss: 0.0989\n",
      "Epoch: 50/100... Training loss: 0.1065\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.0973\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.0980\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.0979\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1046\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.0983\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.0989\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.0986\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.0957\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1068\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1063\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.0989\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.0977\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1055\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1057\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1049\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1055\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1053\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.0980\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1053\n",
      "Epoch: 51/100... Training loss: 0.1057\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.0988\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0988\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.0983\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1046\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1053\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1048\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.1042\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1060\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.0985\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.0992\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1042\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.0962\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0990\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1076\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1042\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1058\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0976\n",
      "Epoch: 51/100... Training loss: 0.0990\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1051\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.0996\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1040\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1066\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.0981\n",
      "Epoch: 51/100... Training loss: 0.0990\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1040\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.0981\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1052\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.0973\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1059\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1064\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.0986\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.0982\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.1063\n",
      "Epoch: 52/100... Training loss: 0.0982\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.0973\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1039\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1056\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.0972\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.0975\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1048\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.1055\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.0989\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.0987\n",
      "Epoch: 52/100... Training loss: 0.0974\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1045\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1062\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1062\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1065\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.0973\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1057\n",
      "Epoch: 52/100... Training loss: 0.1061\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.0989\n",
      "Epoch: 52/100... Training loss: 0.0988\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.1047\n",
      "Epoch: 52/100... Training loss: 0.0971\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.0988\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.0986\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.0977\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.0977\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.1070\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1063\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.0987\n",
      "Epoch: 52/100... Training loss: 0.1039\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.1051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100... Training loss: 0.0986\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1061\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1046\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1039\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1059\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1045\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1066\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1048\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1060\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1057\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.0988\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1044\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.0985\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.0990\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.0982\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.0973\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1049\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1048\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.0982\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0972\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.0962\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1058\n",
      "Epoch: 53/100... Training loss: 0.1044\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.1054\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.1044\n",
      "Epoch: 53/100... Training loss: 0.0982\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1044\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1055\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.0983\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1053\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1052\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.0968\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.0988\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.0981\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1063\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.0940\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1053\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1063\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1066\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1063\n",
      "Epoch: 53/100... Training loss: 0.1056\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1047\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.0988\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.0978\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1054\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.0980\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1063\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1053\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.0990\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1012\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1012\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1062\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.0985\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.0963\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.0977\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1054\n",
      "Epoch: 54/100... Training loss: 0.0956\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.0980\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0979\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.0980\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.0986\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.0986\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1057\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.1065\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.0978\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1055\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1061\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1091\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1056\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1002\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.0985\n",
      "Epoch: 54/100... Training loss: 0.1051\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.1000\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.0975\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1050\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1047\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1053\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1053\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.0984\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0984\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.0987\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100... Training loss: 0.1048\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.0964\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1040\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.0983\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.0982\n",
      "Epoch: 55/100... Training loss: 0.1049\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.0970\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.0988\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1041\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1041\n",
      "Epoch: 55/100... Training loss: 0.1067\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1049\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.0968\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1033\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.0983\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.1041\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1051\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1039\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.1042\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.0987\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.0971\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1062\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1068\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1067\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.1046\n",
      "Epoch: 55/100... Training loss: 0.1059\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.0977\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.0964\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1039\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.0965\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.1050\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.0986\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.0992\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0982\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1064\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.1047\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1033\n",
      "Epoch: 55/100... Training loss: 0.0973\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1042\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1042\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.0983\n",
      "Epoch: 55/100... Training loss: 0.1068\n",
      "Epoch: 55/100... Training loss: 0.1040\n",
      "Epoch: 55/100... Training loss: 0.0987\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1047\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.1042\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.0982\n",
      "Epoch: 55/100... Training loss: 0.1040\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1039\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1049\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0978\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.0992\n",
      "Epoch: 56/100... Training loss: 0.1054\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1063\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1041\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1041\n",
      "Epoch: 56/100... Training loss: 0.1046\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.0980\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.0978\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1043\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1038\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1070\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.0975\n",
      "Epoch: 56/100... Training loss: 0.1038\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1057\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0992\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1037\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.0997\n",
      "Epoch: 56/100... Training loss: 0.1046\n",
      "Epoch: 56/100... Training loss: 0.0976\n",
      "Epoch: 56/100... Training loss: 0.1039\n",
      "Epoch: 56/100... Training loss: 0.0959\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1037\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.0979\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1051\n",
      "Epoch: 56/100... Training loss: 0.0985\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1051\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1054\n",
      "Epoch: 56/100... Training loss: 0.0974\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.0979\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.0950\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1044\n",
      "Epoch: 56/100... Training loss: 0.0977\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1043\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1044\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.1041\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.0974\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.1048\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.0971\n",
      "Epoch: 56/100... Training loss: 0.0997\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.0994\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0983\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.0985\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.0971\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1048\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.0979\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.0966\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.0992\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1068\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1039\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.0985\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1038\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.0975\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1062\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100... Training loss: 0.1033\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1050\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1048\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.1046\n",
      "Epoch: 57/100... Training loss: 0.0980\n",
      "Epoch: 57/100... Training loss: 0.1038\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1058\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.0970\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1033\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1066\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.1035\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.1055\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1049\n",
      "Epoch: 57/100... Training loss: 0.1064\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.0982\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1037\n",
      "Epoch: 57/100... Training loss: 0.0980\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.0963\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.1066\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1064\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.0972\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.0982\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.0971\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1042\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.0978\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.0978\n",
      "Epoch: 57/100... Training loss: 0.1049\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1042\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1037\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1049\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1038\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.0969\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1054\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.0976\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1037\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1001\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.0965\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.0988\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.0986\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.0974\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0973\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1059\n",
      "Epoch: 57/100... Training loss: 0.1042\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1035\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0977\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1044\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1050\n",
      "Epoch: 58/100... Training loss: 0.0979\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.0980\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1053\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1057\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1038\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1042\n",
      "Epoch: 58/100... Training loss: 0.1038\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.0990\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0966\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1042\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1053\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.0979\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.0982\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.1048\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1077\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.0974\n",
      "Epoch: 58/100... Training loss: 0.1053\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1040\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1054\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.1045\n",
      "Epoch: 58/100... Training loss: 0.1050\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1064\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1035\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100... Training loss: 0.0987\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1040\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0978\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.0995\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.0978\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1040\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1057\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.0969\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1048\n",
      "Epoch: 58/100... Training loss: 0.1060\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.0982\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.0974\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.0971\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1048\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.0978\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.0973\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.0967\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.0975\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1035\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1075\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1047\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1039\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1066\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.0971\n",
      "Epoch: 59/100... Training loss: 0.1052\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1051\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1055\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1054\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1039\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.0971\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.0983\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.1072\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.0981\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1045\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.0976\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.0981\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1047\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.0979\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1046\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.0969\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1056\n",
      "Epoch: 59/100... Training loss: 0.1044\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1043\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1057\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1041\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.0978\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1056\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.0979\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.0981\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.0983\n",
      "Epoch: 59/100... Training loss: 0.0977\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0985\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.0982\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0964\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.1041\n",
      "Epoch: 59/100... Training loss: 0.0983\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.0987\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.0977\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.0976\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.1053\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.1049\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.0960\n",
      "Epoch: 59/100... Training loss: 0.0970\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.0994\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1058\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.0964\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.0967\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0984\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.0978\n",
      "Epoch: 60/100... Training loss: 0.1055\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1042\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1050\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1033\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.0994\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1033\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.0991\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0991\n",
      "Epoch: 60/100... Training loss: 0.1044\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.0986\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1037\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.1037\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1044\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1063\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0969\n",
      "Epoch: 60/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.1047\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1033\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1048\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.0977\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/100... Training loss: 0.1050\n",
      "Epoch: 60/100... Training loss: 0.1043\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1038\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1042\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.0978\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.1054\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.0994\n",
      "Epoch: 60/100... Training loss: 0.1042\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1054\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.0991\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.0979\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.1037\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1046\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1051\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1053\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1058\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.0975\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.0948\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.1054\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1056\n",
      "Epoch: 61/100... Training loss: 0.0982\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1042\n",
      "Epoch: 61/100... Training loss: 0.1054\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1052\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.1056\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1054\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.1044\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1052\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1049\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.0949\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.0971\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1038\n",
      "Epoch: 61/100... Training loss: 0.1050\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.0962\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1047\n",
      "Epoch: 61/100... Training loss: 0.0972\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.0974\n",
      "Epoch: 61/100... Training loss: 0.1037\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1037\n",
      "Epoch: 61/100... Training loss: 0.1037\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1046\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.0972\n",
      "Epoch: 61/100... Training loss: 0.1042\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1065\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.0981\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.0984\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.0966\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.1038\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.0991\n",
      "Epoch: 61/100... Training loss: 0.0993\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1035\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.0984\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.0976\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.1042\n",
      "Epoch: 61/100... Training loss: 0.0980\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.0963\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1035\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.0981\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1045\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1044\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0945\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.0993\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.0993\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.0970\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.0968\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1044\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.0985\n",
      "Epoch: 62/100... Training loss: 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.0969\n",
      "Epoch: 62/100... Training loss: 0.0977\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1039\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.0979\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1039\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1036\n",
      "Epoch: 62/100... Training loss: 0.0971\n",
      "Epoch: 62/100... Training loss: 0.1048\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.0981\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1048\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.0981\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.0984\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.1036\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.0986\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.0981\n",
      "Epoch: 62/100... Training loss: 0.1043\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0970\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1047\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.0963\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0985\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1049\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1040\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1037\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.0975\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1052\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.0970\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.0975\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1040\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 63/100... Training loss: 0.1048\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.1047\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1035\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1048\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.0972\n",
      "Epoch: 63/100... Training loss: 0.1050\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.0977\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1047\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1054\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.0974\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.1039\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.0974\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0972\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1033\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.1045\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1050\n",
      "Epoch: 63/100... Training loss: 0.1060\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.0979\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1042\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.1052\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.0968\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0972\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.0961\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1053\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1045\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1084\n",
      "Epoch: 63/100... Training loss: 0.1037\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1035\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.0974\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.0970\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1047\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.1050\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.1049\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.0977\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.0981\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1060\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1056\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1037\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1045\n",
      "Epoch: 63/100... Training loss: 0.0974\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.0979\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1041\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.1060\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1021\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1047\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0963\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1046\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1039\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0994\n",
      "Epoch: 64/100... Training loss: 0.0979\n",
      "Epoch: 64/100... Training loss: 0.0955\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1033\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.0985\n",
      "Epoch: 64/100... Training loss: 0.1037\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1058\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.0979\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.1037\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1038\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.0994\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1056\n",
      "Epoch: 64/100... Training loss: 0.1048\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0962\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.0991\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.0984\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.0982\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1041\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.0978\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1034\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.0985\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0976\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1043\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.0955\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1038\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.0983\n",
      "Epoch: 64/100... Training loss: 0.1061\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1034\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.1039\n",
      "Epoch: 64/100... Training loss: 0.0958\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.0974\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1037\n",
      "Epoch: 64/100... Training loss: 0.0974\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1050\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1045\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.0977\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.0984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.0971\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1037\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1056\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.1048\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.1046\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0974\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.0977\n",
      "Epoch: 65/100... Training loss: 0.1041\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1036\n",
      "Epoch: 65/100... Training loss: 0.0976\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1037\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1050\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1043\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.0969\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1047\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1051\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0971\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0978\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1044\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.0974\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1048\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.0981\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1034\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1035\n",
      "Epoch: 65/100... Training loss: 0.1038\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.0978\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1038\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1035\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100... Training loss: 0.0955\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.0971\n",
      "Epoch: 65/100... Training loss: 0.1034\n",
      "Epoch: 65/100... Training loss: 0.0967\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1043\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1055\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0974\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1044\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.0969\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1034\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.1045\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0978\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.0976\n",
      "Epoch: 65/100... Training loss: 0.0983\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.0971\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1048\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1044\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1047\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.0973\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1048\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1052\n",
      "Epoch: 66/100... Training loss: 0.0969\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.1035\n",
      "Epoch: 66/100... Training loss: 0.1042\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1030\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1033\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.1036\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1052\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0965\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.0978\n",
      "Epoch: 66/100... Training loss: 0.1050\n",
      "Epoch: 66/100... Training loss: 0.1030\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0976\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0980\n",
      "Epoch: 66/100... Training loss: 0.0977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1026\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1026\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1041\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.1042\n",
      "Epoch: 66/100... Training loss: 0.0964\n",
      "Epoch: 66/100... Training loss: 0.0971\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1062\n",
      "Epoch: 66/100... Training loss: 0.1035\n",
      "Epoch: 66/100... Training loss: 0.0966\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1065\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.0971\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1046\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0983\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1040\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0950\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.0978\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1045\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.0985\n",
      "Epoch: 66/100... Training loss: 0.1026\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1053\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1050\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.0997\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.0985\n",
      "Epoch: 67/100... Training loss: 0.0997\n",
      "Epoch: 67/100... Training loss: 0.0983\n",
      "Epoch: 67/100... Training loss: 0.1040\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0984\n",
      "Epoch: 67/100... Training loss: 0.1034\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1038\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0997\n",
      "Epoch: 67/100... Training loss: 0.1033\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.0963\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.0958\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1024\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1034\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1046\n",
      "Epoch: 67/100... Training loss: 0.1055\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.1038\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1035\n",
      "Epoch: 67/100... Training loss: 0.1054\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.0979\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1039\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.0971\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.0968\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0975\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1044\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.1048\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1038\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.0971\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0970\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1049\n",
      "Epoch: 67/100... Training loss: 0.1059\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1048\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1040\n",
      "Epoch: 67/100... Training loss: 0.1051\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1046\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1058\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.0997\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.0961\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.0963\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1052\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1043\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.0979\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.0987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.0975\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.0981\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0954\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0972\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.0981\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1035\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.0981\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0977\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.0967\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1033\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0973\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.0962\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0972\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1041\n",
      "Epoch: 68/100... Training loss: 0.1041\n",
      "Epoch: 68/100... Training loss: 0.0979\n",
      "Epoch: 68/100... Training loss: 0.1063\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1049\n",
      "Epoch: 68/100... Training loss: 0.1040\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.1039\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.1036\n",
      "Epoch: 68/100... Training loss: 0.1065\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.1039\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0992\n",
      "Epoch: 68/100... Training loss: 0.0962\n",
      "Epoch: 68/100... Training loss: 0.0981\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0972\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.0949\n",
      "Epoch: 68/100... Training loss: 0.0979\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1043\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1042\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0977\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.1042\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.0971\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1045\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1050\n",
      "Epoch: 68/100... Training loss: 0.1040\n",
      "Epoch: 68/100... Training loss: 0.1025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.1042\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1050\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.0970\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0964\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1044\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1041\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0966\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1043\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1046\n",
      "Epoch: 68/100... Training loss: 0.0976\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.0972\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.0964\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.0966\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.0969\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0973\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0954\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.0975\n",
      "Epoch: 68/100... Training loss: 0.1039\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0951\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.0976\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.0969\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1040\n",
      "Epoch: 69/100... Training loss: 0.0971\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1044\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1044\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1041\n",
      "Epoch: 69/100... Training loss: 0.1036\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1024\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1036\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1050\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.0968\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1039\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100... Training loss: 0.1056\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.0979\n",
      "Epoch: 69/100... Training loss: 0.0981\n",
      "Epoch: 69/100... Training loss: 0.1039\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.0967\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.1041\n",
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.0968\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1074\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.0981\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0960\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.0979\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.1047\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0985\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.0970\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.0966\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0981\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1043\n",
      "Epoch: 69/100... Training loss: 0.1042\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.0969\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1033\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.0971\n",
      "Epoch: 69/100... Training loss: 0.1051\n",
      "Epoch: 69/100... Training loss: 0.1040\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.0970\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.1037\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1024\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.0970\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0996\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.0976\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1036\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1040\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.0995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1055\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1034\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1062\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0971\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1034\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.1046\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1035\n",
      "Epoch: 70/100... Training loss: 0.1040\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0969\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1043\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.0978\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1034\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1047\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1027\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1044\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1033\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0979\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0986\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1029\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1048\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.0967\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0969\n",
      "Epoch: 70/100... Training loss: 0.0973\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1041\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.0975\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0973\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.0976\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.0972\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100... Training loss: 0.1061\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0958\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1034\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1035\n",
      "Epoch: 70/100... Training loss: 0.1029\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.0983\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1027\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1029\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1046\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.0975\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.1027\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.0967\n",
      "Epoch: 70/100... Training loss: 0.1041\n",
      "Epoch: 70/100... Training loss: 0.1066\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.0980\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1076\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1028\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.1037\n",
      "Epoch: 71/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.1046\n",
      "Epoch: 71/100... Training loss: 0.1039\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1041\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1041\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.1043\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1044\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0999\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1037\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1039\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.0963\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1036\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.0971\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.1059\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0972\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1051\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.1066\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1049\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.0974\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1049\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.0962\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1048\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.0965\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.0957\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0959\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0976\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.0946\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 71/100... Training loss: 0.0977\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0965\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0965\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.0964\n",
      "Epoch: 71/100... Training loss: 0.0969\n",
      "Epoch: 71/100... Training loss: 0.1055\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.0963\n",
      "Epoch: 71/100... Training loss: 0.1055\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1044\n",
      "Epoch: 71/100... Training loss: 0.1040\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1028\n",
      "Epoch: 71/100... Training loss: 0.1047\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1046\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.0977\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.0999\n",
      "Epoch: 71/100... Training loss: 0.0971\n",
      "Epoch: 71/100... Training loss: 0.1054\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1048\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.0969\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.0999\n",
      "Epoch: 71/100... Training loss: 0.1036\n",
      "Epoch: 71/100... Training loss: 0.0974\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.0974\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1062\n",
      "Epoch: 72/100... Training loss: 0.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1037\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.0945\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1041\n",
      "Epoch: 72/100... Training loss: 0.1036\n",
      "Epoch: 72/100... Training loss: 0.1033\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.1049\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.0975\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1050\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1029\n",
      "Epoch: 72/100... Training loss: 0.1046\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.1034\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.1049\n",
      "Epoch: 72/100... Training loss: 0.0983\n",
      "Epoch: 72/100... Training loss: 0.1037\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1043\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.0984\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1040\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1024\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.1044\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.1043\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0970\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1038\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1055\n",
      "Epoch: 72/100... Training loss: 0.1031\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.0973\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1037\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1034\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1033\n",
      "Epoch: 72/100... Training loss: 0.1058\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.1047\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0983\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1057\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1043\n",
      "Epoch: 72/100... Training loss: 0.0969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1033\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1040\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1045\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.0966\n",
      "Epoch: 72/100... Training loss: 0.1042\n",
      "Epoch: 72/100... Training loss: 0.0984\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.0964\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.0984\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1038\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.0984\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1031\n",
      "Epoch: 72/100... Training loss: 0.0967\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0968\n",
      "Epoch: 72/100... Training loss: 0.0977\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.1033\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1026\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.0963\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.0972\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1042\n",
      "Epoch: 73/100... Training loss: 0.0969\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1044\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.0972\n",
      "Epoch: 73/100... Training loss: 0.0968\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.1053\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0974\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.0972\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0981\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1025\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1037\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1029\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.0970\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1039\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1041\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1040\n",
      "Epoch: 73/100... Training loss: 0.0980\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.0972\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.1038\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1048\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.0939\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.0989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1029\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.0957\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1026\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.1049\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0974\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1043\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0969\n",
      "Epoch: 73/100... Training loss: 0.0981\n",
      "Epoch: 73/100... Training loss: 0.0984\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0968\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1053\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1039\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.0969\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1047\n",
      "Epoch: 73/100... Training loss: 0.1044\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.0980\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1026\n",
      "Epoch: 73/100... Training loss: 0.0960\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.0984\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0968\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.1041\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.0968\n",
      "Epoch: 73/100... Training loss: 0.0984\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1025\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1026\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1033\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.1040\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.0969\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.0981\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.1031\n",
      "Epoch: 74/100... Training loss: 0.0974\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.1036\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.0977\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.1034\n",
      "Epoch: 74/100... Training loss: 0.1031\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.0967\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1023\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0972\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0969\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.1001\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.0966\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1032\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1037\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1043\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1037\n",
      "Epoch: 74/100... Training loss: 0.0974\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.0974\n",
      "Epoch: 74/100... Training loss: 0.0959\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1034\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1036\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0979\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.0972\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.1050\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1035\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0980\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.1055\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.1032\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.0972\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.1040\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.1073\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.0980\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.0969\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1031\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.0961\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1001\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.1023\n",
      "Epoch: 74/100... Training loss: 0.1051\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.0961\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1043\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1035\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1042\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.1048\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.1039\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1046\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0965\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1051\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1041\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1025\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.0981\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.0970\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0975\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.1046\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.0971\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0964\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1051\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0979\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.1044\n",
      "Epoch: 75/100... Training loss: 0.1039\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1037\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0971\n",
      "Epoch: 75/100... Training loss: 0.0967\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.1036\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1040\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1036\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.0970\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1037\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.0975\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.0970\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.0963\n",
      "Epoch: 75/100... Training loss: 0.1087\n",
      "Epoch: 75/100... Training loss: 0.1027\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1043\n",
      "Epoch: 75/100... Training loss: 0.1078\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0959\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.1043\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1043\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1059\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1022\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1025\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1036\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1041\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.0964\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1039\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.0971\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0970\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1037\n",
      "Epoch: 76/100... Training loss: 0.1042\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.0965\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.0969\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1030\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0958\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.1055\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0971\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1054\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1046\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.0960\n",
      "Epoch: 76/100... Training loss: 0.0962\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1037\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.0958\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.0965\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1042\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1047\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1061\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.1049\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.0970\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.1045\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.0974\n",
      "Epoch: 76/100... Training loss: 0.1036\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.1047\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1032\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1042\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.0972\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1054\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.1032\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.1043\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1030\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.0971\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.1081\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0967\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1034\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1038\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1029\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1038\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.0967\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1038\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.0978\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1049\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.1034\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.0972\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0951\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.1055\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0966\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0972\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0967\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.0978\n",
      "Epoch: 77/100... Training loss: 0.1038\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.0967\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1045\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.1034\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1034\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1034\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0955\n",
      "Epoch: 77/100... Training loss: 0.1045\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0978\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.0974\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0975\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1036\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1044\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.0958\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0984\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.1056\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.0968\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0966\n",
      "Epoch: 78/100... Training loss: 0.1046\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0972\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0958\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0974\n",
      "Epoch: 78/100... Training loss: 0.0954\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1054\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1035\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1033\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0966\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0967\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.0965\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0970\n",
      "Epoch: 78/100... Training loss: 0.1039\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.0971\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.0977\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.1035\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.1030\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0977\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1061\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1037\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0977\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.0970\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.0944\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1036\n",
      "Epoch: 78/100... Training loss: 0.1052\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1033\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1055\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1030\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1042\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.0967\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.0970\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.0967\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0975\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.1035\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.0963\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.1041\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.1052\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1037\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1034\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.0971\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.1060\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.0960\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.1035\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.0973\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.0967\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1031\n",
      "Epoch: 79/100... Training loss: 0.1044\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.1025\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.1041\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.1042\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.1031\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.1031\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0975\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1037\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0952\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.1049\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1031\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0973\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1033\n",
      "Epoch: 79/100... Training loss: 0.1025\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.0970\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.0969\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1019\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1047\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.1019\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.1048\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1032\n",
      "Epoch: 79/100... Training loss: 0.0975\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.1034\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1032\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1035\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1019\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.0963\n",
      "Epoch: 79/100... Training loss: 0.1025\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.1046\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.1032\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0966\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0965\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0963\n",
      "Epoch: 79/100... Training loss: 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.0966\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.0972\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0959\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1037\n",
      "Epoch: 80/100... Training loss: 0.1028\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0969\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1044\n",
      "Epoch: 80/100... Training loss: 0.1036\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.0974\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.0958\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0959\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1028\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.0975\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.0967\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.0972\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1036\n",
      "Epoch: 80/100... Training loss: 0.0973\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0971\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1035\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.1035\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.0969\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0976\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.0947\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.0978\n",
      "Epoch: 80/100... Training loss: 0.0958\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1040\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1037\n",
      "Epoch: 80/100... Training loss: 0.0978\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.0998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0970\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0984\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.1025\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0978\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0969\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1024\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.0966\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.1039\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.0976\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0970\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0962\n",
      "Epoch: 80/100... Training loss: 0.1025\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1052\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1053\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1041\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.1028\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0975\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1034\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.0969\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.0967\n",
      "Epoch: 81/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.0975\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.1031\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1034\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1036\n",
      "Epoch: 81/100... Training loss: 0.0974\n",
      "Epoch: 81/100... Training loss: 0.1036\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.1036\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0965\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.0971\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0959\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.1031\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.0976\n",
      "Epoch: 81/100... Training loss: 0.1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.1024\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.0960\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.0970\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.0963\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1035\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1044\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1046\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.0958\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.0970\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1032\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.1034\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.0951\n",
      "Epoch: 81/100... Training loss: 0.1050\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1038\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1042\n",
      "Epoch: 81/100... Training loss: 0.0973\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1038\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.0970\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.0964\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0973\n",
      "Epoch: 81/100... Training loss: 0.0954\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0951\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.0965\n",
      "Epoch: 82/100... Training loss: 0.1048\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1033\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.0978\n",
      "Epoch: 82/100... Training loss: 0.1033\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.0993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1039\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.1037\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1038\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1045\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0973\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1056\n",
      "Epoch: 82/100... Training loss: 0.1034\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.1043\n",
      "Epoch: 82/100... Training loss: 0.1027\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0955\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1035\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0961\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.1041\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1035\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1038\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1036\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1034\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.1029\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.0971\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.0978\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.0973\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.0964\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.0951\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1032\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.1031\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1034\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1056\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1034\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.0966\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.1037\n",
      "Epoch: 82/100... Training loss: 0.1019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1043\n",
      "Epoch: 82/100... Training loss: 0.1032\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1033\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.0971\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0974\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.0963\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.1038\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1032\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1034\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.0947\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.1033\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0966\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.0955\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1028\n",
      "Epoch: 83/100... Training loss: 0.0969\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.0965\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0966\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0971\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.0974\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0961\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.1036\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.1048\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.0964\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1039\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.1054\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0979\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.0973\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1028\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0965\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.0969\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.0969\n",
      "Epoch: 83/100... Training loss: 0.0969\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.0963\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1039\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0951\n",
      "Epoch: 83/100... Training loss: 0.1027\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0979\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1039\n",
      "Epoch: 83/100... Training loss: 0.1036\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1029\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1032\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0954\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0973\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0973\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.1035\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.1028\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.1048\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1029\n",
      "Epoch: 84/100... Training loss: 0.1027\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.1057\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1017\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1044\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0970\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.0966\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1024\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1030\n",
      "Epoch: 84/100... Training loss: 0.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100... Training loss: 0.1040\n",
      "Epoch: 84/100... Training loss: 0.0958\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.1031\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.1027\n",
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0957\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.1048\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.0966\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0972\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1034\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1028\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1054\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1036\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1046\n",
      "Epoch: 84/100... Training loss: 0.0965\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1034\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0954\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0968\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.1035\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.1029\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1040\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1028\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0968\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.1040\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0970\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1038\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.0970\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.0974\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.1025\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1042\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.1033\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0952\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1041\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0968\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.1040\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.1044\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.1046\n",
      "Epoch: 85/100... Training loss: 0.0967\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1039\n",
      "Epoch: 85/100... Training loss: 0.1022\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1033\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.0964\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1024\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1033\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1028\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0960\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0963\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.1041\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.1046\n",
      "Epoch: 85/100... Training loss: 0.1046\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.0952\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1024\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1044\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.1044\n",
      "Epoch: 85/100... Training loss: 0.0961\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0941\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0940\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1043\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.1030\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.1035\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1022\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.1034\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0955\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0982\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.0962\n",
      "Epoch: 86/100... Training loss: 0.1026\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.1060\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.1026\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.1021\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1044\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1021\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.1035\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.1027\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1040\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1026\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0966\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1032\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0973\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.0989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/100... Training loss: 0.1024\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.1027\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0964\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.1076\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.0967\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.0966\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.1039\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.0960\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0967\n",
      "Epoch: 86/100... Training loss: 0.0982\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0960\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.1038\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.0967\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0968\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1035\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.1027\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.1048\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.0966\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1031\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1030\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.1050\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1048\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.1035\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1027\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.0962\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1029\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0978\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1028\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1033\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.0958\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1036\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.1024\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0961\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1027\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1036\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.1033\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.0959\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.0955\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.0978\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.1032\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1024\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.1056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.0977\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1036\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0953\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1035\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1037\n",
      "Epoch: 87/100... Training loss: 0.1032\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0963\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1041\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.1029\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0971\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0965\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0989\n",
      "Epoch: 88/100... Training loss: 0.1023\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.1031\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0963\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0963\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.0968\n",
      "Epoch: 88/100... Training loss: 0.1046\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.1047\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0964\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0957\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.1035\n",
      "Epoch: 88/100... Training loss: 0.1026\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0975\n",
      "Epoch: 88/100... Training loss: 0.1027\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1031\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.1026\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0961\n",
      "Epoch: 88/100... Training loss: 0.1036\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.1049\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1028\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.0967\n",
      "Epoch: 88/100... Training loss: 0.1042\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1021\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.1030\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0989\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.1023\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1028\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0954\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.1028\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0964\n",
      "Epoch: 88/100... Training loss: 0.1039\n",
      "Epoch: 88/100... Training loss: 0.1038\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0971\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1021\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.0963\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0959\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.1041\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.1047\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0968\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0971\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.0957\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0960\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0977\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1027\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.1015\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.1078\n",
      "Epoch: 89/100... Training loss: 0.1036\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1020\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0959\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0962\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.1038\n",
      "Epoch: 89/100... Training loss: 0.0981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100... Training loss: 0.1037\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1030\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.1026\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.1048\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.1031\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0951\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.1032\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.1026\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1015\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.1022\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.1034\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1037\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.1036\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1044\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1057\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1033\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0959\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1041\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1025\n",
      "Epoch: 89/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1025\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0965\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.1022\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.1037\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0963\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0977\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.0966\n",
      "Epoch: 89/100... Training loss: 0.0970\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0977\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.0948\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0966\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.1033\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0965\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.0963\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0949\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.0961\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.1031\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.1030\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1031\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.1030\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1027\n",
      "Epoch: 90/100... Training loss: 0.1027\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1038\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1042\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1035\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.1020\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0966\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1018\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.0951\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0968\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1045\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.1025\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.1058\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.1023\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1044\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.0967\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0956\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.0965\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.0972\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.0972\n",
      "Epoch: 90/100... Training loss: 0.0968\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0968\n",
      "Epoch: 90/100... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.0965\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1041\n",
      "Epoch: 90/100... Training loss: 0.0965\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1050\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.1037\n",
      "Epoch: 90/100... Training loss: 0.1031\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.1022\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.1025\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.1034\n",
      "Epoch: 90/100... Training loss: 0.0961\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1062\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1027\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1040\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.0957\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0969\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1020\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.0965\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0957\n",
      "Epoch: 91/100... Training loss: 0.0969\n",
      "Epoch: 91/100... Training loss: 0.1024\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1041\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.1044\n",
      "Epoch: 91/100... Training loss: 0.1027\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.1025\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1041\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0967\n",
      "Epoch: 91/100... Training loss: 0.0969\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.0952\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.1030\n",
      "Epoch: 91/100... Training loss: 0.0969\n",
      "Epoch: 91/100... Training loss: 0.1033\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0981\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.1024\n",
      "Epoch: 91/100... Training loss: 0.0975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100... Training loss: 0.0958\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.0971\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1021\n",
      "Epoch: 91/100... Training loss: 0.0972\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.1021\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.0960\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.0943\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1024\n",
      "Epoch: 91/100... Training loss: 0.1036\n",
      "Epoch: 91/100... Training loss: 0.0971\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.1043\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0965\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.0970\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1022\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.1027\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0965\n",
      "Epoch: 91/100... Training loss: 0.0943\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.1020\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.1038\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.1025\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.1034\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1028\n",
      "Epoch: 91/100... Training loss: 0.0962\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0949\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.1006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.0968\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1036\n",
      "Epoch: 92/100... Training loss: 0.1039\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1035\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1052\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0955\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.1029\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.1035\n",
      "Epoch: 92/100... Training loss: 0.0953\n",
      "Epoch: 92/100... Training loss: 0.0964\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0969\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0946\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.0967\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0945\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1033\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.0958\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1032\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0963\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0969\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.0979\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0973\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0966\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.0955\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1036\n",
      "Epoch: 92/100... Training loss: 0.1024\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0967\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.1038\n",
      "Epoch: 92/100... Training loss: 0.1029\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0949\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.0962\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.1040\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.1032\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0964\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.1037\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.1042\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.1024\n",
      "Epoch: 92/100... Training loss: 0.1037\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.1036\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0965\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0958\n",
      "Epoch: 93/100... Training loss: 0.0963\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0957\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.1034\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0966\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1053\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1033\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1024\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0937\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.1030\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.1040\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1021\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1051\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1027\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0952\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.1027\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0948\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0944\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.0947\n",
      "Epoch: 93/100... Training loss: 0.1035\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0968\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0958\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.0969\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.0959\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.1035\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1030\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.1018\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.1021\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.1021\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.1017\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1022\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.1040\n",
      "Epoch: 94/100... Training loss: 0.1028\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0964\n",
      "Epoch: 94/100... Training loss: 0.0972\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.0958\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1067\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1031\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.0960\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0983\n",
      "Epoch: 94/100... Training loss: 0.1021\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.0967\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.1030\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0987\n",
      "Epoch: 94/100... Training loss: 0.1027\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0948\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1027\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1033\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0968\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.0983\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.1052\n",
      "Epoch: 94/100... Training loss: 0.1022\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.1026\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0967\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.1026\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0960\n",
      "Epoch: 94/100... Training loss: 0.1041\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1030\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.1029\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.0972\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.1022\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1027\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.1022\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0968\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.1026\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0972\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.0951\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1032\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.1042\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1037\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.0987\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0971\n",
      "Epoch: 94/100... Training loss: 0.1034\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0953\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1036\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0973\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.1031\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.1023\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1025\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0951\n",
      "Epoch: 95/100... Training loss: 0.1045\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.1032\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0938\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.0967\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.0955\n",
      "Epoch: 95/100... Training loss: 0.1035\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0973\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.1027\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0966\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.1051\n",
      "Epoch: 95/100... Training loss: 0.1027\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0965\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.1035\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.1031\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1027\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.0970\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0966\n",
      "Epoch: 95/100... Training loss: 0.0955\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.0961\n",
      "Epoch: 95/100... Training loss: 0.1032\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.1045\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1037\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.0973\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0966\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.1020\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.0972\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.1045\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1026\n",
      "Epoch: 96/100... Training loss: 0.0970\n",
      "Epoch: 96/100... Training loss: 0.0966\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0972\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0930\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.1020\n",
      "Epoch: 96/100... Training loss: 0.1033\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.1006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.0970\n",
      "Epoch: 96/100... Training loss: 0.0960\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.0952\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0968\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0960\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1022\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1044\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1043\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1031\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1026\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.1024\n",
      "Epoch: 96/100... Training loss: 0.1030\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.1036\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0959\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.1048\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.1030\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.1043\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.1032\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0956\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1037\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.1020\n",
      "Epoch: 96/100... Training loss: 0.0955\n",
      "Epoch: 96/100... Training loss: 0.0966\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0964\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.0966\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0951\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0964\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1036\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1030\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.1025\n",
      "Epoch: 97/100... Training loss: 0.1025\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1030\n",
      "Epoch: 97/100... Training loss: 0.0968\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.1031\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0967\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0968\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.0964\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.1034\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.1023\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.1026\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.1022\n",
      "Epoch: 97/100... Training loss: 0.1028\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.1042\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0957\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.0960\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0960\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0964\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.1028\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0934\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1017\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.1020\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0958\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.1066\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.0967\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.1031\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.1027\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.1023\n",
      "Epoch: 97/100... Training loss: 0.1028\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.0956\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1026\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.1035\n",
      "Epoch: 97/100... Training loss: 0.1046\n",
      "Epoch: 97/100... Training loss: 0.1028\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.1025\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.1045\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.0968\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0957\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0964\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.0953\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1044\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0967\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.1017\n",
      "Epoch: 97/100... Training loss: 0.1037\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0948\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1038\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0948\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0963\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.0966\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0969\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0946\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1040\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.1026\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.1026\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.0954\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0953\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1029\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98/100... Training loss: 0.0964\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.0942\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1043\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.1028\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0957\n",
      "Epoch: 98/100... Training loss: 0.1032\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1033\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1027\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0958\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.0963\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.0967\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.1064\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1029\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.0959\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.1034\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.0962\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.1023\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.0964\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0969\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.1034\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0948\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1050\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0975\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0975\n",
      "Epoch: 99/100... Training loss: 0.0960\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0968\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.1018\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1028\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.1027\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.1046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.0966\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.1029\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.1031\n",
      "Epoch: 99/100... Training loss: 0.0969\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1032\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1021\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.1025\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.1035\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.0968\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.1040\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.0947\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.1031\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1048\n",
      "Epoch: 99/100... Training loss: 0.0955\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0979\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.1048\n",
      "Epoch: 99/100... Training loss: 0.0954\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0957\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.1025\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.0966\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.0959\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1030\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.1034\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.0999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0960\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0956\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.0967\n",
      "Epoch: 100/100... Training loss: 0.0968\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0956\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0949\n",
      "Epoch: 100/100... Training loss: 0.1045\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.1063\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.1029\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1048\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.0959\n",
      "Epoch: 100/100... Training loss: 0.1025\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1028\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.1026\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.1039\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.0972\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0950\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0968\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0957\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1026\n",
      "Epoch: 100/100... Training loss: 0.0973\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.0970\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0963\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.1028\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0936\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1028\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.1037\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.1043\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.0963\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.0964\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.0960\n",
      "Epoch: 100/100... Training loss: 0.0955\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0972\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.0970\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0958\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0967\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.0960\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1035\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1033\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0995\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 200\n",
    "# Set's how much noise we're adding to the MNIST images\n",
    "noise_factor = 0.5\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        # Get images from the batch\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        \n",
    "        # Add random noise to the input images\n",
    "        noisy_imgs = imgs + noise_factor * np.random.randn(*imgs.shape)\n",
    "        # Clip the images to be between 0 and 1\n",
    "        noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "        \n",
    "        # Noisy images as inputs, original images as targets\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: noisy_imgs,\n",
    "                                                         targets_: imgs})\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out the performance\n",
    "\n",
    "Here I'm adding noise to the test images and passing them through the autoencoder. It does a suprising great job of removing the noise, even though it's sometimes difficult to tell what the original number is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABawAAAEsCAYAAAAvofT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCF4GEboAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29f1b928eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "noisy_imgs = in_imgs + noise_factor * np.random.randn(*in_imgs.shape)\n",
    "noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: noisy_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([noisy_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Residuals and Principal Component\n",
    "\n",
    "We now need to determine how well this autoencoder works. For each image in the MNIST test dataset, compute the residual error of the autoencoder. This is the difference between the true image and the reconstruction of that image by the autoencoder. It is an image itself. Prepare a figure showing the mean residual error, and the first five principal components. Each is an image. You should preserve signs (i.e. the mean residual error may have negative as well as positive entries). The way to show these images most informatively is to use a mid gray value for zero, then darker values for more negative image values and lighter values for more positive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_imgs = mnist.test.images\n",
    "\n",
    "#Calculate residual mean of auto-encoded images\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: in_imgs.reshape((-1, 28, 28, 1))}).reshape(-1, 28, 28)\n",
    "ae_mean_residual = np.mean(np.subtract(in_imgs.reshape(-1, 28, 28), reconstructed), axis=0)\n",
    "\n",
    "#Get first 5 principal components\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(in_imgs)\n",
    "pc = pca.components_\n",
    "\n",
    "images = np.concatenate((ae_mean_residual.reshape(-1, 28, 28), pc.reshape(-1, 28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot mean and five principal components on the same gray scale for all six images, chosen so the largest absolute value over all six images is full dark or full light respectively and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABawAAAEsCAYAAAAvofT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29f464fd710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_images(imgs):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=imgs.shape[0], sharex=True, sharey=True, figsize=(20,4))\n",
    "    for img, ax in zip(imgs, axes):\n",
    "        ax.imshow(img, cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    fig.tight_layout(pad=0.1)\n",
    "\n",
    "#Normailze with global value\n",
    "image_1 = np.copy(images)\n",
    "max_val = np.max(images1)\n",
    "min_val = np.min(images1)\n",
    "\n",
    "images1 = (image_1 - min_val) / (max_val - min_val)\n",
    "\n",
    "show_images(images1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot mean and five principal components on a scale where the gray scale is chosen for each image separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABawAAAEsCAYAAAAvofT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29f45f65550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normailze with each image\n",
    "images2 = np.copy(images)\n",
    "\n",
    "for i in range(6):\n",
    "    max_val = np.max(images[i])\n",
    "    min_val = np.min(images[i])\n",
    "\n",
    "    images2[i,] = (images2[i,] - min_val) / (max_val - min_val)\n",
    "\n",
    "show_images(images2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders\n",
    "\n",
    "We will evaluate variational autoencoders applied to the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://github.com/hwalsuklee/tensorflow-mnist-VAE\n",
    "* https://github.com/kvfrans/variational-autoencoder \n",
    "* http://kvfrans.com/variational-autoencoders-explained/ \n",
    "\n",
    "We now need to determine how well the codes produced by this autoencoder can be interpolated.\n",
    "* For 10 pairs of MNIST test images of the same digit, selected at random, compute the code for each image of the pair. Now compute 7 evenly spaced linear interpolates between these codes, and decode the result into images. Prepare a figure showing this interpolate. Lay out the figure so each interpolate is a row. On the left of the row is the first test image; then the interpolate closest to it; etc; to the last test image. You should have a 10 rows and 9 columns of images.\n",
    "* For 10 pairs of MNIST test images of different digits, selected at random, compute the code for each image of the pair. Now compute 7 evenly spaced linear interpolates between these codes, and decode the result into images. Prepare a figure showing this interpolate. Lay out the figure so each interpolate is a row. On the left of the row is the first test image; then the interpolate closest to it; etc; to the last test image. You should have a 10 rows and 9 columns of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./MNIST_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import vae\n",
    "\n",
    "dim_z = 2\n",
    "n_hidden = 500\n",
    "learn_rate = 1e-3\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, mnist.train.images.shape[1]], name='target_img')\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "# input for PMLR\n",
    "z_in = tf.placeholder(tf.float32, shape=[None, dim_z], name='latent_variable')\n",
    "\n",
    "# network architecture\n",
    "y, z, loss, neg_marginal_likelihood, KL_divergence = vae.autoencoder(x, x, mnist.train.images.shape[1], dim_z, n_hidden, keep_prob)\n",
    "\n",
    "# optimization\n",
    "train_op = tf.train.AdamOptimizer(learn_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: L_tot 188.28 L_likelihood 181.25 L_divergence 7.03\n",
      "epoch 1: L_tot 178.97 L_likelihood 171.69 L_divergence 7.27\n",
      "epoch 2: L_tot 166.75 L_likelihood 160.84 L_divergence 5.91\n",
      "epoch 3: L_tot 161.12 L_likelihood 155.02 L_divergence 6.10\n",
      "epoch 4: L_tot 154.51 L_likelihood 148.43 L_divergence 6.08\n",
      "epoch 5: L_tot 157.87 L_likelihood 151.58 L_divergence 6.28\n",
      "epoch 6: L_tot 156.39 L_likelihood 150.16 L_divergence 6.22\n",
      "epoch 7: L_tot 155.03 L_likelihood 148.77 L_divergence 6.26\n",
      "epoch 8: L_tot 146.28 L_likelihood 140.22 L_divergence 6.06\n",
      "epoch 9: L_tot 152.87 L_likelihood 147.04 L_divergence 5.83\n",
      "epoch 10: L_tot 153.66 L_likelihood 147.43 L_divergence 6.23\n",
      "epoch 11: L_tot 153.24 L_likelihood 147.05 L_divergence 6.19\n",
      "epoch 12: L_tot 151.28 L_likelihood 145.08 L_divergence 6.19\n",
      "epoch 13: L_tot 155.91 L_likelihood 149.37 L_divergence 6.53\n",
      "epoch 14: L_tot 157.11 L_likelihood 150.53 L_divergence 6.58\n",
      "epoch 15: L_tot 153.13 L_likelihood 146.67 L_divergence 6.46\n",
      "epoch 16: L_tot 155.81 L_likelihood 148.83 L_divergence 6.98\n",
      "epoch 17: L_tot 149.33 L_likelihood 143.06 L_divergence 6.27\n",
      "epoch 18: L_tot 150.84 L_likelihood 144.15 L_divergence 6.70\n",
      "epoch 19: L_tot 153.02 L_likelihood 146.88 L_divergence 6.14\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([[-0.22398895,  3.1181712 ]], dtype=float32) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlnd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    276\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 277\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    278\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlnd\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3322\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlnd\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3411\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[1;32m-> 3412\u001b[1;33m                                                            types_str))\n\u001b[0m\u001b[0;32m   3413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a ndarray into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-0883a2895e5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mz_codes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mz_in\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz_codes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlnd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlnd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1113\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlnd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \"\"\"\n\u001b[0;32m    419\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlnd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlnd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    279\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[0;32m    280\u001b[0m                         \u001b[1;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m                         % (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[0;32m    282\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument array([[-0.22398895,  3.1181712 ]], dtype=float32) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "total_batch = mnist.train.images.shape[0]//batch_size\n",
    "min_tot_loss = 1e99\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer(), feed_dict={keep_prob : 0.9})\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(total_batch):\n",
    "            train_images, train_labels = mnist.train.next_batch(batch_size)\n",
    "            _, tot_loss, loss_likelihood, loss_divergence = sess.run(\n",
    "                    (train_op, loss, neg_marginal_likelihood, KL_divergence),\n",
    "                    feed_dict={x: train_images, keep_prob : 0.9})\n",
    "            \n",
    "        print(\"epoch %d: L_tot %03.2f L_likelihood %03.2f L_divergence %03.2f\" % (epoch, tot_loss, loss_likelihood, loss_divergence))\n",
    "    \n",
    "    \n",
    "    z_codes = sess.run((z), feed_dict={x: mnist.test.images[0:1,:], keep_prob : 0.9})\n",
    "    image = sess.run(decoded, feed_dict={z_in: z_codes, keep_prob : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
