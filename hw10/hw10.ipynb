{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder\n",
    "\n",
    "We will evaluate denoising autoencoders applied to the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geesi\\Anaconda3\\envs\\dlnd\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model \n",
    "\n",
    "Autoencoders can be used to denoise images quite successfully just by training the network on noisy images. We can create the noisy images ourselves by adding Gaussian noise to the training images, then clipping the values to be between 0 and 1. We'll use noisy images as input and the original, clean images as targets. Here's an example of the noisy images I generated and the denoised images.\n",
    "\n",
    "![Denoising autoencoder](assets/denoising.png)\n",
    "\n",
    "\n",
    "Since this is a harder problem for the network, we'll want to use deeper convolutional layers here, more feature maps. We wil use 32-32-16 for the depths of the convolutional layers in the encoder, and the same depths going backward through the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs_, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n",
    "# Now 14x14x32\n",
    "conv2 = tf.layers.conv2d(maxpool1, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "# Now 7x7x32\n",
    "conv3 = tf.layers.conv2d(maxpool2, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "encoded = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')\n",
    "# Now 4x4x16\n",
    "\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "# Now 7x7x16\n",
    "conv4 = tf.layers.conv2d(upsample1, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "# Now 14x14x16\n",
    "conv5 = tf.layers.conv2d(upsample2, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))\n",
    "# Now 28x28x32\n",
    "conv6 = tf.layers.conv2d(upsample3, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "\n",
    "logits = tf.layers.conv2d(conv6, 1, (3,3), padding='same', activation=None)\n",
    "#Now 28x28x1\n",
    "\n",
    "decoded = tf.nn.sigmoid(logits, name='decoded')\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Training loss: 0.6963\n",
      "Epoch: 1/100... Training loss: 0.6888\n",
      "Epoch: 1/100... Training loss: 0.6817\n",
      "Epoch: 1/100... Training loss: 0.6691\n",
      "Epoch: 1/100... Training loss: 0.6500\n",
      "Epoch: 1/100... Training loss: 0.6193\n",
      "Epoch: 1/100... Training loss: 0.5831\n",
      "Epoch: 1/100... Training loss: 0.5391\n",
      "Epoch: 1/100... Training loss: 0.5141\n",
      "Epoch: 1/100... Training loss: 0.4993\n",
      "Epoch: 1/100... Training loss: 0.5381\n",
      "Epoch: 1/100... Training loss: 0.5265\n",
      "Epoch: 1/100... Training loss: 0.5055\n",
      "Epoch: 1/100... Training loss: 0.4760\n",
      "Epoch: 1/100... Training loss: 0.4790\n",
      "Epoch: 1/100... Training loss: 0.4601\n",
      "Epoch: 1/100... Training loss: 0.4676\n",
      "Epoch: 1/100... Training loss: 0.4571\n",
      "Epoch: 1/100... Training loss: 0.4501\n",
      "Epoch: 1/100... Training loss: 0.4393\n",
      "Epoch: 1/100... Training loss: 0.4213\n",
      "Epoch: 1/100... Training loss: 0.4212\n",
      "Epoch: 1/100... Training loss: 0.4179\n",
      "Epoch: 1/100... Training loss: 0.4021\n",
      "Epoch: 1/100... Training loss: 0.3889\n",
      "Epoch: 1/100... Training loss: 0.3717\n",
      "Epoch: 1/100... Training loss: 0.3588\n",
      "Epoch: 1/100... Training loss: 0.3518\n",
      "Epoch: 1/100... Training loss: 0.3455\n",
      "Epoch: 1/100... Training loss: 0.3308\n",
      "Epoch: 1/100... Training loss: 0.3252\n",
      "Epoch: 1/100... Training loss: 0.3022\n",
      "Epoch: 1/100... Training loss: 0.3134\n",
      "Epoch: 1/100... Training loss: 0.3046\n",
      "Epoch: 1/100... Training loss: 0.2965\n",
      "Epoch: 1/100... Training loss: 0.2808\n",
      "Epoch: 1/100... Training loss: 0.2837\n",
      "Epoch: 1/100... Training loss: 0.2832\n",
      "Epoch: 1/100... Training loss: 0.2742\n",
      "Epoch: 1/100... Training loss: 0.2784\n",
      "Epoch: 1/100... Training loss: 0.2721\n",
      "Epoch: 1/100... Training loss: 0.2721\n",
      "Epoch: 1/100... Training loss: 0.2686\n",
      "Epoch: 1/100... Training loss: 0.2652\n",
      "Epoch: 1/100... Training loss: 0.2735\n",
      "Epoch: 1/100... Training loss: 0.2662\n",
      "Epoch: 1/100... Training loss: 0.2726\n",
      "Epoch: 1/100... Training loss: 0.2587\n",
      "Epoch: 1/100... Training loss: 0.2708\n",
      "Epoch: 1/100... Training loss: 0.2617\n",
      "Epoch: 1/100... Training loss: 0.2672\n",
      "Epoch: 1/100... Training loss: 0.2642\n",
      "Epoch: 1/100... Training loss: 0.2657\n",
      "Epoch: 1/100... Training loss: 0.2644\n",
      "Epoch: 1/100... Training loss: 0.2683\n",
      "Epoch: 1/100... Training loss: 0.2589\n",
      "Epoch: 1/100... Training loss: 0.2667\n",
      "Epoch: 1/100... Training loss: 0.2643\n",
      "Epoch: 1/100... Training loss: 0.2555\n",
      "Epoch: 1/100... Training loss: 0.2556\n",
      "Epoch: 1/100... Training loss: 0.2489\n",
      "Epoch: 1/100... Training loss: 0.2577\n",
      "Epoch: 1/100... Training loss: 0.2492\n",
      "Epoch: 1/100... Training loss: 0.2540\n",
      "Epoch: 1/100... Training loss: 0.2490\n",
      "Epoch: 1/100... Training loss: 0.2522\n",
      "Epoch: 1/100... Training loss: 0.2420\n",
      "Epoch: 1/100... Training loss: 0.2427\n",
      "Epoch: 1/100... Training loss: 0.2468\n",
      "Epoch: 1/100... Training loss: 0.2401\n",
      "Epoch: 1/100... Training loss: 0.2527\n",
      "Epoch: 1/100... Training loss: 0.2450\n",
      "Epoch: 1/100... Training loss: 0.2392\n",
      "Epoch: 1/100... Training loss: 0.2401\n",
      "Epoch: 1/100... Training loss: 0.2400\n",
      "Epoch: 1/100... Training loss: 0.2381\n",
      "Epoch: 1/100... Training loss: 0.2344\n",
      "Epoch: 1/100... Training loss: 0.2401\n",
      "Epoch: 1/100... Training loss: 0.2374\n",
      "Epoch: 1/100... Training loss: 0.2370\n",
      "Epoch: 1/100... Training loss: 0.2352\n",
      "Epoch: 1/100... Training loss: 0.2292\n",
      "Epoch: 1/100... Training loss: 0.2331\n",
      "Epoch: 1/100... Training loss: 0.2316\n",
      "Epoch: 1/100... Training loss: 0.2312\n",
      "Epoch: 1/100... Training loss: 0.2323\n",
      "Epoch: 1/100... Training loss: 0.2243\n",
      "Epoch: 1/100... Training loss: 0.2254\n",
      "Epoch: 1/100... Training loss: 0.2221\n",
      "Epoch: 1/100... Training loss: 0.2279\n",
      "Epoch: 1/100... Training loss: 0.2206\n",
      "Epoch: 1/100... Training loss: 0.2289\n",
      "Epoch: 1/100... Training loss: 0.2217\n",
      "Epoch: 1/100... Training loss: 0.2218\n",
      "Epoch: 1/100... Training loss: 0.2232\n",
      "Epoch: 1/100... Training loss: 0.2240\n",
      "Epoch: 1/100... Training loss: 0.2216\n",
      "Epoch: 1/100... Training loss: 0.2193\n",
      "Epoch: 1/100... Training loss: 0.2245\n",
      "Epoch: 1/100... Training loss: 0.2133\n",
      "Epoch: 1/100... Training loss: 0.2223\n",
      "Epoch: 1/100... Training loss: 0.2231\n",
      "Epoch: 1/100... Training loss: 0.2151\n",
      "Epoch: 1/100... Training loss: 0.2260\n",
      "Epoch: 1/100... Training loss: 0.2179\n",
      "Epoch: 1/100... Training loss: 0.2153\n",
      "Epoch: 1/100... Training loss: 0.2163\n",
      "Epoch: 1/100... Training loss: 0.2265\n",
      "Epoch: 1/100... Training loss: 0.2141\n",
      "Epoch: 1/100... Training loss: 0.2171\n",
      "Epoch: 1/100... Training loss: 0.2087\n",
      "Epoch: 1/100... Training loss: 0.2215\n",
      "Epoch: 1/100... Training loss: 0.2202\n",
      "Epoch: 1/100... Training loss: 0.2121\n",
      "Epoch: 1/100... Training loss: 0.2147\n",
      "Epoch: 1/100... Training loss: 0.2068\n",
      "Epoch: 1/100... Training loss: 0.2113\n",
      "Epoch: 1/100... Training loss: 0.2038\n",
      "Epoch: 1/100... Training loss: 0.2036\n",
      "Epoch: 1/100... Training loss: 0.2070\n",
      "Epoch: 1/100... Training loss: 0.2031\n",
      "Epoch: 1/100... Training loss: 0.2058\n",
      "Epoch: 1/100... Training loss: 0.2118\n",
      "Epoch: 1/100... Training loss: 0.2085\n",
      "Epoch: 1/100... Training loss: 0.2036\n",
      "Epoch: 1/100... Training loss: 0.2021\n",
      "Epoch: 1/100... Training loss: 0.2011\n",
      "Epoch: 1/100... Training loss: 0.2045\n",
      "Epoch: 1/100... Training loss: 0.2041\n",
      "Epoch: 1/100... Training loss: 0.2037\n",
      "Epoch: 1/100... Training loss: 0.2066\n",
      "Epoch: 1/100... Training loss: 0.2021\n",
      "Epoch: 1/100... Training loss: 0.2063\n",
      "Epoch: 1/100... Training loss: 0.1994\n",
      "Epoch: 1/100... Training loss: 0.1994\n",
      "Epoch: 1/100... Training loss: 0.2041\n",
      "Epoch: 1/100... Training loss: 0.1971\n",
      "Epoch: 1/100... Training loss: 0.2034\n",
      "Epoch: 1/100... Training loss: 0.2036\n",
      "Epoch: 1/100... Training loss: 0.1988\n",
      "Epoch: 1/100... Training loss: 0.1952\n",
      "Epoch: 1/100... Training loss: 0.2079\n",
      "Epoch: 1/100... Training loss: 0.1965\n",
      "Epoch: 1/100... Training loss: 0.1966\n",
      "Epoch: 1/100... Training loss: 0.2008\n",
      "Epoch: 1/100... Training loss: 0.1954\n",
      "Epoch: 1/100... Training loss: 0.1962\n",
      "Epoch: 1/100... Training loss: 0.1952\n",
      "Epoch: 1/100... Training loss: 0.1946\n",
      "Epoch: 1/100... Training loss: 0.1991\n",
      "Epoch: 1/100... Training loss: 0.1958\n",
      "Epoch: 1/100... Training loss: 0.1980\n",
      "Epoch: 1/100... Training loss: 0.1939\n",
      "Epoch: 1/100... Training loss: 0.1939\n",
      "Epoch: 1/100... Training loss: 0.1983\n",
      "Epoch: 1/100... Training loss: 0.1952\n",
      "Epoch: 1/100... Training loss: 0.1935\n",
      "Epoch: 1/100... Training loss: 0.1945\n",
      "Epoch: 1/100... Training loss: 0.1864\n",
      "Epoch: 1/100... Training loss: 0.1960\n",
      "Epoch: 1/100... Training loss: 0.2003\n",
      "Epoch: 1/100... Training loss: 0.1909\n",
      "Epoch: 1/100... Training loss: 0.1946\n",
      "Epoch: 1/100... Training loss: 0.1966\n",
      "Epoch: 1/100... Training loss: 0.1898\n",
      "Epoch: 1/100... Training loss: 0.1925\n",
      "Epoch: 1/100... Training loss: 0.1906\n",
      "Epoch: 1/100... Training loss: 0.1873\n",
      "Epoch: 1/100... Training loss: 0.1897\n",
      "Epoch: 1/100... Training loss: 0.1828\n",
      "Epoch: 1/100... Training loss: 0.1903\n",
      "Epoch: 1/100... Training loss: 0.1890\n",
      "Epoch: 1/100... Training loss: 0.1933\n",
      "Epoch: 1/100... Training loss: 0.1944\n",
      "Epoch: 1/100... Training loss: 0.1868\n",
      "Epoch: 1/100... Training loss: 0.1968\n",
      "Epoch: 1/100... Training loss: 0.1840\n",
      "Epoch: 1/100... Training loss: 0.1824\n",
      "Epoch: 1/100... Training loss: 0.1887\n",
      "Epoch: 1/100... Training loss: 0.1856\n",
      "Epoch: 1/100... Training loss: 0.1873\n",
      "Epoch: 1/100... Training loss: 0.1855\n",
      "Epoch: 1/100... Training loss: 0.1848\n",
      "Epoch: 1/100... Training loss: 0.1865\n",
      "Epoch: 1/100... Training loss: 0.1884\n",
      "Epoch: 1/100... Training loss: 0.1939\n",
      "Epoch: 1/100... Training loss: 0.1884\n",
      "Epoch: 1/100... Training loss: 0.1880\n",
      "Epoch: 1/100... Training loss: 0.1923\n",
      "Epoch: 1/100... Training loss: 0.1891\n",
      "Epoch: 1/100... Training loss: 0.1876\n",
      "Epoch: 1/100... Training loss: 0.1816\n",
      "Epoch: 1/100... Training loss: 0.1876\n",
      "Epoch: 1/100... Training loss: 0.1859\n",
      "Epoch: 1/100... Training loss: 0.1886\n",
      "Epoch: 1/100... Training loss: 0.1823\n",
      "Epoch: 1/100... Training loss: 0.1843\n",
      "Epoch: 1/100... Training loss: 0.1846\n",
      "Epoch: 1/100... Training loss: 0.1803\n",
      "Epoch: 1/100... Training loss: 0.1839\n",
      "Epoch: 1/100... Training loss: 0.1838\n",
      "Epoch: 1/100... Training loss: 0.1843\n",
      "Epoch: 1/100... Training loss: 0.1881\n",
      "Epoch: 1/100... Training loss: 0.1898\n",
      "Epoch: 1/100... Training loss: 0.1789\n",
      "Epoch: 1/100... Training loss: 0.1855\n",
      "Epoch: 1/100... Training loss: 0.1845\n",
      "Epoch: 1/100... Training loss: 0.1895\n",
      "Epoch: 1/100... Training loss: 0.1816\n",
      "Epoch: 1/100... Training loss: 0.1830\n",
      "Epoch: 1/100... Training loss: 0.1791\n",
      "Epoch: 1/100... Training loss: 0.1866\n",
      "Epoch: 1/100... Training loss: 0.1856\n",
      "Epoch: 1/100... Training loss: 0.1809\n",
      "Epoch: 1/100... Training loss: 0.1856\n",
      "Epoch: 1/100... Training loss: 0.1790\n",
      "Epoch: 1/100... Training loss: 0.1809\n",
      "Epoch: 1/100... Training loss: 0.1803\n",
      "Epoch: 1/100... Training loss: 0.1768\n",
      "Epoch: 1/100... Training loss: 0.1765\n",
      "Epoch: 1/100... Training loss: 0.1848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Training loss: 0.1785\n",
      "Epoch: 1/100... Training loss: 0.1754\n",
      "Epoch: 1/100... Training loss: 0.1816\n",
      "Epoch: 1/100... Training loss: 0.1784\n",
      "Epoch: 1/100... Training loss: 0.1807\n",
      "Epoch: 1/100... Training loss: 0.1693\n",
      "Epoch: 1/100... Training loss: 0.1744\n",
      "Epoch: 1/100... Training loss: 0.1791\n",
      "Epoch: 1/100... Training loss: 0.1737\n",
      "Epoch: 1/100... Training loss: 0.1771\n",
      "Epoch: 1/100... Training loss: 0.1763\n",
      "Epoch: 1/100... Training loss: 0.1742\n",
      "Epoch: 1/100... Training loss: 0.1808\n",
      "Epoch: 1/100... Training loss: 0.1711\n",
      "Epoch: 1/100... Training loss: 0.1775\n",
      "Epoch: 1/100... Training loss: 0.1765\n",
      "Epoch: 1/100... Training loss: 0.1787\n",
      "Epoch: 1/100... Training loss: 0.1769\n",
      "Epoch: 1/100... Training loss: 0.1761\n",
      "Epoch: 1/100... Training loss: 0.1771\n",
      "Epoch: 1/100... Training loss: 0.1748\n",
      "Epoch: 1/100... Training loss: 0.1785\n",
      "Epoch: 1/100... Training loss: 0.1716\n",
      "Epoch: 1/100... Training loss: 0.1741\n",
      "Epoch: 1/100... Training loss: 0.1694\n",
      "Epoch: 1/100... Training loss: 0.1721\n",
      "Epoch: 1/100... Training loss: 0.1715\n",
      "Epoch: 1/100... Training loss: 0.1719\n",
      "Epoch: 1/100... Training loss: 0.1677\n",
      "Epoch: 1/100... Training loss: 0.1780\n",
      "Epoch: 1/100... Training loss: 0.1685\n",
      "Epoch: 1/100... Training loss: 0.1752\n",
      "Epoch: 1/100... Training loss: 0.1701\n",
      "Epoch: 1/100... Training loss: 0.1720\n",
      "Epoch: 1/100... Training loss: 0.1687\n",
      "Epoch: 1/100... Training loss: 0.1654\n",
      "Epoch: 1/100... Training loss: 0.1744\n",
      "Epoch: 1/100... Training loss: 0.1775\n",
      "Epoch: 1/100... Training loss: 0.1750\n",
      "Epoch: 1/100... Training loss: 0.1680\n",
      "Epoch: 1/100... Training loss: 0.1678\n",
      "Epoch: 1/100... Training loss: 0.1742\n",
      "Epoch: 1/100... Training loss: 0.1679\n",
      "Epoch: 1/100... Training loss: 0.1712\n",
      "Epoch: 1/100... Training loss: 0.1745\n",
      "Epoch: 1/100... Training loss: 0.1680\n",
      "Epoch: 1/100... Training loss: 0.1717\n",
      "Epoch: 1/100... Training loss: 0.1738\n",
      "Epoch: 1/100... Training loss: 0.1664\n",
      "Epoch: 1/100... Training loss: 0.1679\n",
      "Epoch: 1/100... Training loss: 0.1667\n",
      "Epoch: 1/100... Training loss: 0.1696\n",
      "Epoch: 1/100... Training loss: 0.1686\n",
      "Epoch: 1/100... Training loss: 0.1672\n",
      "Epoch: 1/100... Training loss: 0.1716\n",
      "Epoch: 1/100... Training loss: 0.1626\n",
      "Epoch: 1/100... Training loss: 0.1698\n",
      "Epoch: 1/100... Training loss: 0.1707\n",
      "Epoch: 1/100... Training loss: 0.1630\n",
      "Epoch: 1/100... Training loss: 0.1695\n",
      "Epoch: 1/100... Training loss: 0.1739\n",
      "Epoch: 1/100... Training loss: 0.1612\n",
      "Epoch: 1/100... Training loss: 0.1734\n",
      "Epoch: 1/100... Training loss: 0.1657\n",
      "Epoch: 1/100... Training loss: 0.1680\n",
      "Epoch: 1/100... Training loss: 0.1687\n",
      "Epoch: 1/100... Training loss: 0.1631\n",
      "Epoch: 1/100... Training loss: 0.1685\n",
      "Epoch: 1/100... Training loss: 0.1694\n",
      "Epoch: 1/100... Training loss: 0.1694\n",
      "Epoch: 1/100... Training loss: 0.1620\n",
      "Epoch: 1/100... Training loss: 0.1705\n",
      "Epoch: 1/100... Training loss: 0.1647\n",
      "Epoch: 1/100... Training loss: 0.1626\n",
      "Epoch: 1/100... Training loss: 0.1607\n",
      "Epoch: 1/100... Training loss: 0.1577\n",
      "Epoch: 1/100... Training loss: 0.1671\n",
      "Epoch: 1/100... Training loss: 0.1652\n",
      "Epoch: 1/100... Training loss: 0.1668\n",
      "Epoch: 2/100... Training loss: 0.1652\n",
      "Epoch: 2/100... Training loss: 0.1633\n",
      "Epoch: 2/100... Training loss: 0.1657\n",
      "Epoch: 2/100... Training loss: 0.1644\n",
      "Epoch: 2/100... Training loss: 0.1660\n",
      "Epoch: 2/100... Training loss: 0.1681\n",
      "Epoch: 2/100... Training loss: 0.1612\n",
      "Epoch: 2/100... Training loss: 0.1726\n",
      "Epoch: 2/100... Training loss: 0.1665\n",
      "Epoch: 2/100... Training loss: 0.1623\n",
      "Epoch: 2/100... Training loss: 0.1680\n",
      "Epoch: 2/100... Training loss: 0.1568\n",
      "Epoch: 2/100... Training loss: 0.1574\n",
      "Epoch: 2/100... Training loss: 0.1638\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1652\n",
      "Epoch: 2/100... Training loss: 0.1617\n",
      "Epoch: 2/100... Training loss: 0.1612\n",
      "Epoch: 2/100... Training loss: 0.1645\n",
      "Epoch: 2/100... Training loss: 0.1687\n",
      "Epoch: 2/100... Training loss: 0.1615\n",
      "Epoch: 2/100... Training loss: 0.1647\n",
      "Epoch: 2/100... Training loss: 0.1576\n",
      "Epoch: 2/100... Training loss: 0.1565\n",
      "Epoch: 2/100... Training loss: 0.1605\n",
      "Epoch: 2/100... Training loss: 0.1580\n",
      "Epoch: 2/100... Training loss: 0.1566\n",
      "Epoch: 2/100... Training loss: 0.1645\n",
      "Epoch: 2/100... Training loss: 0.1591\n",
      "Epoch: 2/100... Training loss: 0.1550\n",
      "Epoch: 2/100... Training loss: 0.1594\n",
      "Epoch: 2/100... Training loss: 0.1671\n",
      "Epoch: 2/100... Training loss: 0.1615\n",
      "Epoch: 2/100... Training loss: 0.1536\n",
      "Epoch: 2/100... Training loss: 0.1642\n",
      "Epoch: 2/100... Training loss: 0.1655\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1566\n",
      "Epoch: 2/100... Training loss: 0.1611\n",
      "Epoch: 2/100... Training loss: 0.1556\n",
      "Epoch: 2/100... Training loss: 0.1568\n",
      "Epoch: 2/100... Training loss: 0.1610\n",
      "Epoch: 2/100... Training loss: 0.1556\n",
      "Epoch: 2/100... Training loss: 0.1596\n",
      "Epoch: 2/100... Training loss: 0.1617\n",
      "Epoch: 2/100... Training loss: 0.1580\n",
      "Epoch: 2/100... Training loss: 0.1557\n",
      "Epoch: 2/100... Training loss: 0.1565\n",
      "Epoch: 2/100... Training loss: 0.1566\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1619\n",
      "Epoch: 2/100... Training loss: 0.1572\n",
      "Epoch: 2/100... Training loss: 0.1563\n",
      "Epoch: 2/100... Training loss: 0.1563\n",
      "Epoch: 2/100... Training loss: 0.1558\n",
      "Epoch: 2/100... Training loss: 0.1627\n",
      "Epoch: 2/100... Training loss: 0.1619\n",
      "Epoch: 2/100... Training loss: 0.1536\n",
      "Epoch: 2/100... Training loss: 0.1537\n",
      "Epoch: 2/100... Training loss: 0.1546\n",
      "Epoch: 2/100... Training loss: 0.1542\n",
      "Epoch: 2/100... Training loss: 0.1537\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1566\n",
      "Epoch: 2/100... Training loss: 0.1592\n",
      "Epoch: 2/100... Training loss: 0.1530\n",
      "Epoch: 2/100... Training loss: 0.1547\n",
      "Epoch: 2/100... Training loss: 0.1562\n",
      "Epoch: 2/100... Training loss: 0.1580\n",
      "Epoch: 2/100... Training loss: 0.1561\n",
      "Epoch: 2/100... Training loss: 0.1596\n",
      "Epoch: 2/100... Training loss: 0.1589\n",
      "Epoch: 2/100... Training loss: 0.1544\n",
      "Epoch: 2/100... Training loss: 0.1542\n",
      "Epoch: 2/100... Training loss: 0.1602\n",
      "Epoch: 2/100... Training loss: 0.1611\n",
      "Epoch: 2/100... Training loss: 0.1541\n",
      "Epoch: 2/100... Training loss: 0.1535\n",
      "Epoch: 2/100... Training loss: 0.1552\n",
      "Epoch: 2/100... Training loss: 0.1546\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1534\n",
      "Epoch: 2/100... Training loss: 0.1546\n",
      "Epoch: 2/100... Training loss: 0.1541\n",
      "Epoch: 2/100... Training loss: 0.1563\n",
      "Epoch: 2/100... Training loss: 0.1585\n",
      "Epoch: 2/100... Training loss: 0.1512\n",
      "Epoch: 2/100... Training loss: 0.1588\n",
      "Epoch: 2/100... Training loss: 0.1599\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1601\n",
      "Epoch: 2/100... Training loss: 0.1567\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1588\n",
      "Epoch: 2/100... Training loss: 0.1569\n",
      "Epoch: 2/100... Training loss: 0.1570\n",
      "Epoch: 2/100... Training loss: 0.1548\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1530\n",
      "Epoch: 2/100... Training loss: 0.1522\n",
      "Epoch: 2/100... Training loss: 0.1567\n",
      "Epoch: 2/100... Training loss: 0.1541\n",
      "Epoch: 2/100... Training loss: 0.1514\n",
      "Epoch: 2/100... Training loss: 0.1474\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1558\n",
      "Epoch: 2/100... Training loss: 0.1488\n",
      "Epoch: 2/100... Training loss: 0.1553\n",
      "Epoch: 2/100... Training loss: 0.1566\n",
      "Epoch: 2/100... Training loss: 0.1471\n",
      "Epoch: 2/100... Training loss: 0.1518\n",
      "Epoch: 2/100... Training loss: 0.1538\n",
      "Epoch: 2/100... Training loss: 0.1534\n",
      "Epoch: 2/100... Training loss: 0.1511\n",
      "Epoch: 2/100... Training loss: 0.1511\n",
      "Epoch: 2/100... Training loss: 0.1492\n",
      "Epoch: 2/100... Training loss: 0.1511\n",
      "Epoch: 2/100... Training loss: 0.1550\n",
      "Epoch: 2/100... Training loss: 0.1535\n",
      "Epoch: 2/100... Training loss: 0.1501\n",
      "Epoch: 2/100... Training loss: 0.1531\n",
      "Epoch: 2/100... Training loss: 0.1530\n",
      "Epoch: 2/100... Training loss: 0.1514\n",
      "Epoch: 2/100... Training loss: 0.1516\n",
      "Epoch: 2/100... Training loss: 0.1536\n",
      "Epoch: 2/100... Training loss: 0.1455\n",
      "Epoch: 2/100... Training loss: 0.1470\n",
      "Epoch: 2/100... Training loss: 0.1509\n",
      "Epoch: 2/100... Training loss: 0.1479\n",
      "Epoch: 2/100... Training loss: 0.1528\n",
      "Epoch: 2/100... Training loss: 0.1565\n",
      "Epoch: 2/100... Training loss: 0.1495\n",
      "Epoch: 2/100... Training loss: 0.1466\n",
      "Epoch: 2/100... Training loss: 0.1561\n",
      "Epoch: 2/100... Training loss: 0.1501\n",
      "Epoch: 2/100... Training loss: 0.1519\n",
      "Epoch: 2/100... Training loss: 0.1505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100... Training loss: 0.1511\n",
      "Epoch: 2/100... Training loss: 0.1496\n",
      "Epoch: 2/100... Training loss: 0.1515\n",
      "Epoch: 2/100... Training loss: 0.1534\n",
      "Epoch: 2/100... Training loss: 0.1483\n",
      "Epoch: 2/100... Training loss: 0.1485\n",
      "Epoch: 2/100... Training loss: 0.1499\n",
      "Epoch: 2/100... Training loss: 0.1557\n",
      "Epoch: 2/100... Training loss: 0.1498\n",
      "Epoch: 2/100... Training loss: 0.1554\n",
      "Epoch: 2/100... Training loss: 0.1545\n",
      "Epoch: 2/100... Training loss: 0.1457\n",
      "Epoch: 2/100... Training loss: 0.1477\n",
      "Epoch: 2/100... Training loss: 0.1478\n",
      "Epoch: 2/100... Training loss: 0.1486\n",
      "Epoch: 2/100... Training loss: 0.1478\n",
      "Epoch: 2/100... Training loss: 0.1468\n",
      "Epoch: 2/100... Training loss: 0.1493\n",
      "Epoch: 2/100... Training loss: 0.1498\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1507\n",
      "Epoch: 2/100... Training loss: 0.1467\n",
      "Epoch: 2/100... Training loss: 0.1510\n",
      "Epoch: 2/100... Training loss: 0.1475\n",
      "Epoch: 2/100... Training loss: 0.1484\n",
      "Epoch: 2/100... Training loss: 0.1479\n",
      "Epoch: 2/100... Training loss: 0.1488\n",
      "Epoch: 2/100... Training loss: 0.1500\n",
      "Epoch: 2/100... Training loss: 0.1505\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1518\n",
      "Epoch: 2/100... Training loss: 0.1496\n",
      "Epoch: 2/100... Training loss: 0.1448\n",
      "Epoch: 2/100... Training loss: 0.1466\n",
      "Epoch: 2/100... Training loss: 0.1453\n",
      "Epoch: 2/100... Training loss: 0.1474\n",
      "Epoch: 2/100... Training loss: 0.1474\n",
      "Epoch: 2/100... Training loss: 0.1500\n",
      "Epoch: 2/100... Training loss: 0.1497\n",
      "Epoch: 2/100... Training loss: 0.1463\n",
      "Epoch: 2/100... Training loss: 0.1476\n",
      "Epoch: 2/100... Training loss: 0.1526\n",
      "Epoch: 2/100... Training loss: 0.1441\n",
      "Epoch: 2/100... Training loss: 0.1473\n",
      "Epoch: 2/100... Training loss: 0.1476\n",
      "Epoch: 2/100... Training loss: 0.1464\n",
      "Epoch: 2/100... Training loss: 0.1459\n",
      "Epoch: 2/100... Training loss: 0.1504\n",
      "Epoch: 2/100... Training loss: 0.1520\n",
      "Epoch: 2/100... Training loss: 0.1452\n",
      "Epoch: 2/100... Training loss: 0.1473\n",
      "Epoch: 2/100... Training loss: 0.1472\n",
      "Epoch: 2/100... Training loss: 0.1456\n",
      "Epoch: 2/100... Training loss: 0.1460\n",
      "Epoch: 2/100... Training loss: 0.1472\n",
      "Epoch: 2/100... Training loss: 0.1463\n",
      "Epoch: 2/100... Training loss: 0.1448\n",
      "Epoch: 2/100... Training loss: 0.1454\n",
      "Epoch: 2/100... Training loss: 0.1461\n",
      "Epoch: 2/100... Training loss: 0.1434\n",
      "Epoch: 2/100... Training loss: 0.1460\n",
      "Epoch: 2/100... Training loss: 0.1464\n",
      "Epoch: 2/100... Training loss: 0.1452\n",
      "Epoch: 2/100... Training loss: 0.1419\n",
      "Epoch: 2/100... Training loss: 0.1434\n",
      "Epoch: 2/100... Training loss: 0.1417\n",
      "Epoch: 2/100... Training loss: 0.1459\n",
      "Epoch: 2/100... Training loss: 0.1475\n",
      "Epoch: 2/100... Training loss: 0.1450\n",
      "Epoch: 2/100... Training loss: 0.1404\n",
      "Epoch: 2/100... Training loss: 0.1417\n",
      "Epoch: 2/100... Training loss: 0.1452\n",
      "Epoch: 2/100... Training loss: 0.1485\n",
      "Epoch: 2/100... Training loss: 0.1473\n",
      "Epoch: 2/100... Training loss: 0.1452\n",
      "Epoch: 2/100... Training loss: 0.1397\n",
      "Epoch: 2/100... Training loss: 0.1452\n",
      "Epoch: 2/100... Training loss: 0.1486\n",
      "Epoch: 2/100... Training loss: 0.1470\n",
      "Epoch: 2/100... Training loss: 0.1477\n",
      "Epoch: 2/100... Training loss: 0.1522\n",
      "Epoch: 2/100... Training loss: 0.1487\n",
      "Epoch: 2/100... Training loss: 0.1431\n",
      "Epoch: 2/100... Training loss: 0.1463\n",
      "Epoch: 2/100... Training loss: 0.1428\n",
      "Epoch: 2/100... Training loss: 0.1417\n",
      "Epoch: 2/100... Training loss: 0.1388\n",
      "Epoch: 2/100... Training loss: 0.1423\n",
      "Epoch: 2/100... Training loss: 0.1416\n",
      "Epoch: 2/100... Training loss: 0.1474\n",
      "Epoch: 2/100... Training loss: 0.1470\n",
      "Epoch: 2/100... Training loss: 0.1417\n",
      "Epoch: 2/100... Training loss: 0.1430\n",
      "Epoch: 2/100... Training loss: 0.1451\n",
      "Epoch: 2/100... Training loss: 0.1460\n",
      "Epoch: 2/100... Training loss: 0.1466\n",
      "Epoch: 2/100... Training loss: 0.1453\n",
      "Epoch: 2/100... Training loss: 0.1390\n",
      "Epoch: 2/100... Training loss: 0.1422\n",
      "Epoch: 2/100... Training loss: 0.1469\n",
      "Epoch: 2/100... Training loss: 0.1457\n",
      "Epoch: 2/100... Training loss: 0.1441\n",
      "Epoch: 2/100... Training loss: 0.1462\n",
      "Epoch: 2/100... Training loss: 0.1427\n",
      "Epoch: 2/100... Training loss: 0.1433\n",
      "Epoch: 2/100... Training loss: 0.1418\n",
      "Epoch: 2/100... Training loss: 0.1421\n",
      "Epoch: 2/100... Training loss: 0.1470\n",
      "Epoch: 2/100... Training loss: 0.1477\n",
      "Epoch: 2/100... Training loss: 0.1418\n",
      "Epoch: 2/100... Training loss: 0.1427\n",
      "Epoch: 2/100... Training loss: 0.1421\n",
      "Epoch: 2/100... Training loss: 0.1405\n",
      "Epoch: 2/100... Training loss: 0.1408\n",
      "Epoch: 2/100... Training loss: 0.1425\n",
      "Epoch: 2/100... Training loss: 0.1385\n",
      "Epoch: 2/100... Training loss: 0.1408\n",
      "Epoch: 2/100... Training loss: 0.1385\n",
      "Epoch: 2/100... Training loss: 0.1441\n",
      "Epoch: 2/100... Training loss: 0.1429\n",
      "Epoch: 2/100... Training loss: 0.1424\n",
      "Epoch: 2/100... Training loss: 0.1425\n",
      "Epoch: 2/100... Training loss: 0.1460\n",
      "Epoch: 2/100... Training loss: 0.1472\n",
      "Epoch: 2/100... Training loss: 0.1403\n",
      "Epoch: 2/100... Training loss: 0.1416\n",
      "Epoch: 2/100... Training loss: 0.1398\n",
      "Epoch: 2/100... Training loss: 0.1434\n",
      "Epoch: 2/100... Training loss: 0.1390\n",
      "Epoch: 2/100... Training loss: 0.1364\n",
      "Epoch: 2/100... Training loss: 0.1443\n",
      "Epoch: 2/100... Training loss: 0.1429\n",
      "Epoch: 2/100... Training loss: 0.1403\n",
      "Epoch: 2/100... Training loss: 0.1419\n",
      "Epoch: 2/100... Training loss: 0.1399\n",
      "Epoch: 2/100... Training loss: 0.1388\n",
      "Epoch: 2/100... Training loss: 0.1415\n",
      "Epoch: 2/100... Training loss: 0.1487\n",
      "Epoch: 2/100... Training loss: 0.1432\n",
      "Epoch: 2/100... Training loss: 0.1461\n",
      "Epoch: 2/100... Training loss: 0.1359\n",
      "Epoch: 2/100... Training loss: 0.1378\n",
      "Epoch: 2/100... Training loss: 0.1386\n",
      "Epoch: 2/100... Training loss: 0.1437\n",
      "Epoch: 2/100... Training loss: 0.1399\n",
      "Epoch: 2/100... Training loss: 0.1439\n",
      "Epoch: 2/100... Training loss: 0.1421\n",
      "Epoch: 2/100... Training loss: 0.1447\n",
      "Epoch: 2/100... Training loss: 0.1409\n",
      "Epoch: 2/100... Training loss: 0.1411\n",
      "Epoch: 2/100... Training loss: 0.1393\n",
      "Epoch: 2/100... Training loss: 0.1395\n",
      "Epoch: 2/100... Training loss: 0.1413\n",
      "Epoch: 2/100... Training loss: 0.1411\n",
      "Epoch: 2/100... Training loss: 0.1426\n",
      "Epoch: 2/100... Training loss: 0.1381\n",
      "Epoch: 2/100... Training loss: 0.1427\n",
      "Epoch: 2/100... Training loss: 0.1403\n",
      "Epoch: 2/100... Training loss: 0.1417\n",
      "Epoch: 2/100... Training loss: 0.1374\n",
      "Epoch: 2/100... Training loss: 0.1437\n",
      "Epoch: 2/100... Training loss: 0.1445\n",
      "Epoch: 3/100... Training loss: 0.1440\n",
      "Epoch: 3/100... Training loss: 0.1355\n",
      "Epoch: 3/100... Training loss: 0.1431\n",
      "Epoch: 3/100... Training loss: 0.1435\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1383\n",
      "Epoch: 3/100... Training loss: 0.1460\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1439\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1426\n",
      "Epoch: 3/100... Training loss: 0.1422\n",
      "Epoch: 3/100... Training loss: 0.1400\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1390\n",
      "Epoch: 3/100... Training loss: 0.1402\n",
      "Epoch: 3/100... Training loss: 0.1425\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1408\n",
      "Epoch: 3/100... Training loss: 0.1470\n",
      "Epoch: 3/100... Training loss: 0.1448\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1428\n",
      "Epoch: 3/100... Training loss: 0.1391\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1436\n",
      "Epoch: 3/100... Training loss: 0.1400\n",
      "Epoch: 3/100... Training loss: 0.1415\n",
      "Epoch: 3/100... Training loss: 0.1388\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1377\n",
      "Epoch: 3/100... Training loss: 0.1374\n",
      "Epoch: 3/100... Training loss: 0.1377\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1426\n",
      "Epoch: 3/100... Training loss: 0.1426\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1370\n",
      "Epoch: 3/100... Training loss: 0.1400\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1423\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1398\n",
      "Epoch: 3/100... Training loss: 0.1374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1399\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1354\n",
      "Epoch: 3/100... Training loss: 0.1400\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1352\n",
      "Epoch: 3/100... Training loss: 0.1408\n",
      "Epoch: 3/100... Training loss: 0.1423\n",
      "Epoch: 3/100... Training loss: 0.1382\n",
      "Epoch: 3/100... Training loss: 0.1379\n",
      "Epoch: 3/100... Training loss: 0.1431\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1402\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1406\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1352\n",
      "Epoch: 3/100... Training loss: 0.1334\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1391\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1375\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1375\n",
      "Epoch: 3/100... Training loss: 0.1388\n",
      "Epoch: 3/100... Training loss: 0.1382\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1362\n",
      "Epoch: 3/100... Training loss: 0.1383\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1374\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1391\n",
      "Epoch: 3/100... Training loss: 0.1406\n",
      "Epoch: 3/100... Training loss: 0.1332\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1370\n",
      "Epoch: 3/100... Training loss: 0.1361\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1409\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1354\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1347\n",
      "Epoch: 3/100... Training loss: 0.1411\n",
      "Epoch: 3/100... Training loss: 0.1393\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1327\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1371\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1418\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1368\n",
      "Epoch: 3/100... Training loss: 0.1305\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1354\n",
      "Epoch: 3/100... Training loss: 0.1342\n",
      "Epoch: 3/100... Training loss: 0.1327\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1327\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1343\n",
      "Epoch: 3/100... Training loss: 0.1285\n",
      "Epoch: 3/100... Training loss: 0.1315\n",
      "Epoch: 3/100... Training loss: 0.1343\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1316\n",
      "Epoch: 3/100... Training loss: 0.1379\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1313\n",
      "Epoch: 3/100... Training loss: 0.1339\n",
      "Epoch: 3/100... Training loss: 0.1356\n",
      "Epoch: 3/100... Training loss: 0.1362\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1325\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1365\n",
      "Epoch: 3/100... Training loss: 0.1313\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1352\n",
      "Epoch: 3/100... Training loss: 0.1319\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1303\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1318\n",
      "Epoch: 3/100... Training loss: 0.1336\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1322\n",
      "Epoch: 3/100... Training loss: 0.1314\n",
      "Epoch: 3/100... Training loss: 0.1322\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1368\n",
      "Epoch: 3/100... Training loss: 0.1340\n",
      "Epoch: 3/100... Training loss: 0.1295\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1338\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1299\n",
      "Epoch: 3/100... Training loss: 0.1345\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1301\n",
      "Epoch: 3/100... Training loss: 0.1344\n",
      "Epoch: 3/100... Training loss: 0.1326\n",
      "Epoch: 3/100... Training loss: 0.1319\n",
      "Epoch: 3/100... Training loss: 0.1347\n",
      "Epoch: 3/100... Training loss: 0.1345\n",
      "Epoch: 3/100... Training loss: 0.1320\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1365\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1343\n",
      "Epoch: 3/100... Training loss: 0.1322\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1352\n",
      "Epoch: 3/100... Training loss: 0.1314\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1340\n",
      "Epoch: 3/100... Training loss: 0.1325\n",
      "Epoch: 3/100... Training loss: 0.1288\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1301\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1361\n",
      "Epoch: 3/100... Training loss: 0.1296\n",
      "Epoch: 3/100... Training loss: 0.1274\n",
      "Epoch: 3/100... Training loss: 0.1376\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1344\n",
      "Epoch: 3/100... Training loss: 0.1338\n",
      "Epoch: 3/100... Training loss: 0.1346\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1355\n",
      "Epoch: 3/100... Training loss: 0.1373\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1334\n",
      "Epoch: 3/100... Training loss: 0.1384\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1320\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1278\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1399\n",
      "Epoch: 3/100... Training loss: 0.1356\n",
      "Epoch: 3/100... Training loss: 0.1305\n",
      "Epoch: 3/100... Training loss: 0.1305\n",
      "Epoch: 3/100... Training loss: 0.1315\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1339\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1322\n",
      "Epoch: 3/100... Training loss: 0.1300\n",
      "Epoch: 3/100... Training loss: 0.1306\n",
      "Epoch: 3/100... Training loss: 0.1347\n",
      "Epoch: 3/100... Training loss: 0.1340\n",
      "Epoch: 3/100... Training loss: 0.1307\n",
      "Epoch: 3/100... Training loss: 0.1325\n",
      "Epoch: 3/100... Training loss: 0.1326\n",
      "Epoch: 3/100... Training loss: 0.1320\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1277\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1282\n",
      "Epoch: 3/100... Training loss: 0.1334\n",
      "Epoch: 3/100... Training loss: 0.1315\n",
      "Epoch: 3/100... Training loss: 0.1321\n",
      "Epoch: 3/100... Training loss: 0.1340\n",
      "Epoch: 3/100... Training loss: 0.1324\n",
      "Epoch: 3/100... Training loss: 0.1327\n",
      "Epoch: 3/100... Training loss: 0.1286\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1344\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1322\n",
      "Epoch: 3/100... Training loss: 0.1265\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1310\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100... Training loss: 0.1316\n",
      "Epoch: 3/100... Training loss: 0.1321\n",
      "Epoch: 3/100... Training loss: 0.1311\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1332\n",
      "Epoch: 3/100... Training loss: 0.1344\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1305\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1334\n",
      "Epoch: 3/100... Training loss: 0.1306\n",
      "Epoch: 3/100... Training loss: 0.1307\n",
      "Epoch: 3/100... Training loss: 0.1345\n",
      "Epoch: 3/100... Training loss: 0.1304\n",
      "Epoch: 3/100... Training loss: 0.1325\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1318\n",
      "Epoch: 3/100... Training loss: 0.1328\n",
      "Epoch: 3/100... Training loss: 0.1332\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1318\n",
      "Epoch: 3/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1347\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1331\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1340\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1374\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1373\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1363\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1364\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1328\n",
      "Epoch: 4/100... Training loss: 0.1307\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1348\n",
      "Epoch: 4/100... Training loss: 0.1305\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1276\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1336\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1371\n",
      "Epoch: 4/100... Training loss: 0.1337\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1283\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1331\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1317\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1326\n",
      "Epoch: 4/100... Training loss: 0.1364\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1338\n",
      "Epoch: 4/100... Training loss: 0.1312\n",
      "Epoch: 4/100... Training loss: 0.1261\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1337\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1270\n",
      "Epoch: 4/100... Training loss: 0.1319\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1345\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1327\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1363\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1305\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1256\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1266\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1270\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1255\n",
      "Epoch: 4/100... Training loss: 0.1251\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1276\n",
      "Epoch: 4/100... Training loss: 0.1242\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1276\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1285\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1305\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1246\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1277\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1305\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1328\n",
      "Epoch: 4/100... Training loss: 0.1289\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1289\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1259\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1244\n",
      "Epoch: 4/100... Training loss: 0.1268\n",
      "Epoch: 4/100... Training loss: 0.1267\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1323\n",
      "Epoch: 4/100... Training loss: 0.1250\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1259\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1319\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1268\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1310\n",
      "Epoch: 4/100... Training loss: 0.1251\n",
      "Epoch: 4/100... Training loss: 0.1326\n",
      "Epoch: 4/100... Training loss: 0.1267\n",
      "Epoch: 4/100... Training loss: 0.1310\n",
      "Epoch: 4/100... Training loss: 0.1323\n",
      "Epoch: 4/100... Training loss: 0.1260\n",
      "Epoch: 4/100... Training loss: 0.1277\n",
      "Epoch: 4/100... Training loss: 0.1286\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1265\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1263\n",
      "Epoch: 4/100... Training loss: 0.1307\n",
      "Epoch: 4/100... Training loss: 0.1284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100... Training loss: 0.1257\n",
      "Epoch: 4/100... Training loss: 0.1256\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1245\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1232\n",
      "Epoch: 4/100... Training loss: 0.1342\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1227\n",
      "Epoch: 4/100... Training loss: 0.1242\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1251\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1255\n",
      "Epoch: 4/100... Training loss: 0.1256\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1218\n",
      "Epoch: 4/100... Training loss: 0.1285\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1261\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1284\n",
      "Epoch: 4/100... Training loss: 0.1249\n",
      "Epoch: 4/100... Training loss: 0.1269\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1289\n",
      "Epoch: 4/100... Training loss: 0.1249\n",
      "Epoch: 4/100... Training loss: 0.1220\n",
      "Epoch: 4/100... Training loss: 0.1265\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1265\n",
      "Epoch: 4/100... Training loss: 0.1267\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1275\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1248\n",
      "Epoch: 4/100... Training loss: 0.1257\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1272\n",
      "Epoch: 4/100... Training loss: 0.1268\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1246\n",
      "Epoch: 4/100... Training loss: 0.1266\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1250\n",
      "Epoch: 4/100... Training loss: 0.1261\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1268\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1249\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1263\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1212\n",
      "Epoch: 4/100... Training loss: 0.1253\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1270\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1275\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1257\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1269\n",
      "Epoch: 4/100... Training loss: 0.1249\n",
      "Epoch: 4/100... Training loss: 0.1248\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1259\n",
      "Epoch: 4/100... Training loss: 0.1221\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1270\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1284\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1244\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1308\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1300\n",
      "Epoch: 5/100... Training loss: 0.1232\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1304\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1286\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1302\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1299\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1319\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1284\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1230\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1223\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1287\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1214\n",
      "Epoch: 5/100... Training loss: 0.1316\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1225\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1209\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1337\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1229\n",
      "Epoch: 5/100... Training loss: 0.1302\n",
      "Epoch: 5/100... Training loss: 0.1205\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1229\n",
      "Epoch: 5/100... Training loss: 0.1274\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1227\n",
      "Epoch: 5/100... Training loss: 0.1213\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1216\n",
      "Epoch: 5/100... Training loss: 0.1225\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1189\n",
      "Epoch: 5/100... Training loss: 0.1227\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1317\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1301\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1223\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1295\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1223\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1209\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1194\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1214\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1218\n",
      "Epoch: 5/100... Training loss: 0.1249\n",
      "Epoch: 5/100... Training loss: 0.1222\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1213\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1298\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1205\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1230\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1286\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1202\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1224\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1224\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1210\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1216\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1201\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1202\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1205\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1220\n",
      "Epoch: 5/100... Training loss: 0.1228\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1304\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1213\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1216\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1197\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1289\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1220\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1197\n",
      "Epoch: 5/100... Training loss: 0.1228\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1211\n",
      "Epoch: 5/100... Training loss: 0.1225\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1212\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1209\n",
      "Epoch: 5/100... Training loss: 0.1232\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1210\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1308\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1189\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1194\n",
      "Epoch: 5/100... Training loss: 0.1232\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1184\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1166\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1153\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1186\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1282\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1294\n",
      "Epoch: 6/100... Training loss: 0.1196\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1285\n",
      "Epoch: 6/100... Training loss: 0.1181\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1261\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1185\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1279\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1182\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1247\n",
      "Epoch: 6/100... Training loss: 0.1241\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1254\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1275\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1205\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1203\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1186\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1267\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1232\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1169\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1213\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1225\n",
      "Epoch: 6/100... Training loss: 0.1175\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1232\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1187\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1183\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1183\n",
      "Epoch: 6/100... Training loss: 0.1162\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1245\n",
      "Epoch: 6/100... Training loss: 0.1194\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1159\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1251\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1185\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1213\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1232\n",
      "Epoch: 6/100... Training loss: 0.1170\n",
      "Epoch: 6/100... Training loss: 0.1205\n",
      "Epoch: 6/100... Training loss: 0.1213\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1202\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1175\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1183\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1164\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1193\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1258\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1251\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1178\n",
      "Epoch: 6/100... Training loss: 0.1167\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1166\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1184\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1202\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1179\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1288\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1247\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1203\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1139\n",
      "Epoch: 6/100... Training loss: 0.1181\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1245\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1187\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1177\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1186\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1170\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1169\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1196\n",
      "Epoch: 6/100... Training loss: 0.1190\n",
      "Epoch: 6/100... Training loss: 0.1189\n",
      "Epoch: 6/100... Training loss: 0.1185\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1182\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1159\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1181\n",
      "Epoch: 6/100... Training loss: 0.1198\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1247\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1219\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1226\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1183\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1218\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1127\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1223\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1257\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1170\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1163\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1154\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1242\n",
      "Epoch: 7/100... Training loss: 0.1168\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1176\n",
      "Epoch: 7/100... Training loss: 0.1229\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1245\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1149\n",
      "Epoch: 7/100... Training loss: 0.1176\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1159\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1168\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1136\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1162\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1166\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1160\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1167\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1164\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1184\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1168\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1152\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1229\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1253\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1148\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1155\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1145\n",
      "Epoch: 7/100... Training loss: 0.1144\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1124\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1157\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1141\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1166\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1164\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1136\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1155\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1176\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1147\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1135\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1143\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1242\n",
      "Epoch: 7/100... Training loss: 0.1184\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1159\n",
      "Epoch: 7/100... Training loss: 0.1148\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1234\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1129\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1218\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1144\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1124\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1242\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1225\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1157\n",
      "Epoch: 8/100... Training loss: 0.1119\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1103\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1206\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1225\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1210\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1141\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1227\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1210\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1216\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1182\n",
      "Epoch: 8/100... Training loss: 0.1212\n",
      "Epoch: 8/100... Training loss: 0.1139\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1228\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1215\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1139\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1170\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1140\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1206\n",
      "Epoch: 8/100... Training loss: 0.1217\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1102\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1121\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1124\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1138\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1121\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1135\n",
      "Epoch: 8/100... Training loss: 0.1157\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1131\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1222\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1151\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1136\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1138\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1120\n",
      "Epoch: 8/100... Training loss: 0.1106\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1182\n",
      "Epoch: 8/100... Training loss: 0.1134\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1151\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1142\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1216\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1216\n",
      "Epoch: 8/100... Training loss: 0.1133\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1128\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1157\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1159\n",
      "Epoch: 8/100... Training loss: 0.1215\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1159\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1140\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1208\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1226\n",
      "Epoch: 9/100... Training loss: 0.1118\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1204\n",
      "Epoch: 9/100... Training loss: 0.1193\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100... Training loss: 0.1202\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1188\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1137\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1124\n",
      "Epoch: 9/100... Training loss: 0.1117\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1199\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1199\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1133\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1122\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1142\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1216\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1149\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1100\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1127\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1147\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1147\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1137\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1209\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1137\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1123\n",
      "Epoch: 9/100... Training loss: 0.1204\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1147\n",
      "Epoch: 9/100... Training loss: 0.1123\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1119\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1130\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1130\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1082\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1109\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1184\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1124\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1128\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1128\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1116\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1104\n",
      "Epoch: 9/100... Training loss: 0.1184\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1125\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1130\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1107\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1208\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1200\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1095\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1086\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1206\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1117\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1149\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1184\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1202\n",
      "Epoch: 9/100... Training loss: 0.1113\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1188\n",
      "Epoch: 9/100... Training loss: 0.1121\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1149\n",
      "Epoch: 9/100... Training loss: 0.1122\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1120\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1190\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1098\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1123\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1174\n",
      "Epoch: 10/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1178\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1181\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1110\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1117\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1105\n",
      "Epoch: 10/100... Training loss: 0.1199\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1106\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1196\n",
      "Epoch: 10/100... Training loss: 0.1079\n",
      "Epoch: 10/100... Training loss: 0.1098\n",
      "Epoch: 10/100... Training loss: 0.1093\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1106\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1107\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1066\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1111\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1180\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1101\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1118\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1123\n",
      "Epoch: 10/100... Training loss: 0.1177\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1130\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1102\n",
      "Epoch: 10/100... Training loss: 0.1102\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1110\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1117\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1130\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1103\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1118\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1117\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1102\n",
      "Epoch: 10/100... Training loss: 0.1103\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1175\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1095\n",
      "Epoch: 10/100... Training loss: 0.1112\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1106\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1111\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1123\n",
      "Epoch: 10/100... Training loss: 0.1191\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1087\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1171\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1096\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1160\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1163\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1143\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1099\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1107\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1099\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1143\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1175\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1168\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1107\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1171\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1100\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1102\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1083\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1094\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1106\n",
      "Epoch: 11/100... Training loss: 0.1160\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1106\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1173\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1181\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1102\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1089\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1105\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1091\n",
      "Epoch: 11/100... Training loss: 0.1106\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1096\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1155\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1151\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1094\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1076\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1155\n",
      "Epoch: 11/100... Training loss: 0.1098\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1101\n",
      "Epoch: 11/100... Training loss: 0.1082\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1098\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1105\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1107\n",
      "Epoch: 11/100... Training loss: 0.1098\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1092\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1095\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1094\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1151\n",
      "Epoch: 11/100... Training loss: 0.1119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1073\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1163\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1103\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1056\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 12/100... Training loss: 0.1152\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1147\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1181\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1089\n",
      "Epoch: 12/100... Training loss: 0.1153\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1163\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1089\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1154\n",
      "Epoch: 12/100... Training loss: 0.1141\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1149\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1162\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1091\n",
      "Epoch: 12/100... Training loss: 0.1153\n",
      "Epoch: 12/100... Training loss: 0.1152\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1164\n",
      "Epoch: 12/100... Training loss: 0.1171\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1083\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1084\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1138\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1082\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1066\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1137\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1138\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1105\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1159\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1087\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1171\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1149\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1091\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1159\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1105\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1107\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1092\n",
      "Epoch: 12/100... Training loss: 0.1179\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1076\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1084\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1075\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1141\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1092\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1072\n",
      "Epoch: 12/100... Training loss: 0.1137\n",
      "Epoch: 12/100... Training loss: 0.1137\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1159\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1096\n",
      "Epoch: 12/100... Training loss: 0.1150\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1155\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1073\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1062\n",
      "Epoch: 12/100... Training loss: 0.1071\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1140\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1105\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1169\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1140\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1082\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1160\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1165\n",
      "Epoch: 13/100... Training loss: 0.1154\n",
      "Epoch: 13/100... Training loss: 0.1164\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1157\n",
      "Epoch: 13/100... Training loss: 0.1119\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1141\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1143\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1128\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1158\n",
      "Epoch: 13/100... Training loss: 0.1150\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1074\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1139\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1119\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1147\n",
      "Epoch: 13/100... Training loss: 0.1073\n",
      "Epoch: 13/100... Training loss: 0.1081\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1053\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1087\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1177\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1106\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1051\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1058\n",
      "Epoch: 13/100... Training loss: 0.1150\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1087\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1134\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1165\n",
      "Epoch: 13/100... Training loss: 0.1104\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1078\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1081\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1081\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1157\n",
      "Epoch: 13/100... Training loss: 0.1130\n",
      "Epoch: 13/100... Training loss: 0.1075\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1063\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1085\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1156\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1119\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1076\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1077\n",
      "Epoch: 13/100... Training loss: 0.1076\n",
      "Epoch: 13/100... Training loss: 0.1140\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1138\n",
      "Epoch: 13/100... Training loss: 0.1089\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1072\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1119\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1087\n",
      "Epoch: 13/100... Training loss: 0.1166\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1066\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1060\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1139\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1139\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1085\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1071\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1161\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1136\n",
      "Epoch: 13/100... Training loss: 0.1085\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1164\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1069\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1153\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1140\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1143\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1159\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1140\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1144\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1074\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1080\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1137\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1137\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1069\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1160\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1135\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1149\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1141\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1066\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1067\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1070\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1051\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1074\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1140\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1073\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1147\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1074\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1125\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1129\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1071\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1063\n",
      "Epoch: 14/100... Training loss: 0.1058\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1083\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1062\n",
      "Epoch: 14/100... Training loss: 0.1145\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1164\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1083\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1139\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1061\n",
      "Epoch: 14/100... Training loss: 0.1126\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1068\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1137\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1148\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1111\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1134\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1061\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1127\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1062\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1085\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1083\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1075\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1083\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1064\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1121\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1154\n",
      "Epoch: 14/100... Training loss: 0.1116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1069\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1054\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1060\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1071\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1147\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1126\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1168\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1145\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1123\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1124\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1135\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1067\n",
      "Epoch: 15/100... Training loss: 0.1156\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1071\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1117\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1124\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1150\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1117\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1067\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1127\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1066\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1075\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1131\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1143\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1135\n",
      "Epoch: 15/100... Training loss: 0.1127\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1145\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1114\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1114\n",
      "Epoch: 15/100... Training loss: 0.1053\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1114\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1150\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1140\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1137\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1065\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1114\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1047\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1117\n",
      "Epoch: 15/100... Training loss: 0.1067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1049\n",
      "Epoch: 15/100... Training loss: 0.1054\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1056\n",
      "Epoch: 15/100... Training loss: 0.1127\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1075\n",
      "Epoch: 15/100... Training loss: 0.1066\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1065\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1072\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1126\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1132\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1077\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1133\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1124\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1145\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1046\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1062\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1108\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1115\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1062\n",
      "Epoch: 16/100... Training loss: 0.1120\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1064\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1137\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1043\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1139\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1120\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1104\n",
      "Epoch: 16/100... Training loss: 0.1123\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1031\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1072\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1116\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1133\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1115\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1135\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1065\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1132\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1104\n",
      "Epoch: 16/100... Training loss: 0.1077\n",
      "Epoch: 16/100... Training loss: 0.1044\n",
      "Epoch: 16/100... Training loss: 0.1134\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100... Training loss: 0.1098\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1053\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1165\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1115\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1143\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1133\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1128\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1131\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1065\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1044\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1033\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1122\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1098\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1142\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1058\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1046\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1059\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1116\n",
      "Epoch: 16/100... Training loss: 0.1126\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1072\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1123\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1108\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1128\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1050\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1064\n",
      "Epoch: 16/100... Training loss: 0.1140\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1059\n",
      "Epoch: 16/100... Training loss: 0.1055\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1037\n",
      "Epoch: 16/100... Training loss: 0.1042\n",
      "Epoch: 16/100... Training loss: 0.1108\n",
      "Epoch: 16/100... Training loss: 0.1071\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1057\n",
      "Epoch: 16/100... Training loss: 0.1098\n",
      "Epoch: 16/100... Training loss: 0.1065\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1056\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1042\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1131\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1120\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1153\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1061\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1125\n",
      "Epoch: 17/100... Training loss: 0.1058\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1035\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1057\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1117\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1054\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1065\n",
      "Epoch: 17/100... Training loss: 0.1109\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1047\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1138\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1134\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1037\n",
      "Epoch: 17/100... Training loss: 0.1054\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1052\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1055\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1118\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1056\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1125\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1023\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1049\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1131\n",
      "Epoch: 17/100... Training loss: 0.1130\n",
      "Epoch: 17/100... Training loss: 0.1116\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1048\n",
      "Epoch: 17/100... Training loss: 0.1118\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1137\n",
      "Epoch: 17/100... Training loss: 0.1052\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1061\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1053\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1126\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1055\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1148\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1058\n",
      "Epoch: 17/100... Training loss: 0.1137\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1031\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1058\n",
      "Epoch: 17/100... Training loss: 0.1120\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1031\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1112\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1116\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1032\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1119\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1114\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1113\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1121\n",
      "Epoch: 17/100... Training loss: 0.1056\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1017\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1124\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1126\n",
      "Epoch: 17/100... Training loss: 0.1142\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1055\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1053\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1108\n",
      "Epoch: 18/100... Training loss: 0.1050\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1115\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1120\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1035\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1118\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1117\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1046\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1027\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1117\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1103\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1128\n",
      "Epoch: 18/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1044\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1119\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1051\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1048\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1115\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1049\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1038\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1118\n",
      "Epoch: 18/100... Training loss: 0.1103\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1053\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1108\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1051\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1060\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1044\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1117\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1092\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1011\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1043\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1103\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1054\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1037\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1046\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1121\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1049\n",
      "Epoch: 18/100... Training loss: 0.1046\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1035\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1121\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1045\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1047\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1008\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1092\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1034\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1039\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1060\n",
      "Epoch: 18/100... Training loss: 0.1137\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1110\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1103\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1143\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1100\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1105\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1103\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1110\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1105\n",
      "Epoch: 19/100... Training loss: 0.1050\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1100\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1043\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1100\n",
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1050\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1052\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1048\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1055\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1046\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1112\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1141\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1113\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1017\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1024\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1041\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1123\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1040\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1103\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1133\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1103\n",
      "Epoch: 19/100... Training loss: 0.1108\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1037\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1048\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1021\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1040\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1115\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1041\n",
      "Epoch: 19/100... Training loss: 0.1045\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1053\n",
      "Epoch: 19/100... Training loss: 0.1041\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1042\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1108\n",
      "Epoch: 19/100... Training loss: 0.1043\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1110\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1085\n",
      "Epoch: 19/100... Training loss: 0.1048\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1043\n",
      "Epoch: 19/100... Training loss: 0.1039\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1018\n",
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1053\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1085\n",
      "Epoch: 19/100... Training loss: 0.1039\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1112\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1038\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1038\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1120\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1106\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1114\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1027\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1107\n",
      "Epoch: 20/100... Training loss: 0.1097\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1097\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1112\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1109\n",
      "Epoch: 20/100... Training loss: 0.1052\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1036\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1037\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1115\n",
      "Epoch: 20/100... Training loss: 0.1042\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1101\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1084\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1127\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1040\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1099\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1033\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1055\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1136\n",
      "Epoch: 20/100... Training loss: 0.1115\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1034\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1137\n",
      "Epoch: 20/100... Training loss: 0.1049\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1037\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1107\n",
      "Epoch: 20/100... Training loss: 0.1047\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1029\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1035\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1116\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1119\n",
      "Epoch: 20/100... Training loss: 0.1047\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1040\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1034\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1057\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1039\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1041\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1110\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1040\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1117\n",
      "Epoch: 20/100... Training loss: 0.1036\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1017\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1042\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1034\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1109\n",
      "Epoch: 20/100... Training loss: 0.1030\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1045\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1045\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1052\n",
      "Epoch: 20/100... Training loss: 0.1108\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1049\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1030\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1090\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1044\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1039\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1028\n",
      "Epoch: 21/100... Training loss: 0.1096\n",
      "Epoch: 21/100... Training loss: 0.1031\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1032\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1031\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1118\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1108\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1037\n",
      "Epoch: 21/100... Training loss: 0.1098\n",
      "Epoch: 21/100... Training loss: 0.1118\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1084\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1116\n",
      "Epoch: 21/100... Training loss: 0.1115\n",
      "Epoch: 21/100... Training loss: 0.1036\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1107\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1036\n",
      "Epoch: 21/100... Training loss: 0.1126\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1112\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1038\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1026\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1023\n",
      "Epoch: 21/100... Training loss: 0.1084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1015\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1085\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1093\n",
      "Epoch: 21/100... Training loss: 0.1119\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1097\n",
      "Epoch: 21/100... Training loss: 0.1101\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1075\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1031\n",
      "Epoch: 21/100... Training loss: 0.1072\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1086\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1016\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1107\n",
      "Epoch: 21/100... Training loss: 0.1123\n",
      "Epoch: 21/100... Training loss: 0.1101\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1038\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1031\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1115\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1072\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1044\n",
      "Epoch: 21/100... Training loss: 0.1024\n",
      "Epoch: 21/100... Training loss: 0.1086\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1096\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1075\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1117\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1029\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1106\n",
      "Epoch: 21/100... Training loss: 0.1035\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1116\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1014\n",
      "Epoch: 21/100... Training loss: 0.1085\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1105\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1019\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1040\n",
      "Epoch: 21/100... Training loss: 0.1015\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1090\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1093\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1044\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1024\n",
      "Epoch: 21/100... Training loss: 0.1033\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1085\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1035\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1105\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1109\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1041\n",
      "Epoch: 22/100... Training loss: 0.1104\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1036\n",
      "Epoch: 22/100... Training loss: 0.1035\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1123\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1086\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1026\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1040\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1103\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1097\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1101\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1117\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1035\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1086\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1049\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1091\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1107\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1110\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1125\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1049\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1031\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1108\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1021\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1098\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1117\n",
      "Epoch: 22/100... Training loss: 0.1098\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1041\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1041\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1054\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1029\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1099\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 22/100... Training loss: 0.1096\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1012\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1091\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1030\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1043\n",
      "Epoch: 22/100... Training loss: 0.1091\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1098\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1032\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1032\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1034\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1026\n",
      "Epoch: 22/100... Training loss: 0.1106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1038\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1049\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1034\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1025\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1017\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1111\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1038\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1025\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1110\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1091\n",
      "Epoch: 22/100... Training loss: 0.1026\n",
      "Epoch: 22/100... Training loss: 0.1025\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1092\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1103\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1091\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1094\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1093\n",
      "Epoch: 23/100... Training loss: 0.1081\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1099\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1102\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1037\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1049\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1021\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1088\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1049\n",
      "Epoch: 23/100... Training loss: 0.1091\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1092\n",
      "Epoch: 23/100... Training loss: 0.1088\n",
      "Epoch: 23/100... Training loss: 0.1098\n",
      "Epoch: 23/100... Training loss: 0.1008\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1097\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1015\n",
      "Epoch: 23/100... Training loss: 0.1040\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1099\n",
      "Epoch: 23/100... Training loss: 0.1051\n",
      "Epoch: 23/100... Training loss: 0.1101\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1107\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100... Training loss: 0.1024\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1016\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1092\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1026\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1093\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1026\n",
      "Epoch: 23/100... Training loss: 0.1088\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1047\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1096\n",
      "Epoch: 23/100... Training loss: 0.1016\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1027\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1025\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1102\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1028\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1032\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1119\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1051\n",
      "Epoch: 23/100... Training loss: 0.1027\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1091\n",
      "Epoch: 23/100... Training loss: 0.1112\n",
      "Epoch: 23/100... Training loss: 0.1028\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1020\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1037\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1095\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1089\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1110\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1099\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1091\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1007\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1085\n",
      "Epoch: 24/100... Training loss: 0.1075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1021\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1012\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1034\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1033\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1083\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1027\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1066\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1035\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1038\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1123\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1033\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1021\n",
      "Epoch: 24/100... Training loss: 0.1014\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1038\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1101\n",
      "Epoch: 24/100... Training loss: 0.1095\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1092\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1023\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1105\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1098\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1033\n",
      "Epoch: 24/100... Training loss: 0.1090\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1021\n",
      "Epoch: 24/100... Training loss: 0.1020\n",
      "Epoch: 24/100... Training loss: 0.1106\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1083\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1089\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1094\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1027\n",
      "Epoch: 24/100... Training loss: 0.1015\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.0996\n",
      "Epoch: 24/100... Training loss: 0.1035\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1086\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1035\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1090\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1101\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1017\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1040\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1090\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1107\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1093\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1091\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1111\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1001\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1086\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1013\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1025\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1111\n",
      "Epoch: 25/100... Training loss: 0.1085\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1018\n",
      "Epoch: 25/100... Training loss: 0.1022\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1107\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1110\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1107\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1096\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1098\n",
      "Epoch: 25/100... Training loss: 0.1008\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1090\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1015\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1022\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1017\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1014\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1093\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1010\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1110\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1013\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1091\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1033\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1028\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1105\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1090\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1099\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1089\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1031\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.0993\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1031\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1028\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1098\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1111\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1116\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1023\n",
      "Epoch: 26/100... Training loss: 0.1092\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1075\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1002\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1006\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1105\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1008\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1022\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1104\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1006\n",
      "Epoch: 26/100... Training loss: 0.1080\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1022\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1029\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1010\n",
      "Epoch: 26/100... Training loss: 0.1043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100... Training loss: 0.1112\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1104\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1012\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1037\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1089\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1081\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1081\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1024\n",
      "Epoch: 26/100... Training loss: 0.1097\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1008\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1085\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1109\n",
      "Epoch: 26/100... Training loss: 0.1086\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1088\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1019\n",
      "Epoch: 26/100... Training loss: 0.1031\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1095\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1018\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1022\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1018\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1020\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1006\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1022\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1016\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1093\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1085\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1095\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1014\n",
      "Epoch: 26/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1012\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1082\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1090\n",
      "Epoch: 27/100... Training loss: 0.1021\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1091\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1087\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.0997\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1076\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1096\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1093\n",
      "Epoch: 27/100... Training loss: 0.1073\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1003\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1025\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1005\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1084\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1012\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1020\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1093\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1070\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1081\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1044\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.0998\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1075\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1076\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1084\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1122\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1086\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1082\n",
      "Epoch: 27/100... Training loss: 0.1091\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1100\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1044\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1000\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1089\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1005\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1010\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1087\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.0988\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1085\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1005\n",
      "Epoch: 27/100... Training loss: 0.1093\n",
      "Epoch: 27/100... Training loss: 0.0991\n",
      "Epoch: 27/100... Training loss: 0.1091\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1095\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1104\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1091\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.0996\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1012\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1099\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1002\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1097\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1027\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1017\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1094\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1010\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1080\n",
      "Epoch: 28/100... Training loss: 0.1090\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1074\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1025\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.1079\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1009\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1027\n",
      "Epoch: 28/100... Training loss: 0.1017\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1003\n",
      "Epoch: 28/100... Training loss: 0.1079\n",
      "Epoch: 28/100... Training loss: 0.1086\n",
      "Epoch: 28/100... Training loss: 0.1081\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1081\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1101\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1097\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1074\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1084\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1007\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1080\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.0996\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1084\n",
      "Epoch: 28/100... Training loss: 0.1080\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1029\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1014\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1084\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1029\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1086\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1027\n",
      "Epoch: 28/100... Training loss: 0.1010\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1088\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1016\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1092\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1083\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1096\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1074\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1080\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1071\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1018\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1074\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.0984\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1069\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1052\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1078\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1082\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1014\n",
      "Epoch: 29/100... Training loss: 0.1008\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1069\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1030\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1093\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1095\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1027\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100... Training loss: 0.1006\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1016\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1071\n",
      "Epoch: 29/100... Training loss: 0.1052\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1082\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1096\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1090\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1067\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1097\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1010\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1061\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1011\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.0998\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1083\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1076\n",
      "Epoch: 29/100... Training loss: 0.1076\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.1101\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1017\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1068\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1091\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1082\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1069\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1075\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1091\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1052\n",
      "Epoch: 29/100... Training loss: 0.1122\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1061\n",
      "Epoch: 29/100... Training loss: 0.1014\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1088\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1082\n",
      "Epoch: 29/100... Training loss: 0.1011\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1016\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.0995\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1014\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.0990\n",
      "Epoch: 29/100... Training loss: 0.1071\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1083\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1071\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1089\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1074\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.0991\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1015\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1006\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1099\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1001\n",
      "Epoch: 29/100... Training loss: 0.1084\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1078\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1083\n",
      "Epoch: 30/100... Training loss: 0.1015\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1009\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1028\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1075\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1066\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1028\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1028\n",
      "Epoch: 30/100... Training loss: 0.1063\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1034\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1085\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1016\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1017\n",
      "Epoch: 30/100... Training loss: 0.1034\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1001\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1016\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.1015\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1089\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.0996\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1094\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1004\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1067\n",
      "Epoch: 30/100... Training loss: 0.1016\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1083\n",
      "Epoch: 30/100... Training loss: 0.1009\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1084\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.1082\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1015\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1015\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1008\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1072\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1085\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1072\n",
      "Epoch: 30/100... Training loss: 0.1082\n",
      "Epoch: 30/100... Training loss: 0.1067\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1074\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1015\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1097\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1063\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1073\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1074\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1078\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1080\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1067\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1067\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1013\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1012\n",
      "Epoch: 31/100... Training loss: 0.1070\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1071\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1079\n",
      "Epoch: 31/100... Training loss: 0.1016\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1070\n",
      "Epoch: 31/100... Training loss: 0.1003\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1087\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1008\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1084\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1019\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1097\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1079\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.0993\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.0979\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1000\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.0987\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1006\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1003\n",
      "Epoch: 31/100... Training loss: 0.1012\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1082\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1092\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1085\n",
      "Epoch: 31/100... Training loss: 0.1085\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1001\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1071\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1065\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1011\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1002\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 31/100... Training loss: 0.1012\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.0996\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1004\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1070\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1007\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1080\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1016\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1013\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1089\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1080\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1078\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1019\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1065\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1081\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1065\n",
      "Epoch: 31/100... Training loss: 0.1002\n",
      "Epoch: 31/100... Training loss: 0.1073\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.0983\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1081\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1078\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100... Training loss: 0.0971\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1090\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1006\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1011\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1078\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1075\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1008\n",
      "Epoch: 32/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1086\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.0999\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1091\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1058\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1075\n",
      "Epoch: 32/100... Training loss: 0.1019\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1075\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1083\n",
      "Epoch: 32/100... Training loss: 0.0985\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1019\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1013\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1088\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1083\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1010\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1013\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.0997\n",
      "Epoch: 32/100... Training loss: 0.1096\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1082\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1059\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1020\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1080\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1003\n",
      "Epoch: 32/100... Training loss: 0.1011\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.0995\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1076\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1085\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1076\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1006\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.0997\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1069\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.0989\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1077\n",
      "Epoch: 33/100... Training loss: 0.1011\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1011\n",
      "Epoch: 33/100... Training loss: 0.1073\n",
      "Epoch: 33/100... Training loss: 0.1011\n",
      "Epoch: 33/100... Training loss: 0.1091\n",
      "Epoch: 33/100... Training loss: 0.1006\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1081\n",
      "Epoch: 33/100... Training loss: 0.1090\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1012\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1078\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1095\n",
      "Epoch: 33/100... Training loss: 0.1060\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1012\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1080\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1072\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1005\n",
      "Epoch: 33/100... Training loss: 0.1082\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1056\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1008\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1019\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1079\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1056\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1073\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1012\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.0982\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1090\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1080\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1004\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1077\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1082\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1001\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1085\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1060\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1057\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1019\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.0997\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1068\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1006\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1073\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1010\n",
      "Epoch: 33/100... Training loss: 0.1057\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1006\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1008\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.0999\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1011\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1083\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.0979\n",
      "Epoch: 34/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1016\n",
      "Epoch: 34/100... Training loss: 0.1008\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1003\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.0979\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1077\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1074\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1003\n",
      "Epoch: 34/100... Training loss: 0.1064\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1053\n",
      "Epoch: 34/100... Training loss: 0.1087\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1073\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1016\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1070\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1066\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1013\n",
      "Epoch: 34/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1053\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1079\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1000\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1083\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.0987\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1072\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1016\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1078\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1075\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1016\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1062\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.0985\n",
      "Epoch: 34/100... Training loss: 0.1067\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1066\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1065\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.1013\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1065\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.0996\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1091\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1053\n",
      "Epoch: 34/100... Training loss: 0.1071\n",
      "Epoch: 34/100... Training loss: 0.0998\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1054\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1081\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1004\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1054\n",
      "Epoch: 34/100... Training loss: 0.1083\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1054\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1073\n",
      "Epoch: 34/100... Training loss: 0.0985\n",
      "Epoch: 34/100... Training loss: 0.0996\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1065\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.0999\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1008\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1000\n",
      "Epoch: 34/100... Training loss: 0.1006\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.0991\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.0997\n",
      "Epoch: 34/100... Training loss: 0.1080\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1066\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1089\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1064\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1079\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1047\n",
      "Epoch: 35/100... Training loss: 0.1002\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1010\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.1011\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1002\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1065\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1008\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.0998\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1001\n",
      "Epoch: 35/100... Training loss: 0.1004\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1072\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1073\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1073\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1073\n",
      "Epoch: 35/100... Training loss: 0.1009\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1069\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1057\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1078\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1069\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1065\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1004\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.0985\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.0994\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1076\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1010\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1011\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1078\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1047\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1078\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1011\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.0998\n",
      "Epoch: 35/100... Training loss: 0.1002\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1081\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1079\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1008\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.0972\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1061\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1064\n",
      "Epoch: 35/100... Training loss: 0.1063\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1090\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1065\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1001\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.0992\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1069\n",
      "Epoch: 35/100... Training loss: 0.1009\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1047\n",
      "Epoch: 35/100... Training loss: 0.1008\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1001\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1012\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1057\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.1081\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1084\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1087\n",
      "Epoch: 36/100... Training loss: 0.0995\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.0997\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.0997\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1070\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1070\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1075\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1072\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1068\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1087\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1005\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.1073\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1012\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1068\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1060\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1054\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.0996\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1062\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1002\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1081\n",
      "Epoch: 36/100... Training loss: 0.1063\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1067\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1072\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1057\n",
      "Epoch: 36/100... Training loss: 0.1012\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1012\n",
      "Epoch: 36/100... Training loss: 0.0982\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.0999\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1079\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.0994\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1073\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.0986\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1070\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.0993\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1063\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1062\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.0983\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.0995\n",
      "Epoch: 37/100... Training loss: 0.1059\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100... Training loss: 0.1091\n",
      "Epoch: 37/100... Training loss: 0.1071\n",
      "Epoch: 37/100... Training loss: 0.1079\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1076\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1084\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.0986\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.1011\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1066\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1061\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1071\n",
      "Epoch: 37/100... Training loss: 0.1073\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1064\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1012\n",
      "Epoch: 37/100... Training loss: 0.1079\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.0997\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.0985\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1073\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1064\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.0995\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.0997\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.0967\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1008\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.0990\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1011\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1056\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1097\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1066\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1063\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1059\n",
      "Epoch: 37/100... Training loss: 0.1011\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.0997\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1070\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.0985\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1056\n",
      "Epoch: 37/100... Training loss: 0.0994\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1066\n",
      "Epoch: 37/100... Training loss: 0.1068\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1070\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1079\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.0987\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1056\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1060\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1061\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1060\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1075\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.0999\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1061\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.0986\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.0990\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.1007\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.0998\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1068\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1006\n",
      "Epoch: 38/100... Training loss: 0.1083\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.0996\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1006\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1061\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1065\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.0985\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1079\n",
      "Epoch: 38/100... Training loss: 0.0984\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1071\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1065\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.0964\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/100... Training loss: 0.1056\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1063\n",
      "Epoch: 38/100... Training loss: 0.1074\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1080\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1082\n",
      "Epoch: 38/100... Training loss: 0.1079\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1068\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.0991\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.0990\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1064\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.0994\n",
      "Epoch: 38/100... Training loss: 0.1001\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1065\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1001\n",
      "Epoch: 38/100... Training loss: 0.1096\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.0996\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1056\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.0985\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1081\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1060\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1076\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1072\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1070\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1006\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1079\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1072\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.0986\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.0993\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1048\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.0997\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.0988\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.1050\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.1076\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1046\n",
      "Epoch: 39/100... Training loss: 0.1066\n",
      "Epoch: 39/100... Training loss: 0.1048\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1065\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.0999\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.0997\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.0988\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1048\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1001\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1053\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.0997\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.0990\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1012\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.0979\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1003\n",
      "Epoch: 39/100... Training loss: 0.0973\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1063\n",
      "Epoch: 39/100... Training loss: 0.0996\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.0999\n",
      "Epoch: 39/100... Training loss: 0.1071\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.0996\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.0996\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1081\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.0992\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.0985\n",
      "Epoch: 39/100... Training loss: 0.1061\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1066\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.1071\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1067\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1063\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1067\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.0995\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1050\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.0996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1013\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1068\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1001\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1075\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1004\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.0973\n",
      "Epoch: 40/100... Training loss: 0.0994\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1070\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.0998\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1078\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1067\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1066\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1067\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1065\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1073\n",
      "Epoch: 40/100... Training loss: 0.1084\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.0982\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1000\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1001\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1069\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1074\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1004\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1074\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.0998\n",
      "Epoch: 40/100... Training loss: 0.0983\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.0992\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.0995\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1056\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1083\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1074\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1059\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1080\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1086\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1062\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.0989\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.0999\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1092\n",
      "Epoch: 40/100... Training loss: 0.1000\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1064\n",
      "Epoch: 40/100... Training loss: 0.1076\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.0998\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1081\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.0996\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1028\n",
      "Epoch: 40/100... Training loss: 0.1065\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.0984\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.0988\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1001\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1056\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1028\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1000\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.0991\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1070\n",
      "Epoch: 41/100... Training loss: 0.1054\n",
      "Epoch: 41/100... Training loss: 0.1071\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1081\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.0987\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1057\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1056\n",
      "Epoch: 41/100... Training loss: 0.0997\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1056\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1060\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1077\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1069\n",
      "Epoch: 41/100... Training loss: 0.0984\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1072\n",
      "Epoch: 41/100... Training loss: 0.1067\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1067\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.0993\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1050\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1100\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1081\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1060\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1062\n",
      "Epoch: 41/100... Training loss: 0.0989\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.0996\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 41/100... Training loss: 0.1057\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 41/100... Training loss: 0.1060\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.0999\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.0994\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.0988\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1062\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1056\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.0991\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.0983\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.0991\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1055\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1073\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.0989\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.0995\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1073\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1069\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1068\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1062\n",
      "Epoch: 42/100... Training loss: 0.1002\n",
      "Epoch: 42/100... Training loss: 0.0987\n",
      "Epoch: 42/100... Training loss: 0.0989\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.0981\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1071\n",
      "Epoch: 42/100... Training loss: 0.1093\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1073\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1061\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1051\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1062\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1071\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.0983\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1068\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1072\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1063\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1067\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1048\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.0990\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.0993\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1064\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.0981\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1045\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1053\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1004\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.0991\n",
      "Epoch: 42/100... Training loss: 0.0994\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1060\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.1045\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1002\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1066\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.0985\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.0989\n",
      "Epoch: 42/100... Training loss: 0.1002\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.0993\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1069\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.0978\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.0981\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1004\n",
      "Epoch: 42/100... Training loss: 0.0969\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1066\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.0990\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1045\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.0995\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 43/100... Training loss: 0.1001\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.0975\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.0979\n",
      "Epoch: 43/100... Training loss: 0.0983\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1064\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1056\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1054\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.0998\n",
      "Epoch: 43/100... Training loss: 0.0998\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1065\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1053\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1072\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.0995\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1067\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.0984\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 43/100... Training loss: 0.0995\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1054\n",
      "Epoch: 43/100... Training loss: 0.1063\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1051\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.0976\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1080\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.1051\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1062\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1044\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1000\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.0984\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.0978\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.0983\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.0992\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1044\n",
      "Epoch: 43/100... Training loss: 0.0971\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.0969\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1081\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1061\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1066\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1051\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1060\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.1001\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.0985\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.0991\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.1058\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1049\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1056\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1064\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.0979\n",
      "Epoch: 44/100... Training loss: 0.1060\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1063\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1068\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.0990\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.1060\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1056\n",
      "Epoch: 44/100... Training loss: 0.1066\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1065\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1044\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1057\n",
      "Epoch: 44/100... Training loss: 0.0984\n",
      "Epoch: 44/100... Training loss: 0.1021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.0992\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1044\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.0997\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.0990\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1053\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.0988\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1063\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1057\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1054\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1050\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1060\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.0999\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1064\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.0997\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1002\n",
      "Epoch: 44/100... Training loss: 0.1067\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1050\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.0976\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.0966\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.0999\n",
      "Epoch: 44/100... Training loss: 0.1054\n",
      "Epoch: 44/100... Training loss: 0.1049\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1002\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.0969\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1055\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.0978\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.0997\n",
      "Epoch: 44/100... Training loss: 0.1064\n",
      "Epoch: 44/100... Training loss: 0.1054\n",
      "Epoch: 44/100... Training loss: 0.0981\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1051\n",
      "Epoch: 44/100... Training loss: 0.0993\n",
      "Epoch: 44/100... Training loss: 0.1059\n",
      "Epoch: 44/100... Training loss: 0.1051\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1081\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1051\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.0995\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1068\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1061\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1042\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1069\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1068\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.0985\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1055\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1008\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1056\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.0987\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.0981\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1054\n",
      "Epoch: 45/100... Training loss: 0.1063\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1056\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.0985\n",
      "Epoch: 45/100... Training loss: 0.1074\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1062\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1068\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1060\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1058\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1061\n",
      "Epoch: 45/100... Training loss: 0.1047\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.0993\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1071\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1044\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1044\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1062\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1008\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1047\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.0988\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1060\n",
      "Epoch: 45/100... Training loss: 0.0989\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1059\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1040\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.0987\n",
      "Epoch: 45/100... Training loss: 0.1044\n",
      "Epoch: 45/100... Training loss: 0.0991\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1056\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.0975\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1077\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.0987\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.0994\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1055\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1051\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1054\n",
      "Epoch: 46/100... Training loss: 0.0980\n",
      "Epoch: 46/100... Training loss: 0.1056\n",
      "Epoch: 46/100... Training loss: 0.1044\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1062\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1051\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.1044\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1083\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1066\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1061\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.0991\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.0977\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.0997\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.1057\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.0983\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.0992\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1058\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1054\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1087\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.0996\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1054\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1034\n",
      "Epoch: 46/100... Training loss: 0.1034\n",
      "Epoch: 46/100... Training loss: 0.1057\n",
      "Epoch: 46/100... Training loss: 0.1056\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.0990\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1058\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1057\n",
      "Epoch: 46/100... Training loss: 0.0996\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1001\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1061\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1057\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.0986\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.0978\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1001\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1067\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1054\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1062\n",
      "Epoch: 47/100... Training loss: 0.0988\n",
      "Epoch: 47/100... Training loss: 0.1058\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.0983\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1001\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1046\n",
      "Epoch: 47/100... Training loss: 0.1065\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.0995\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.0984\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1059\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.0995\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1070\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.0991\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1052\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1063\n",
      "Epoch: 47/100... Training loss: 0.0995\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1063\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.0994\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1055\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.0987\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1035\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1075\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.0970\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.0993\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.0973\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.0983\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1035\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1002\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1055\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.0979\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1054\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.1046\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1059\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1051\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1051\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1052\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1046\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1048\n",
      "Epoch: 48/100... Training loss: 0.1047\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1047\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1054\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.0982\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.0993\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.0993\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.0987\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.1055\n",
      "Epoch: 48/100... Training loss: 0.0970\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.0993\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.0989\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1062\n",
      "Epoch: 48/100... Training loss: 0.1048\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1065\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1044\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.0978\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.1062\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1048\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.0998\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.0987\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1046\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1057\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1084\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.0998\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1047\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1060\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1075\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1065\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1059\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.0971\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.1046\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.0989\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1046\n",
      "Epoch: 48/100... Training loss: 0.0986\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1067\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1058\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1053\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1032\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.0978\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.0991\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.0991\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.0984\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.0987\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1032\n",
      "Epoch: 49/100... Training loss: 0.1052\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.0985\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.0979\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1052\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.0995\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1054\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1028\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1047\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1054\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1057\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1028\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.0984\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.0987\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1069\n",
      "Epoch: 49/100... Training loss: 0.1066\n",
      "Epoch: 49/100... Training loss: 0.0987\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1078\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.0986\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1059\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1056\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1047\n",
      "Epoch: 49/100... Training loss: 0.1049\n",
      "Epoch: 49/100... Training loss: 0.1012\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1062\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1056\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1052\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1051\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.0995\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.0975\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.0977\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1070\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1056\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1067\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.0986\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1053\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1077\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1047\n",
      "Epoch: 50/100... Training loss: 0.1051\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1059\n",
      "Epoch: 50/100... Training loss: 0.0990\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.1007\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.1048\n",
      "Epoch: 50/100... Training loss: 0.1056\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.0969\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1065\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1047\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1072\n",
      "Epoch: 50/100... Training loss: 0.0983\n",
      "Epoch: 50/100... Training loss: 0.1057\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.0975\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1049\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.0981\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1065\n",
      "Epoch: 50/100... Training loss: 0.0983\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1053\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.0976\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.0963\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.0980\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.0985\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1049\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1061\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1048\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.0980\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1042\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.0962\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.0982\n",
      "Epoch: 50/100... Training loss: 0.1047\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1055\n",
      "Epoch: 50/100... Training loss: 0.1051\n",
      "Epoch: 50/100... Training loss: 0.1055\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.0985\n",
      "Epoch: 50/100... Training loss: 0.0989\n",
      "Epoch: 50/100... Training loss: 0.1065\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.0973\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.0980\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.0979\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1046\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.0983\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.0989\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.0986\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.0957\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1068\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1063\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.0989\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.0977\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1055\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1057\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1049\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1055\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1053\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.0980\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1053\n",
      "Epoch: 51/100... Training loss: 0.1057\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.0988\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0988\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.0983\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1046\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1053\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1048\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.1042\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1060\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.0985\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.0992\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1042\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.0962\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0990\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1076\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1042\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1058\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0976\n",
      "Epoch: 51/100... Training loss: 0.0990\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1051\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.0996\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1040\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1066\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.0981\n",
      "Epoch: 51/100... Training loss: 0.0990\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1040\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.0981\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1052\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.0973\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1059\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1064\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.0986\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.0982\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.1063\n",
      "Epoch: 52/100... Training loss: 0.0982\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.0973\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1039\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1056\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.0972\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.0975\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1048\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.1055\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.0989\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.0987\n",
      "Epoch: 52/100... Training loss: 0.0974\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1045\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1062\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1062\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1065\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.0973\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1057\n",
      "Epoch: 52/100... Training loss: 0.1061\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.0989\n",
      "Epoch: 52/100... Training loss: 0.0988\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.1047\n",
      "Epoch: 52/100... Training loss: 0.0971\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.0988\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.0986\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.0977\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.0977\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.1070\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1063\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.0987\n",
      "Epoch: 52/100... Training loss: 0.1039\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.1051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100... Training loss: 0.0986\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1061\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1046\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1039\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1059\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1045\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1066\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1048\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1060\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1057\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.0988\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1044\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.0985\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.0990\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.0982\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.0973\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1049\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1048\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.0982\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0972\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.0962\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1058\n",
      "Epoch: 53/100... Training loss: 0.1044\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.1054\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.1044\n",
      "Epoch: 53/100... Training loss: 0.0982\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1044\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1055\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.0983\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1053\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1052\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.0968\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.0988\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.0981\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1063\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.0940\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1053\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1063\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1066\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1063\n",
      "Epoch: 53/100... Training loss: 0.1056\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1047\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.0988\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.0978\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1054\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.0980\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1063\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1053\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.0990\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1012\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1012\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1062\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.0985\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.0963\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.0977\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1054\n",
      "Epoch: 54/100... Training loss: 0.0956\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.0980\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0979\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.0980\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.0986\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.0986\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1057\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.1065\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.0978\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1055\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1061\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1091\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1056\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1002\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.0985\n",
      "Epoch: 54/100... Training loss: 0.1051\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.1000\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.0975\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1050\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1047\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1053\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1053\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.0984\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0984\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.0987\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100... Training loss: 0.1048\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.0964\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1040\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.0983\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.0982\n",
      "Epoch: 55/100... Training loss: 0.1049\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.0970\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.0988\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1041\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1041\n",
      "Epoch: 55/100... Training loss: 0.1067\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1049\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.0968\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1033\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.0983\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.1041\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1051\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1039\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.1042\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.0987\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.0971\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1062\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1068\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1067\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.1046\n",
      "Epoch: 55/100... Training loss: 0.1059\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.0977\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.0964\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1039\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.0965\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.1050\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.0986\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.0992\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0982\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1064\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.1047\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1033\n",
      "Epoch: 55/100... Training loss: 0.0973\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1042\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1042\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.0983\n",
      "Epoch: 55/100... Training loss: 0.1068\n",
      "Epoch: 55/100... Training loss: 0.1040\n",
      "Epoch: 55/100... Training loss: 0.0987\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1047\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.1042\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.0982\n",
      "Epoch: 55/100... Training loss: 0.1040\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1039\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1049\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0978\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.0992\n",
      "Epoch: 56/100... Training loss: 0.1054\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1063\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1041\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1041\n",
      "Epoch: 56/100... Training loss: 0.1046\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.0980\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.0978\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1043\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1038\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1070\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.0975\n",
      "Epoch: 56/100... Training loss: 0.1038\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1057\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0992\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1037\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.0997\n",
      "Epoch: 56/100... Training loss: 0.1046\n",
      "Epoch: 56/100... Training loss: 0.0976\n",
      "Epoch: 56/100... Training loss: 0.1039\n",
      "Epoch: 56/100... Training loss: 0.0959\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1037\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.0979\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1051\n",
      "Epoch: 56/100... Training loss: 0.0985\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1051\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1054\n",
      "Epoch: 56/100... Training loss: 0.0974\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.0979\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.0950\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1044\n",
      "Epoch: 56/100... Training loss: 0.0977\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1043\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1044\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.1041\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.0974\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.1048\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.0971\n",
      "Epoch: 56/100... Training loss: 0.0997\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.0994\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0983\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.0985\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.0971\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1048\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.0979\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.0966\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.0992\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1068\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1039\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.0985\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1038\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.0975\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1062\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100... Training loss: 0.1033\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1050\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1048\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.1046\n",
      "Epoch: 57/100... Training loss: 0.0980\n",
      "Epoch: 57/100... Training loss: 0.1038\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1058\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.0970\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1033\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1066\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.1035\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.1055\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1049\n",
      "Epoch: 57/100... Training loss: 0.1064\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.0982\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1037\n",
      "Epoch: 57/100... Training loss: 0.0980\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.0963\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.1066\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1064\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.0972\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.0982\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.0971\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1042\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.0978\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.0978\n",
      "Epoch: 57/100... Training loss: 0.1049\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1042\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1037\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1049\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1038\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.0969\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1054\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.0976\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1037\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1001\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.0965\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.0988\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.0986\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.0974\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0973\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1059\n",
      "Epoch: 57/100... Training loss: 0.1042\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1035\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0977\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1044\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1050\n",
      "Epoch: 58/100... Training loss: 0.0979\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.0980\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1053\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1057\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1038\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1042\n",
      "Epoch: 58/100... Training loss: 0.1038\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.0990\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0966\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1042\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1053\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.0979\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.0982\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.1048\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1077\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.0974\n",
      "Epoch: 58/100... Training loss: 0.1053\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1040\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1054\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.1045\n",
      "Epoch: 58/100... Training loss: 0.1050\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1064\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1035\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100... Training loss: 0.0987\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1040\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0978\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.0995\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.0978\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1040\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1057\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.0969\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1048\n",
      "Epoch: 58/100... Training loss: 0.1060\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.0982\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.0974\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.0971\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1048\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.0978\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.0973\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.0967\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.0975\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1035\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1075\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1047\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1039\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1066\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.0971\n",
      "Epoch: 59/100... Training loss: 0.1052\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1051\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1055\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1054\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1039\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.0971\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.0983\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.1072\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.0981\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1045\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.0976\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.0981\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1047\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.0979\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1046\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.0969\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1056\n",
      "Epoch: 59/100... Training loss: 0.1044\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1043\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1057\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1041\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.0978\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1056\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.0979\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.0981\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.0983\n",
      "Epoch: 59/100... Training loss: 0.0977\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0985\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.0982\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0964\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.1041\n",
      "Epoch: 59/100... Training loss: 0.0983\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.0987\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.0977\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.0976\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.1053\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.1049\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.0960\n",
      "Epoch: 59/100... Training loss: 0.0970\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.0994\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1058\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.0964\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.0967\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0984\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.0978\n",
      "Epoch: 60/100... Training loss: 0.1055\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1042\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1050\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1033\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.0994\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1033\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.0991\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0991\n",
      "Epoch: 60/100... Training loss: 0.1044\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.0986\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1037\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.1037\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1044\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1063\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0969\n",
      "Epoch: 60/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.1047\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1033\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1048\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.0977\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/100... Training loss: 0.1050\n",
      "Epoch: 60/100... Training loss: 0.1043\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1038\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1042\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.0978\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.1054\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.0994\n",
      "Epoch: 60/100... Training loss: 0.1042\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1054\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.0991\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.0979\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.1037\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1046\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1051\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1053\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1058\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.0975\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.0948\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.1054\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1056\n",
      "Epoch: 61/100... Training loss: 0.0982\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1042\n",
      "Epoch: 61/100... Training loss: 0.1054\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1052\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.1056\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1054\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.1044\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1052\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1049\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.0949\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.0971\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1038\n",
      "Epoch: 61/100... Training loss: 0.1050\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.0962\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1047\n",
      "Epoch: 61/100... Training loss: 0.0972\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.0974\n",
      "Epoch: 61/100... Training loss: 0.1037\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1037\n",
      "Epoch: 61/100... Training loss: 0.1037\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1046\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.0972\n",
      "Epoch: 61/100... Training loss: 0.1042\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1065\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.0981\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.0984\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.0966\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.1038\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.0991\n",
      "Epoch: 61/100... Training loss: 0.0993\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1035\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.0984\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.0976\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.1042\n",
      "Epoch: 61/100... Training loss: 0.0980\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.0963\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1035\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.0981\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1045\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1044\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0945\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.0993\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.0993\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.0970\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.0968\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1044\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.0985\n",
      "Epoch: 62/100... Training loss: 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.0969\n",
      "Epoch: 62/100... Training loss: 0.0977\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1039\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.0979\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1039\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1036\n",
      "Epoch: 62/100... Training loss: 0.0971\n",
      "Epoch: 62/100... Training loss: 0.1048\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.0981\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1048\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.0981\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.0984\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.1036\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.0986\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.0981\n",
      "Epoch: 62/100... Training loss: 0.1043\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0970\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1047\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.0963\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0985\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1049\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1040\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1037\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.0975\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1052\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.0970\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.0975\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1040\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 63/100... Training loss: 0.1048\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.1047\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1035\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1048\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.0972\n",
      "Epoch: 63/100... Training loss: 0.1050\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.0977\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1047\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1054\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.0974\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.1039\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.0974\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0972\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1033\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.1045\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1050\n",
      "Epoch: 63/100... Training loss: 0.1060\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.0979\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1042\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.1052\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.0968\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0972\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.0961\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1053\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1045\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1084\n",
      "Epoch: 63/100... Training loss: 0.1037\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1035\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.0974\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.0970\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1047\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.1050\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.1049\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.0977\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.0981\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1060\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1056\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1037\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1045\n",
      "Epoch: 63/100... Training loss: 0.0974\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.0979\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1041\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.1060\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1021\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1047\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0963\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1046\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1039\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0994\n",
      "Epoch: 64/100... Training loss: 0.0979\n",
      "Epoch: 64/100... Training loss: 0.0955\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1033\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.0985\n",
      "Epoch: 64/100... Training loss: 0.1037\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1058\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.0979\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.1037\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1038\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.0994\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1056\n",
      "Epoch: 64/100... Training loss: 0.1048\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0962\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.0991\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.0984\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.0982\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1041\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.0978\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1034\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.0985\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0976\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1043\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.0955\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1038\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.0983\n",
      "Epoch: 64/100... Training loss: 0.1061\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1034\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.1039\n",
      "Epoch: 64/100... Training loss: 0.0958\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.0974\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1037\n",
      "Epoch: 64/100... Training loss: 0.0974\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1050\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1045\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.0977\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.0984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.0971\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1037\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1056\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.1048\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.1046\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0974\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.0977\n",
      "Epoch: 65/100... Training loss: 0.1041\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1036\n",
      "Epoch: 65/100... Training loss: 0.0976\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1037\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1050\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1043\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.0969\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1047\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1051\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0971\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0978\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1044\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.0974\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1048\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.0981\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1034\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1035\n",
      "Epoch: 65/100... Training loss: 0.1038\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.0978\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1038\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1035\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100... Training loss: 0.0955\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.0971\n",
      "Epoch: 65/100... Training loss: 0.1034\n",
      "Epoch: 65/100... Training loss: 0.0967\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1043\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1055\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0974\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1044\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.0969\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1034\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.1045\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0978\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.0976\n",
      "Epoch: 65/100... Training loss: 0.0983\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.0971\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1048\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1044\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1047\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.0973\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1048\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1052\n",
      "Epoch: 66/100... Training loss: 0.0969\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.1035\n",
      "Epoch: 66/100... Training loss: 0.1042\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1030\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1033\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.1036\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1052\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0965\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.0978\n",
      "Epoch: 66/100... Training loss: 0.1050\n",
      "Epoch: 66/100... Training loss: 0.1030\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0976\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0980\n",
      "Epoch: 66/100... Training loss: 0.0977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1026\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1026\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1041\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.1042\n",
      "Epoch: 66/100... Training loss: 0.0964\n",
      "Epoch: 66/100... Training loss: 0.0971\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1062\n",
      "Epoch: 66/100... Training loss: 0.1035\n",
      "Epoch: 66/100... Training loss: 0.0966\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1065\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.0971\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1046\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0983\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1040\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0950\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.0978\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1045\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.0985\n",
      "Epoch: 66/100... Training loss: 0.1026\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1053\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1050\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.0997\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.0985\n",
      "Epoch: 67/100... Training loss: 0.0997\n",
      "Epoch: 67/100... Training loss: 0.0983\n",
      "Epoch: 67/100... Training loss: 0.1040\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0984\n",
      "Epoch: 67/100... Training loss: 0.1034\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1038\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0997\n",
      "Epoch: 67/100... Training loss: 0.1033\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.0963\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.0958\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1024\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1034\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1046\n",
      "Epoch: 67/100... Training loss: 0.1055\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.1038\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1035\n",
      "Epoch: 67/100... Training loss: 0.1054\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.0979\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1039\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.0971\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.0968\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0975\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1044\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.1048\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1038\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.0971\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0970\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1049\n",
      "Epoch: 67/100... Training loss: 0.1059\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1048\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1040\n",
      "Epoch: 67/100... Training loss: 0.1051\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1046\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1058\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.0997\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.0961\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.0963\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1052\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1043\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.0979\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.0987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.0975\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.0981\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0954\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0972\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.0981\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1035\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.0981\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0977\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.0967\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1033\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0973\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.0962\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0972\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1041\n",
      "Epoch: 68/100... Training loss: 0.1041\n",
      "Epoch: 68/100... Training loss: 0.0979\n",
      "Epoch: 68/100... Training loss: 0.1063\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1049\n",
      "Epoch: 68/100... Training loss: 0.1040\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.1039\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.1036\n",
      "Epoch: 68/100... Training loss: 0.1065\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.1039\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0992\n",
      "Epoch: 68/100... Training loss: 0.0962\n",
      "Epoch: 68/100... Training loss: 0.0981\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0972\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.0949\n",
      "Epoch: 68/100... Training loss: 0.0979\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1043\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1042\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0977\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.1042\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.0971\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1045\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1050\n",
      "Epoch: 68/100... Training loss: 0.1040\n",
      "Epoch: 68/100... Training loss: 0.1025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.1042\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1050\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.0970\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0964\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1044\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1041\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0966\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1043\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1046\n",
      "Epoch: 68/100... Training loss: 0.0976\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.0972\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.0964\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.0966\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.0969\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0973\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0954\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.0975\n",
      "Epoch: 68/100... Training loss: 0.1039\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0951\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.0976\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.0969\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1040\n",
      "Epoch: 69/100... Training loss: 0.0971\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1044\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1044\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1041\n",
      "Epoch: 69/100... Training loss: 0.1036\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1024\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1036\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1050\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.0968\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1039\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100... Training loss: 0.1056\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.0979\n",
      "Epoch: 69/100... Training loss: 0.0981\n",
      "Epoch: 69/100... Training loss: 0.1039\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.0967\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.1041\n",
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.0968\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1074\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.0981\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0960\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.0979\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.1047\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0985\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.0970\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.0966\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0981\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1043\n",
      "Epoch: 69/100... Training loss: 0.1042\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.0969\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1033\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.0971\n",
      "Epoch: 69/100... Training loss: 0.1051\n",
      "Epoch: 69/100... Training loss: 0.1040\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.0970\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.1037\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1024\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.0970\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0996\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.0976\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1036\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1040\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.0995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1055\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1034\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1062\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0971\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1034\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.1046\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1035\n",
      "Epoch: 70/100... Training loss: 0.1040\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0969\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1043\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.0978\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1034\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1047\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1027\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1044\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1033\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0979\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0986\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1029\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1048\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.0967\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0969\n",
      "Epoch: 70/100... Training loss: 0.0973\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1041\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.0975\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0973\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.0976\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.0972\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100... Training loss: 0.1061\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0958\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1034\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1035\n",
      "Epoch: 70/100... Training loss: 0.1029\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.0983\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1027\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1029\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1046\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.0975\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.1027\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.0967\n",
      "Epoch: 70/100... Training loss: 0.1041\n",
      "Epoch: 70/100... Training loss: 0.1066\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.0980\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1076\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1028\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.1037\n",
      "Epoch: 71/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.1046\n",
      "Epoch: 71/100... Training loss: 0.1039\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1041\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1041\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.1043\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1044\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0999\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1037\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1039\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.0963\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1036\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.0971\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.1059\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0972\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1051\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.1066\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1049\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.0974\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1049\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.0962\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1048\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.0965\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.0957\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0959\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0976\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.0946\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 71/100... Training loss: 0.0977\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0965\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0965\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.0964\n",
      "Epoch: 71/100... Training loss: 0.0969\n",
      "Epoch: 71/100... Training loss: 0.1055\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.0963\n",
      "Epoch: 71/100... Training loss: 0.1055\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1044\n",
      "Epoch: 71/100... Training loss: 0.1040\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1028\n",
      "Epoch: 71/100... Training loss: 0.1047\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1046\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.0977\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.0999\n",
      "Epoch: 71/100... Training loss: 0.0971\n",
      "Epoch: 71/100... Training loss: 0.1054\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1048\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.0969\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.0999\n",
      "Epoch: 71/100... Training loss: 0.1036\n",
      "Epoch: 71/100... Training loss: 0.0974\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.0974\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1062\n",
      "Epoch: 72/100... Training loss: 0.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1037\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.0945\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1041\n",
      "Epoch: 72/100... Training loss: 0.1036\n",
      "Epoch: 72/100... Training loss: 0.1033\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.1049\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.0975\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1050\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1029\n",
      "Epoch: 72/100... Training loss: 0.1046\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.1034\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.1049\n",
      "Epoch: 72/100... Training loss: 0.0983\n",
      "Epoch: 72/100... Training loss: 0.1037\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1043\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.0984\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1040\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1024\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.1044\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.1043\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0970\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1038\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1055\n",
      "Epoch: 72/100... Training loss: 0.1031\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.0973\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1037\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1034\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1033\n",
      "Epoch: 72/100... Training loss: 0.1058\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.1047\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0983\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1057\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1043\n",
      "Epoch: 72/100... Training loss: 0.0969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1033\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1040\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1045\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.0966\n",
      "Epoch: 72/100... Training loss: 0.1042\n",
      "Epoch: 72/100... Training loss: 0.0984\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.0964\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.0984\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1038\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.0984\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1031\n",
      "Epoch: 72/100... Training loss: 0.0967\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0968\n",
      "Epoch: 72/100... Training loss: 0.0977\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.1033\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1026\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.0963\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.0972\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1042\n",
      "Epoch: 73/100... Training loss: 0.0969\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1044\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.0972\n",
      "Epoch: 73/100... Training loss: 0.0968\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.1053\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0974\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.0972\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0981\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1025\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1037\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1029\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.0970\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1039\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1041\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1040\n",
      "Epoch: 73/100... Training loss: 0.0980\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.0972\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.1038\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1048\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.0939\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.0989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1029\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.0957\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1026\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.1049\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0974\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1043\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0969\n",
      "Epoch: 73/100... Training loss: 0.0981\n",
      "Epoch: 73/100... Training loss: 0.0984\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0968\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1053\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1039\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.0969\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1047\n",
      "Epoch: 73/100... Training loss: 0.1044\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.0980\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1026\n",
      "Epoch: 73/100... Training loss: 0.0960\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.0984\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0968\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.1041\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.0968\n",
      "Epoch: 73/100... Training loss: 0.0984\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1025\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1026\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1033\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.1040\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.0969\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.0981\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.1031\n",
      "Epoch: 74/100... Training loss: 0.0974\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.1036\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.0977\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.1034\n",
      "Epoch: 74/100... Training loss: 0.1031\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.0967\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1023\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0972\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0969\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.1001\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.0966\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1032\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1037\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1043\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1037\n",
      "Epoch: 74/100... Training loss: 0.0974\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.0974\n",
      "Epoch: 74/100... Training loss: 0.0959\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1034\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1036\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0979\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.0972\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.1050\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1035\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0980\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.1055\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.1032\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.0972\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.1040\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.1073\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.0980\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.0969\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1031\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.0961\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1001\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.1023\n",
      "Epoch: 74/100... Training loss: 0.1051\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.0961\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1043\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1035\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1042\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.1048\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.1039\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1046\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0965\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1051\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1041\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1025\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.0981\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.0970\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0975\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.1046\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.0971\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0964\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1051\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0979\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.1044\n",
      "Epoch: 75/100... Training loss: 0.1039\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1037\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0971\n",
      "Epoch: 75/100... Training loss: 0.0967\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.1036\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1040\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1036\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.0970\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1037\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.0975\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.0970\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.0963\n",
      "Epoch: 75/100... Training loss: 0.1087\n",
      "Epoch: 75/100... Training loss: 0.1027\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1043\n",
      "Epoch: 75/100... Training loss: 0.1078\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0959\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.1043\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1043\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1059\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1022\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1025\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1036\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1041\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.0964\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1039\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.0971\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0970\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1037\n",
      "Epoch: 76/100... Training loss: 0.1042\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.0965\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.0969\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1030\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0958\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.1055\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0971\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1054\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1046\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.0960\n",
      "Epoch: 76/100... Training loss: 0.0962\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1037\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.0958\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.0965\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1042\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1047\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1061\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.1049\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.0970\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.1045\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.0974\n",
      "Epoch: 76/100... Training loss: 0.1036\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.1047\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1032\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1042\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.0972\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1054\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.1032\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.1043\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1030\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.0971\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.1081\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0967\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1034\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1038\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1029\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1038\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.0967\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1038\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.0978\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1049\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.1034\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.0972\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0951\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.1055\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0966\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0972\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0967\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.0978\n",
      "Epoch: 77/100... Training loss: 0.1038\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.0967\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1045\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.1034\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1034\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1034\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0955\n",
      "Epoch: 77/100... Training loss: 0.1045\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0978\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.0974\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0975\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1036\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1044\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.0958\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0984\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.1056\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.0968\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0966\n",
      "Epoch: 78/100... Training loss: 0.1046\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0972\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0958\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0974\n",
      "Epoch: 78/100... Training loss: 0.0954\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1054\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1035\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1033\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0966\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0967\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.0965\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0970\n",
      "Epoch: 78/100... Training loss: 0.1039\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.0971\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.0977\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.1035\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.1030\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0977\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1061\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1037\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0977\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.0970\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.0944\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1036\n",
      "Epoch: 78/100... Training loss: 0.1052\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1033\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1055\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1030\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1042\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.0967\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.0970\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.0967\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0975\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.1035\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.0963\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.1041\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.1052\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1037\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1034\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.0971\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.1060\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.0960\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.1035\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.0973\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.0967\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1031\n",
      "Epoch: 79/100... Training loss: 0.1044\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.1025\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.1041\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.1042\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.1031\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.1031\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0975\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1037\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0952\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.1049\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1031\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0973\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1033\n",
      "Epoch: 79/100... Training loss: 0.1025\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.0970\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.0969\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1019\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1047\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.1019\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.1048\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1032\n",
      "Epoch: 79/100... Training loss: 0.0975\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.1034\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1032\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1035\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1019\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.0963\n",
      "Epoch: 79/100... Training loss: 0.1025\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.1046\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.1032\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0966\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0965\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0963\n",
      "Epoch: 79/100... Training loss: 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.0966\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.0972\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0959\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1037\n",
      "Epoch: 80/100... Training loss: 0.1028\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0969\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1044\n",
      "Epoch: 80/100... Training loss: 0.1036\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.0974\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.0958\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0959\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1028\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.0975\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.0967\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.0972\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1036\n",
      "Epoch: 80/100... Training loss: 0.0973\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0971\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1035\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.1035\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.0969\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0976\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.0947\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.0978\n",
      "Epoch: 80/100... Training loss: 0.0958\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1040\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1037\n",
      "Epoch: 80/100... Training loss: 0.0978\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.0998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0970\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0984\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.1025\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0978\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0969\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1024\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.0966\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.1039\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.0976\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0970\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0962\n",
      "Epoch: 80/100... Training loss: 0.1025\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1052\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1053\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1041\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.1028\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0975\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1034\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.0969\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.0967\n",
      "Epoch: 81/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.0975\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.1031\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1034\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1036\n",
      "Epoch: 81/100... Training loss: 0.0974\n",
      "Epoch: 81/100... Training loss: 0.1036\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.1036\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0965\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.0971\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0959\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.1031\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.0976\n",
      "Epoch: 81/100... Training loss: 0.1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.1024\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.0960\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.0970\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.0963\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1035\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1044\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1046\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.0958\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.0970\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1032\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.1034\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.0951\n",
      "Epoch: 81/100... Training loss: 0.1050\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1038\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1042\n",
      "Epoch: 81/100... Training loss: 0.0973\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1038\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.0970\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.0964\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0973\n",
      "Epoch: 81/100... Training loss: 0.0954\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0951\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.0965\n",
      "Epoch: 82/100... Training loss: 0.1048\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1033\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.0978\n",
      "Epoch: 82/100... Training loss: 0.1033\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.0993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1039\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.1037\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1038\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1045\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0973\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1056\n",
      "Epoch: 82/100... Training loss: 0.1034\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.1043\n",
      "Epoch: 82/100... Training loss: 0.1027\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0955\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1035\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0961\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.1041\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1035\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1038\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1036\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1034\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.1029\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.0971\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.0978\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.0973\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.0964\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.0951\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1032\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.1031\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1034\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1056\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1034\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.0966\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.1037\n",
      "Epoch: 82/100... Training loss: 0.1019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1043\n",
      "Epoch: 82/100... Training loss: 0.1032\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1033\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.0971\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0974\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.0963\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.1038\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1032\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1034\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.0947\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.1033\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0966\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.0955\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1028\n",
      "Epoch: 83/100... Training loss: 0.0969\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.0965\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0966\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0971\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.0974\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0961\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.1036\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.1048\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.0964\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1039\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.1054\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0979\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.0973\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1028\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0965\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.0969\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.0969\n",
      "Epoch: 83/100... Training loss: 0.0969\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.0963\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1039\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0951\n",
      "Epoch: 83/100... Training loss: 0.1027\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0979\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1039\n",
      "Epoch: 83/100... Training loss: 0.1036\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1029\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1032\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0954\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0973\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0973\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.1035\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.1028\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.1048\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1029\n",
      "Epoch: 84/100... Training loss: 0.1027\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.1057\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1017\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1044\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0970\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.0966\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1024\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1030\n",
      "Epoch: 84/100... Training loss: 0.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100... Training loss: 0.1040\n",
      "Epoch: 84/100... Training loss: 0.0958\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.1031\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.1027\n",
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0957\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.1048\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.0966\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0972\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1034\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1028\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1054\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1036\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1046\n",
      "Epoch: 84/100... Training loss: 0.0965\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1034\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0954\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0968\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.1035\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.1029\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1040\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1028\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0968\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.1040\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0970\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1038\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.0970\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.0974\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.1025\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1042\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.1033\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0952\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1041\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0968\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.1040\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.1044\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.1046\n",
      "Epoch: 85/100... Training loss: 0.0967\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1039\n",
      "Epoch: 85/100... Training loss: 0.1022\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1033\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.0964\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1024\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1033\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1028\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0960\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0963\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.1041\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.1046\n",
      "Epoch: 85/100... Training loss: 0.1046\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.0952\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1024\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1044\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.1044\n",
      "Epoch: 85/100... Training loss: 0.0961\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0941\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0940\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1043\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.1030\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.1035\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1022\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.1034\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0955\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0982\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.0962\n",
      "Epoch: 86/100... Training loss: 0.1026\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.1060\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.1026\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.1021\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1044\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1021\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.1035\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.1027\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1040\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1026\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0966\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1032\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0973\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.0989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/100... Training loss: 0.1024\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.1027\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0964\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.1076\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.0967\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.0966\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.1039\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.0960\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0967\n",
      "Epoch: 86/100... Training loss: 0.0982\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0960\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.1038\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.0967\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0968\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1035\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.1027\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.1048\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.0966\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1031\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1030\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.1050\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1048\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.1035\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1027\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.0962\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1029\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0978\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1028\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1033\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.0958\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1036\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.1024\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0961\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1027\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1036\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.1033\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.0959\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.0955\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.0978\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.1032\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1024\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.1056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.0977\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1036\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0953\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1035\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1037\n",
      "Epoch: 87/100... Training loss: 0.1032\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0963\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1041\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.1029\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0971\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0965\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0989\n",
      "Epoch: 88/100... Training loss: 0.1023\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.1031\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0963\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0963\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.0968\n",
      "Epoch: 88/100... Training loss: 0.1046\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.1047\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0964\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0957\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.1035\n",
      "Epoch: 88/100... Training loss: 0.1026\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0975\n",
      "Epoch: 88/100... Training loss: 0.1027\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1031\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.1026\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0961\n",
      "Epoch: 88/100... Training loss: 0.1036\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.1049\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1028\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.0967\n",
      "Epoch: 88/100... Training loss: 0.1042\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1021\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.1030\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0989\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.1023\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1028\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0954\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.1028\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0964\n",
      "Epoch: 88/100... Training loss: 0.1039\n",
      "Epoch: 88/100... Training loss: 0.1038\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0971\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1021\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.0963\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0959\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.1041\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.1047\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0968\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0971\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.0957\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0960\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0977\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1027\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.1015\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.1078\n",
      "Epoch: 89/100... Training loss: 0.1036\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1020\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0959\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0962\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.1038\n",
      "Epoch: 89/100... Training loss: 0.0981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100... Training loss: 0.1037\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1030\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.1026\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.1048\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.1031\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0951\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.1032\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.1026\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1015\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.1022\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.1034\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1037\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.1036\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1044\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1057\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1033\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0959\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1041\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1025\n",
      "Epoch: 89/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1025\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0965\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.1022\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.1037\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0963\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0977\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.0966\n",
      "Epoch: 89/100... Training loss: 0.0970\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0977\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.0948\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0966\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.1033\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0965\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.0963\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0949\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.0961\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.1031\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.1030\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1031\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.1030\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1027\n",
      "Epoch: 90/100... Training loss: 0.1027\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1038\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1042\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1035\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.1020\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0966\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1018\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.0951\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0968\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1045\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.1025\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.1058\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.1023\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1044\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.0967\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0956\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.0965\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.0972\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.0972\n",
      "Epoch: 90/100... Training loss: 0.0968\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0968\n",
      "Epoch: 90/100... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.0965\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1041\n",
      "Epoch: 90/100... Training loss: 0.0965\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1050\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.1037\n",
      "Epoch: 90/100... Training loss: 0.1031\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.1022\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.1025\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.1034\n",
      "Epoch: 90/100... Training loss: 0.0961\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1062\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1027\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1040\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.0957\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0969\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1020\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.0965\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0957\n",
      "Epoch: 91/100... Training loss: 0.0969\n",
      "Epoch: 91/100... Training loss: 0.1024\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1041\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.1044\n",
      "Epoch: 91/100... Training loss: 0.1027\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.1025\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1041\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0967\n",
      "Epoch: 91/100... Training loss: 0.0969\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.0952\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.1030\n",
      "Epoch: 91/100... Training loss: 0.0969\n",
      "Epoch: 91/100... Training loss: 0.1033\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0981\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.1024\n",
      "Epoch: 91/100... Training loss: 0.0975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100... Training loss: 0.0958\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.0971\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1021\n",
      "Epoch: 91/100... Training loss: 0.0972\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.1021\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.0960\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.0943\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1024\n",
      "Epoch: 91/100... Training loss: 0.1036\n",
      "Epoch: 91/100... Training loss: 0.0971\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.1043\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0965\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.0970\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1022\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.1027\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0965\n",
      "Epoch: 91/100... Training loss: 0.0943\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.1020\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.1038\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.1025\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.1034\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1028\n",
      "Epoch: 91/100... Training loss: 0.0962\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0949\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.1006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.0968\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1036\n",
      "Epoch: 92/100... Training loss: 0.1039\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1035\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1052\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0955\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.1029\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.1035\n",
      "Epoch: 92/100... Training loss: 0.0953\n",
      "Epoch: 92/100... Training loss: 0.0964\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0969\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0946\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.0967\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0945\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1033\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.0958\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1032\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0963\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0969\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.0979\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0973\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0966\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.0955\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1036\n",
      "Epoch: 92/100... Training loss: 0.1024\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0967\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.1038\n",
      "Epoch: 92/100... Training loss: 0.1029\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0949\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.0962\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.1040\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.1032\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0964\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.1037\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.1042\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.1024\n",
      "Epoch: 92/100... Training loss: 0.1037\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.1036\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0965\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0958\n",
      "Epoch: 93/100... Training loss: 0.0963\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0957\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.1034\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0966\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1053\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1033\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1024\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0937\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.1030\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.1040\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1021\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1051\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1027\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0952\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.1027\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0948\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0944\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.0947\n",
      "Epoch: 93/100... Training loss: 0.1035\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0968\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0958\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.0969\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.0959\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.1035\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1030\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.1018\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.1021\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.1021\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.1017\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1022\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.1040\n",
      "Epoch: 94/100... Training loss: 0.1028\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0964\n",
      "Epoch: 94/100... Training loss: 0.0972\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.0958\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1067\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1031\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.0960\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0983\n",
      "Epoch: 94/100... Training loss: 0.1021\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.0967\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.1030\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0987\n",
      "Epoch: 94/100... Training loss: 0.1027\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0948\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1027\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1033\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0968\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.0983\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.1052\n",
      "Epoch: 94/100... Training loss: 0.1022\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.1026\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0967\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.1026\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0960\n",
      "Epoch: 94/100... Training loss: 0.1041\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1030\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.1029\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.0972\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.1022\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1027\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.1022\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0968\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.1026\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0972\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.0951\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1032\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.1042\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1037\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.0987\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0971\n",
      "Epoch: 94/100... Training loss: 0.1034\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0953\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1036\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0973\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.1031\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.1023\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1025\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0951\n",
      "Epoch: 95/100... Training loss: 0.1045\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.1032\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0938\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.0967\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.0955\n",
      "Epoch: 95/100... Training loss: 0.1035\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0973\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.1027\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0966\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.1051\n",
      "Epoch: 95/100... Training loss: 0.1027\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0965\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.1035\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.1031\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1027\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.0970\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0966\n",
      "Epoch: 95/100... Training loss: 0.0955\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.0961\n",
      "Epoch: 95/100... Training loss: 0.1032\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.1045\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1037\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.0973\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0966\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.1020\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.0972\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.1045\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1026\n",
      "Epoch: 96/100... Training loss: 0.0970\n",
      "Epoch: 96/100... Training loss: 0.0966\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0972\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0930\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.1020\n",
      "Epoch: 96/100... Training loss: 0.1033\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.1006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.0970\n",
      "Epoch: 96/100... Training loss: 0.0960\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.0952\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0968\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0960\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1022\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1044\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1043\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1031\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1026\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.1024\n",
      "Epoch: 96/100... Training loss: 0.1030\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.1036\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0959\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.1048\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.1030\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.1043\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.1032\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0956\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1037\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.1020\n",
      "Epoch: 96/100... Training loss: 0.0955\n",
      "Epoch: 96/100... Training loss: 0.0966\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0964\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.0966\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0951\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0964\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1036\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1030\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.1025\n",
      "Epoch: 97/100... Training loss: 0.1025\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1030\n",
      "Epoch: 97/100... Training loss: 0.0968\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.1031\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0967\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0968\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.0964\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.1034\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.1023\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.1026\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.1022\n",
      "Epoch: 97/100... Training loss: 0.1028\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.1042\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0957\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.0960\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0960\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0964\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.1028\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0934\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1017\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.1020\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0958\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.1066\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.0967\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.1031\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.1027\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.1023\n",
      "Epoch: 97/100... Training loss: 0.1028\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.0956\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1026\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.1035\n",
      "Epoch: 97/100... Training loss: 0.1046\n",
      "Epoch: 97/100... Training loss: 0.1028\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.1025\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.1045\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.0968\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0957\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0964\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.0953\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1044\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0967\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.1017\n",
      "Epoch: 97/100... Training loss: 0.1037\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0948\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1038\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0948\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0963\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.0966\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0969\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0946\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1040\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.1026\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.1026\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.0954\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0953\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1029\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98/100... Training loss: 0.0964\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.0942\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1043\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.1028\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0957\n",
      "Epoch: 98/100... Training loss: 0.1032\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1033\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1027\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0958\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.0963\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.0967\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.1064\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1029\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.0959\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.1034\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.0962\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.1023\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.0964\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0969\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.1034\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0948\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1050\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0975\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0975\n",
      "Epoch: 99/100... Training loss: 0.0960\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0968\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.1018\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1028\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.1027\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.1046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.0966\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.1029\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.1031\n",
      "Epoch: 99/100... Training loss: 0.0969\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1032\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1021\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.1025\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.1035\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.0968\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.1040\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.0947\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.1031\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1048\n",
      "Epoch: 99/100... Training loss: 0.0955\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0979\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.1048\n",
      "Epoch: 99/100... Training loss: 0.0954\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0957\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.1025\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.0966\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.0959\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1030\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.1034\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.0999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0960\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0956\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.0967\n",
      "Epoch: 100/100... Training loss: 0.0968\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0956\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0949\n",
      "Epoch: 100/100... Training loss: 0.1045\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.1063\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.1029\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1048\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.0959\n",
      "Epoch: 100/100... Training loss: 0.1025\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1028\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.1026\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.1039\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.0972\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0950\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0968\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0957\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1026\n",
      "Epoch: 100/100... Training loss: 0.0973\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.0970\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0963\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.1028\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0936\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1028\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.1037\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.1043\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.0963\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.0964\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.0960\n",
      "Epoch: 100/100... Training loss: 0.0955\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0972\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.0970\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0958\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0967\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.0960\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1035\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1033\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0995\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 200\n",
    "# Set's how much noise we're adding to the MNIST images\n",
    "noise_factor = 0.5\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        # Get images from the batch\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        \n",
    "        # Add random noise to the input images\n",
    "        noisy_imgs = imgs + noise_factor * np.random.randn(*imgs.shape)\n",
    "        # Clip the images to be between 0 and 1\n",
    "        noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "        \n",
    "        # Noisy images as inputs, original images as targets\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: noisy_imgs,\n",
    "                                                         targets_: imgs})\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out the performance\n",
    "\n",
    "Here I'm adding noise to the test images and passing them through the autoencoder. It does a suprising great job of removing the noise, even though it's sometimes difficult to tell what the original number is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABawAAAEsCAYAAAAvofT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCF4GEboAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29f1b928eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "noisy_imgs = in_imgs + noise_factor * np.random.randn(*in_imgs.shape)\n",
    "noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: noisy_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([noisy_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Residuals and Principal Component\n",
    "\n",
    "We now need to determine how well this autoencoder works. For each image in the MNIST test dataset, compute the residual error of the autoencoder. This is the difference between the true image and the reconstruction of that image by the autoencoder. It is an image itself. Prepare a figure showing the mean residual error, and the first five principal components. Each is an image. You should preserve signs (i.e. the mean residual error may have negative as well as positive entries). The way to show these images most informatively is to use a mid gray value for zero, then darker values for more negative image values and lighter values for more positive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_imgs = mnist.test.images\n",
    "\n",
    "#Calculate residual mean of auto-encoded images\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: in_imgs.reshape((-1, 28, 28, 1))}).reshape(-1, 28, 28)\n",
    "ae_mean_residual = np.mean(np.subtract(in_imgs.reshape(-1, 28, 28), reconstructed), axis=0)\n",
    "\n",
    "#Get first 5 principal components\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(in_imgs)\n",
    "pc = pca.components_\n",
    "\n",
    "images = np.concatenate((ae_mean_residual.reshape(-1, 28, 28), pc.reshape(-1, 28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot mean and five principal components on the same gray scale for all six images, chosen so the largest absolute value over all six images is full dark or full light respectively and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABawAAAEsCAYAAAAvofT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29f464fd710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_images(imgs):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=imgs.shape[0], sharex=True, sharey=True, figsize=(20,4))\n",
    "    for img, ax in zip(imgs, axes):\n",
    "        ax.imshow(img, cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    fig.tight_layout(pad=0.1)\n",
    "\n",
    "#Normailze with global value\n",
    "image_1 = np.copy(images)\n",
    "max_val = np.max(images1)\n",
    "min_val = np.min(images1)\n",
    "\n",
    "images1 = (image_1 - min_val) / (max_val - min_val)\n",
    "\n",
    "show_images(images1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot mean and five principal components on a scale where the gray scale is chosen for each image separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABawAAAEsCAYAAAAvofT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29f45f65550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normailze with each image\n",
    "images2 = np.copy(images)\n",
    "\n",
    "for i in range(6):\n",
    "    max_val = np.max(images[i])\n",
    "    min_val = np.min(images[i])\n",
    "\n",
    "    images2[i,] = (images2[i,] - min_val) / (max_val - min_val)\n",
    "\n",
    "show_images(images2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders\n",
    "\n",
    "We will evaluate variational autoencoders applied to the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VAE code is downloaded from \n",
    "\n",
    "* https://github.com/hwalsuklee/tensorflow-mnist-VAE\n",
    "\n",
    "We now need to determine how well the codes produced by this autoencoder can be interpolated.\n",
    "* For 10 pairs of MNIST test images of the same digit, selected at random, compute the code for each image of the pair. Now compute 7 evenly spaced linear interpolates between these codes, and decode the result into images. Prepare a figure showing this interpolate. Lay out the figure so each interpolate is a row. On the left of the row is the first test image; then the interpolate closest to it; etc; to the last test image. You should have a 10 rows and 9 columns of images.\n",
    "* For 10 pairs of MNIST test images of different digits, selected at random, compute the code for each image of the pair. Now compute 7 evenly spaced linear interpolates between these codes, and decode the result into images. Prepare a figure showing this interpolate. Lay out the figure so each interpolate is a row. On the left of the row is the first test image; then the interpolate closest to it; etc; to the last test image. You should have a 10 rows and 9 columns of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import vae\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "dim_z = 20\n",
    "n_hidden = 500\n",
    "learn_rate = 1e-3\n",
    "dim_img = mnist.train.images.shape[1]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, dim_img], name='target_img')\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "# input for PMLR\n",
    "z_in = tf.placeholder(tf.float32, shape=[None, dim_z], name='latent_variable')\n",
    "\n",
    "# network architecture\n",
    "y, z, loss, neg_marginal_likelihood, KL_divergence = vae.autoencoder(x, x, dim_img, dim_z, n_hidden, keep_prob)\n",
    "\n",
    "# optimization\n",
    "train_op = tf.train.AdamOptimizer(learn_rate).minimize(loss)\n",
    "\n",
    "decoded = vae.decoder(z_in, dim_img, n_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We will train the model and regenerate the images as asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: L_tot 139.35 L_likelihood 114.38 L_divergence 24.98\n",
      "epoch 1: L_tot 129.99 L_likelihood 105.07 L_divergence 24.92\n",
      "epoch 2: L_tot 122.08 L_likelihood 96.94 L_divergence 25.15\n",
      "epoch 3: L_tot 118.56 L_likelihood 94.22 L_divergence 24.34\n",
      "epoch 4: L_tot 114.67 L_likelihood 90.78 L_divergence 23.89\n",
      "epoch 5: L_tot 111.75 L_likelihood 87.80 L_divergence 23.95\n",
      "epoch 6: L_tot 108.68 L_likelihood 84.83 L_divergence 23.84\n",
      "epoch 7: L_tot 109.99 L_likelihood 86.38 L_divergence 23.61\n",
      "epoch 8: L_tot 112.67 L_likelihood 88.02 L_divergence 24.66\n",
      "epoch 9: L_tot 114.14 L_likelihood 89.51 L_divergence 24.63\n",
      "epoch 10: L_tot 113.33 L_likelihood 89.51 L_divergence 23.82\n",
      "epoch 11: L_tot 113.17 L_likelihood 89.63 L_divergence 23.54\n",
      "epoch 12: L_tot 110.83 L_likelihood 86.22 L_divergence 24.61\n",
      "epoch 13: L_tot 111.64 L_likelihood 87.44 L_divergence 24.19\n",
      "epoch 14: L_tot 112.49 L_likelihood 88.40 L_divergence 24.09\n",
      "epoch 15: L_tot 114.32 L_likelihood 90.26 L_divergence 24.06\n",
      "epoch 16: L_tot 108.74 L_likelihood 85.21 L_divergence 23.53\n",
      "epoch 17: L_tot 113.66 L_likelihood 88.97 L_divergence 24.69\n",
      "epoch 18: L_tot 110.94 L_likelihood 86.95 L_divergence 23.99\n",
      "epoch 19: L_tot 113.32 L_likelihood 88.76 L_divergence 24.56\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "total_batch = mnist.train.images.shape[0]//batch_size\n",
    "\n",
    "def split_codes(codes, interval_num):\n",
    "    results = np.zeros((interval_num + 2, codes.shape[1]))\n",
    "    results[0] = codes[0]\n",
    "    results[interval_num + 1] = codes[1]\n",
    "        \n",
    "    interval = (codes[1] - codes[0]) / (interval_num + 1)\n",
    "    diff = np.copy(interval)\n",
    "        \n",
    "    for i in range(1, interval_num + 1):\n",
    "        results[i] = codes[0] + diff\n",
    "        diff += interval\n",
    "        \n",
    "    return results\n",
    "\n",
    "#Prepare digit images for testing\n",
    "SameDigitPairs = mnist.train.images[np.argwhere(mnist.train.labels == 2)[100:120]].reshape(-1, dim_img)\n",
    "DiffDigitParis = np.zeros((20, dim_img))\n",
    "for i in range(10):\n",
    "    images = mnist.train.images[np.argwhere(mnist.train.labels == i)[200:202]].reshape(-1, dim_img)\n",
    "\n",
    "    DiffDigitParis[i * 2, :] = images[0]\n",
    "    DiffDigitParis[i * 2 + 1, :] = images[1]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer(), feed_dict={keep_prob : 0.9})\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(total_batch):\n",
    "            train_images, train_labels = mnist.train.next_batch(batch_size)\n",
    "            _, tot_loss, loss_likelihood, loss_divergence = sess.run(\n",
    "                    (train_op, loss, neg_marginal_likelihood, KL_divergence),\n",
    "                    feed_dict={x: train_images, keep_prob : 0.9})\n",
    "            \n",
    "        print(\"epoch %d: L_tot %03.2f L_likelihood %03.2f L_divergence %03.2f\" % (epoch, tot_loss, loss_likelihood, loss_divergence))\n",
    "    \n",
    "    \n",
    "    same_z_codes = sess.run((z), feed_dict={x: SameDigitPairs, keep_prob : 1}).reshape(10, 2, -1)\n",
    "    diff_z_codes = sess.run((z), feed_dict={x: DiffDigitParis, keep_prob : 1}).reshape(10, 2, -1)\n",
    "\n",
    "    same_z_codes = np.array([split_codes(codes, 7) for codes in same_z_codes])\n",
    "    diff_z_codes = np.array([split_codes(codes, 7) for codes in diff_z_codes])\n",
    "    \n",
    "    same_images = sess.run(decoded, feed_dict={z_in: same_z_codes.reshape(-1, dim_z), keep_prob : 1})\n",
    "    diff_images = sess.run(decoded, feed_dict={z_in: diff_z_codes.reshape(-1, dim_z), keep_prob : 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Images\n",
    "\n",
    "We plot the results as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(images):\n",
    "    fig, axes = plt.subplots(nrows=10, ncols=9, sharex=True, sharey=True, figsize=(20,20))\n",
    "\n",
    "    for row_imgs, row in zip(images, axes):\n",
    "        for img, ax in zip(row_imgs, row):\n",
    "            ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABawAAAWsCAYAAADFXsQ9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ4+GggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13e24b04940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(same_images.reshape(10,9,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABawAAAWsCAYAAADFXsQ9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAADowv8ACyG1Pe1EJ8MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13e276a6128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(diff_images.reshape(10,9,-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
