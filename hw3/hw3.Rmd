---
title: "Homework 3"
author: "CS 498, Spring 2018, Xiaoming Ji"
date: ''
output:
  html_document:
    toc: yes
  pdf_document: default
params:
  load_precomputed_data: yes
---

CIFAR-10 is a dataset of 32x32 images in 10 categories, collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. It is often used to evaluate machine learning algorithms. You can download this dataset from https://www.cs.toronto.edu/~kriz/cifar.html.

Firstly, we load the files to memory and do some pre-processing on the data.
```{r, eval=!params$load_precomputed_data, echo=FALSE}
start_time = Sys.time()
```

```{r}
# Read binary file and convert to integer vectors
# File format is 10000 records following the pattern:
label_names = read.table("cifar-10-batches-bin/batches.meta.txt")
label_count = dim(label_names)[1]
image_bytes = 32 * 32 * 3
pc_count = 20
```

```{r, eval=!params$load_precomputed_data, echo=FALSE}
#Set filenames need to be read
folder_name = "cifar-10-batches-bin"
file_names = c("data_batch_1.bin", "data_batch_2.bin","data_batch_3.bin",
               "data_batch_4.bin","data_batch_5.bin","test_batch.bin")
num.images = 10000 # Set to 10000 to retrieve all images per file to memory
mat_images = matrix(0, nrow = num.images * length(file_names), ncol = 1024 * 3 + 1)
 
# Cycle through all binary files
pb = txtProgressBar(min = 0, max = length(file_names), style = 3)
index = 1
for (f in 1:length(file_names)) {
  to.read = file(paste(folder_name, "/", file_names[f], sep=""), "rb")
  for(i in 1:num.images) {
    l = readBin(to.read, integer(), size=1, n=1, endian="big")
    mat_images[index, 1: image_bytes] = as.integer(readBin(to.read, raw(), size=1, 
                                                        n=image_bytes, endian="big"))
    mat_images[index, image_bytes + 1] = l + 1
    index = index + 1
  }
  close(to.read)
  setTxtProgressBar(pb, f)
}

all_images = list()
for (i in 1:label_count) { 
  all_images[[i]] = as.data.frame(mat_images[mat_images[,3073] == i,])
}
save(all_images,file="saved/all_images.data")

remove(mat_images)
```

```{r}
drawImage = function(image, title) {
  image[image > 255] = 255
  image[image < 0] = 0
  r = image[1:1024]
  g = image[1025:2048]
  b = image[2049:3072]
  img_matrix = rgb(r, g, b, maxColorValue=255)

  image(matrix(1:(32*32), 32, 32)[, 32:1], col=img_matrix, axes = FALSE,
        main = title)
}
```

# 1.1
For each category, compute the mean image and the first 20 principal components. Plot the error resulting from representing the images of each category using the first 20 principal components against the category.

```{r eval=params$load_precomputed_data, echo=FALSE}
load("saved/all_images.data") #Load images
```

```{r}
#Do PCA using Eigen value and vector
eigen_pca = function (data) {
  mean = colSums(data)
  covmat = cov(data)
  eigen = eigen(covmat, symmetric = TRUE)
  
  return (list(mean = colMeans(data), pc = eigen$vectors, weight = eigen$values))
}

#Constructing a low-dimensional representation:
cld = function(pc, mean, x, k) {
  u = pc[, 1:k]
  x = u %*% crossprod(u, x - mean) + mean
  
  return (x)
}
```

Let's do PCA for each category.
```{r, eval=!params$load_precomputed_data}
t_start = Sys.time()
all_pca = list()
pb = txtProgressBar(min = 0, max = label_count, style = 3)

for (i in 1:label_count) {
  all_pca[[i]] = eigen_pca(all_images[[i]][, -3073])
  setTxtProgressBar(pb, i)
}
cat(paste("\nTime Spent:", difftime(Sys.time(), t_start)))
save(all_pca, file="saved/pca.data")
```
To illustrate how well low-dimensional representation works, we approximate a sample image (Dear) by the mean and some principal components. Notice how good the approximation becomes with relatively few components (100 vs. 3072).
```{r eval=params$load_precomputed_data, echo=FALSE}
load("saved/pca.data")
```

```{r}
sample_index = 311
sample_label = 5
par(mfrow=c(2,5))
par(mar = c(1,1,1,1))

drawImage(all_images[[sample_label]][sample_index, -3073], "Original")
drawImage(all_pca[[sample_label]]$mean, "Mean")
for (k in c(1, 5, 10, 15, 20, 100, 150, 200)){
  drawImage(cld(all_pca[[sample_label]]$pc, all_pca[[sample_label]]$mean,
                t(all_images[[sample_label]][sample_index, -3073]), k), k)
}
```

Now, let's calculate and plot the error. We know that the error is the sum of the diagonal elements of the covariance matrix as:

$$
\sum_{j>s}^{j=d}var\left ( \left \{ r^{(j)} \right \} \right )
$$

```{r}
colors = c("darkblue", "darkcyan", "darkgreen", "darkgrey", "darkorange", "darkorchid", 
           "darkred", "darksalmon", "darkseagreen", "darkturquoise")
line_types = c(1, 1, 1, 2, 2, 3, 3, 4, 4, 5)

var_error = list()
e = rep(0, pc_count)
max_error = 0
min_error = 1e+10
for (i in 1:label_count){
  for (j in 1:pc_count) {
    e[j] = sum(all_pca[[i]]$weight[(j + 1):image_bytes])
  }
  if(max(e) > max_error) max_error = max(e)
  if(min(e) < min_error) min_error = min(e)
  var_error[[i]] = e
}

plot(var_error[[1]], type = "l", xlab="Principal Components Count", 
     ylab="Error (by Eigen Value)",ylim = c(min_error, max_error), 
     col=colors[1], lty = line_types[1])

for (i in 2:label_count){
  lines(var_error[[i]], col=colors[i], lty = line_types[i])
}

legend("topright", legend = label_names[,1], lwd = 1, col = colors, lty=line_types)
```

Alternatively, we can also compute the error by making low-dimensional representation for all of the images in a given category. Then, for each image, find the per-pixel differences between the reconstruction and its original image. Square those differences individually and sum them over the whole image. Finally, calculate the mean of this value over the whole category.

```{r}
pca_image_error = function(images, pc, mean, k) {
  diff = apply(images, 1, function(x){
      return (x[-3073] - cld(pc, mean, x[-3073], k))}
    )
  return (mean(apply(diff, 2, function(v){return (crossprod(v, v))})))
}
```

```{r eval=!params$load_precomputed_data}
t_start = Sys.time()
image_error = list()
e = rep(0, pc_count)
max_error = 0
min_error = 1e+10
pb = txtProgressBar(min = 0, max = label_count * pc_count, style = 3)

for (i in 1:label_count){
  for (k in 1:pc_count){
    e[k] = pca_image_error(all_images[[i]], all_pca[[i]]$pc, all_pca[[i]]$mean, k)
    setTxtProgressBar(pb, (i - 1) * pc_count + k)
  }
  if(max(e) > max_error) max_error = max(e)
  if(min(e) < min_error) min_error = min(e)
  image_error[[i]] = e
}

cat(paste("\nTime Spent:", difftime(Sys.time(), t_start)))
save(image_error, file="saved/image_error.data")
```

```{r eval=params$load_precomputed_data, echo=FALSE}
load("saved/image_error.data")
```

```{r}
plot(image_error[[1]], type = "l", xlab="Principal Components Count", 
     ylab="Error (by Low-Dimensional Image Comparison)", ylim = c(min_error, max_error), 
     col=colors[1], lty = line_types[1])

for (i in 2:label_count){
  lines(image_error[[i]], col=colors[i], lty = line_types[i])
}

legend("topright", legend = label_names[,1], lwd = 1, col = colors, lty=line_types)
```

We can check and conclude the results are almost identical between 2 approaches. 

# 1.2
Compute the distances between mean images for each pair of classes. Use principal coordinate analysis to make a 2D map of the means of each categories. For this exercise, compute distances by thinking of the images as vectors.

We follow *Procedure 4.3* on textbook page 82 to calculate 2D coordinates.
```{r}
MDS = function(D, k) {
  size = dim(D)[1]
  
  A = diag(1, size, size) - matrix(1, size, size) / size
  W = - 1/2 * A %*% D %*% t(A)
  e = eigen(W, symmetric = TRUE)
  
  return (e$vectors[,1:k] %*% diag(sqrt(e$values[1:k])))
}

#Offset the results so that category 1 is at the origin, rotate and scale 
#the results so that category 2 is at (1,0);
transform_2d = function(V) {
  V1 = t(t(V) - V[1,])
 
  theta = asin(abs(V1[2,1])/sqrt(V1[2,1]^2 + V1[2,2]^2)) + pi/2
  r  = matrix(c(cos(theta),sin(theta),-sin(theta),cos(theta)), 2, 2)  #rotation matrix
  V2 = V1 %*% r
  return (V2 / V2[2,1])
}

#Calculate distance of mean images
D = matrix(0, nrow = label_count, ncol = label_count)

for (i in 1: (label_count - 1)) {
  for (j in (i + 1) : label_count){
    diff = (all_pca[[i]]$mean - all_pca[[j]]$mean)
    D[i, j] = sqrt(crossprod(diff, diff))
    D[j, i] = D[i, j]
  }
}
print(D)
V = transform_2d(MDS(D, 2))

plot(V, xlab = "", ylab = "", col="Red", pch = 8, cex = 1.5, xlim = c(-0.1, 1.1))
for(i in 1:label_count){
  text(V[i,1], V[i,2], label_names[i,1], offset = 0)
}
```

It's amazing to see how similar objects close to each other! For example: dog, cat, deer, frog, gird and horse are all animals, they all gathered in top right corner. Automobile and truck are all vehicles and are closely positioned in the plot.

# 1.3
Here is another measure of the similarity of two classes. For class A and class B, define E(A | B) to be the average error obtained by representing all the images of class A using the mean of class A and the first 20 principal components of class B. Now define the similarity between classes to be (1/2)(E(A | B) + E(B | A)). If A and B are very similar, then this error should be small, because A's principal components should be good at representing B. But if they are very different, then A's principal components should represent B poorly. In turn, the similarity measure should be big. Use principal coordinate analysis to make a 2D map of the classes. 

```{r, eval=!params$load_precomputed_data}
t_start = Sys.time()
#Calculate similarity of every classes
S = matrix(0, nrow = label_count, ncol = label_count)

pb = txtProgressBar(min = 0, max = sum(1:10), style = 3)
pbc = 1
for (i in 1: label_count) {
  for (j in i : label_count){
    if(i != j) {
      error_1 = pca_image_error(all_images[[i]], all_pca[[j]]$pc, 
                              all_pca[[i]]$mean, pc_count)
      error_2 = pca_image_error(all_images[[j]], all_pca[[i]]$pc, 
                                all_pca[[j]]$mean, pc_count)
      S[i, j] = (error_1 + error_2) / 2
      S[j, i] = S[i, j]
    } else{
      S[i, j] = image_error[[i]][pc_count]  #Use the previously computed error
    }
    
    setTxtProgressBar(pb, pbc)
    pbc = pbc + 1
  }
}
cat(paste("\nTime Spent:", difftime(Sys.time(), t_start)))
save(S, file="saved/similarity.error")
```
```{r eval=params$load_precomputed_data, echo=FALSE}
load("saved/similarity.error")
```
```{r}
print(S)
V = transform_2d(MDS(S, 2))

plot(V, xlab = "", ylab = "", col="Green", pch = 8, cex = 1.5, xlim = c(-0.1, 1.1))
for(i in 1:label_count){
  text(V[i,1], V[i,2], label_names[i,1], offset = 0)
}
```

Compare this map to the map in the previous exercise, in general, they are similar in terms of similar categories positioned close to each other. For example: dog, cat, deer, frog, gird and horse are grouped together. Automobile and truck and are closely positioned in the plot.

However, if we check what exactly one close to which one, they are quite different. For example: *airplane* is close to *deer* for all animals in this map compared with  *automobile* is close to *horse* in the previous map. This is because the similarity values we calculated as: airplane vs. deer is $`r S[1,5]`$ and automobile vs. horse is $`r S[2, 8]`$. The 2D low-dimension reconstruction of this similarity matrix reflect such differences.

```{r, eval=!params$load_precomputed_data, echo=FALSE}
cat(paste("\nTotal Execution Time:", difftime(Sys.time(), start_time)))
```