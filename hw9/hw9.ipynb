{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - Tutorial\n",
    "\n",
    "### Task: Make change to [MNIST tensorflow tutorial](https://www.tensorflow.org/tutorials/layers) to log the accuracy on tensorboard every 100 batches, for at least 2000 batches.\n",
    "\n",
    "I build a new file ./mnist/mnist.py based on the tutorial. For this task, summary was added to function: *train()*\n",
    "\n",
    "\n",
    "Here is the screen capture of the accuracy graph from tensorboard.\n",
    "<img src=\"images/mnist_tutorial_test.png\">\n",
    "\n",
    "# MNIST - Improved\n",
    "\n",
    "### Task: Modify the architecture that is offered in the MNIST tutorial to get the best accuracy. \n",
    "\n",
    "I tried 2 approaches.\n",
    "\n",
    "* **adam**: Use tutorial model but change the optimizer to AdamOptimizer \n",
    "* **enhance**: Build a more sophisticated model (in *enhance_model()*  ) as:\n",
    "    * 3 convolutional layers (8, 32, 64).\n",
    "    * Add batch normalization layer after every convolutional layer.\n",
    "    * Have (2,2) pool layer after batch normalization layer.\n",
    "    * 1 hidden fully connected layer (1024) and the final fully connected output layer.\n",
    "\n",
    "Here is the screen capture to compare the accuracy of these 3 models.\n",
    "<img src=\"images/mnist_enhance_test.png\">\n",
    "\n",
    "From this fiture, we can conclude AdmaOptimier give the huge performance leap (compared with the tutorial). No much difference in terms of accuracy between **adam** and **enhance**. Both achieved 99% accuracy in 2,000 batches of training.\n",
    "\n",
    "# CIFAR10 -  Tutorial\n",
    "\n",
    "### Task: Make change to [CIFAR10 tensorflow tutorial](https://www.tensorflow.org/tutorials/deep_cnn) to log the accuracy on tensorboard every 100 batches, for at least 2000 batches.\n",
    "\n",
    "I made change to ./cifar10/cifar10_train.py by adding summary to function *train()*\n",
    "\n",
    "Here is the screen capture of the accuracy graph from tensorboard.\n",
    "\n",
    "<img src=\"images/cigar_tutorial.png\">\n",
    "\n",
    "This model achieved 65% accuracy in 2,000 batches of training (batch size: 100).\n",
    "\n",
    "# CIFAR10 - Transfer Learning\n",
    "\n",
    "## Task: Modify the architecture that is offered in the CIFAR-10 tutorial to get the best accuracy.\n",
    "\n",
    "Most of the time we won't want to train a whole convolutional network yourself. Modern ConvNets training on huge datasets like ImageNet take weeks on multiple GPUs. Instead, most people use a pretrained network either as a fixed feature extractor, or as an initial network to fine tune. In this excercise, we'll be using [VGGNet](https://arxiv.org/pdf/1409.1556.pdf) trained on the [ImageNet dataset](http://www.image-net.org/) as a feature extractor. Below is a diagram of the VGGNet architecture.\n",
    "\n",
    "<img src=\"images/vgg16.png\" width=700px>\n",
    "\n",
    "VGGNet is great because it's simple and has great performance, coming in second in the ImageNet competition. The idea here is that we keep all the convolutional layers, but replace the final fully connected layers with our own classifier. This way we can use VGGNet as a feature extractor for our images then easily train a simple classifier on top of that. What we'll do is take the first fully connected layer with 4096 units, including thresholding with ReLUs. We can use those values as a code for each image, then build a classifier on top of those codes.\n",
    "\n",
    "The idea of this task is to leverage the prebuild parameters of VGG16 to classify our cifar10 images. Specifically,\n",
    "\n",
    "* We use VGG16 model (defined under folder ./tensorflow_vgg) with pretrained (on ImageNet images) parameters and cut out the last fully connected layers. (Note: the VGG16 parameter file is not included in the submission)\n",
    "* Build 2 fully connected layers (implemented in *cifar_model()* in ./cifar10_transfer_learning/vgg_cifar_tl.py) and append to the previous VGG16 model.\n",
    "* To train the model, we use the VGG16/relu6 output as the input of our cifar models. This can save us tremendous amount of time to train the how VGG16 model (which has over 100 million parameters).\n",
    "* cifar10_input.py is reused for reading images.\n",
    "\n",
    "Here is the screen capture of the accuracy graph from tensorboard.\n",
    "\n",
    "<img src=\"images/cigar_transfer_learning.png\">\n",
    "\n",
    "VGG16 model hit 71% accuracy in 2,000 batches of training (batch size:100) and perform better than the original model. Although the gap is closed in the later batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
