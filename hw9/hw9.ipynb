{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - Tutorial\n",
    "\n",
    "### Task: Make change to [MNIST tensorflow tutorial](https://www.tensorflow.org/tutorials/layers) to log the accuracy on tensorboard every 100 batches, for at least 2000 batches.\n",
    "\n",
    "Changes made:\n",
    "\n",
    "Here is the screen capture of the accuracy graph from tensorboard.\n",
    "<img src=\"images/mnist_tutorial_test.png\">\n",
    "\n",
    "# MNIST - Improved\n",
    "\n",
    "### Task: Modify the architecture that is offered in the MNIST tutorial to get the best accuracy. \n",
    "\n",
    "Changes made:\n",
    "\n",
    "Here is the screen capture of the accuracy graph from tensorboard.\n",
    "<img src=\"images/mnist_tutorial_enhance_test.png\">\n",
    "\n",
    "# CIFAR10 -  Tutorial\n",
    "\n",
    "### Task: Make change to [CIFAR10 tensorflow tutorial](https://www.tensorflow.org/tutorials/deep_cnn) to log the accuracy on tensorboard every 100 batches, for at least 2000 batches.\n",
    "\n",
    "Changes made:\n",
    "\n",
    "\n",
    "# CIFAR10 - Transfer Learning\n",
    "\n",
    "## Task: Modify the architecture that is offered in the CIFAR-10 tutorial to get the best accuracy.\n",
    "\n",
    "Most of the time we won't want to train a whole convolutional network yourself. Modern ConvNets training on huge datasets like ImageNet take weeks on multiple GPUs. Instead, most people use a pretrained network either as a fixed feature extractor, or as an initial network to fine tune. In this excercise, we'll be using [VGGNet](https://arxiv.org/pdf/1409.1556.pdf) trained on the [ImageNet dataset](http://www.image-net.org/) as a feature extractor. Below is a diagram of the VGGNet architecture.\n",
    "\n",
    "<img src=\"images/vgg16.png\" width=700px>\n",
    "\n",
    "VGGNet is great because it's simple and has great performance, coming in second in the ImageNet competition. The idea here is that we keep all the convolutional layers, but replace the final fully connected layers with our own classifier. This way we can use VGGNet as a feature extractor for our images then easily train a simple classifier on top of that. What we'll do is take the first fully connected layer with 4096 units, including thresholding with ReLUs. We can use those values as a code for each image, then build a classifier on top of those codes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
